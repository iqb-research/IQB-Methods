[
  {
    "objectID": "posts_r_sig.html",
    "href": "posts_r_sig.html",
    "title": "R-SIG",
    "section": "",
    "text": "In the “R Special Interest Group” (R-SIG) we talk about all kinds of topics related to coding in R. It takes place every other week, so drop by if you’re interested!\n\nStructure\nEach session will focus on a specific topic/exercise, with a little input in the beginning, and a longer exercise part afterwards.\nYou also have the opportunity to bring in R-related questions which we will discuss in the end for 10 - 15 minutes. Please send them in the Friday before the next session.\nA suggestion for a timetable we can loosely follow:\n\n13:00 - 13:15: Input\n13:15 - 13:35: Exercise time :)\n13:35 - 13:50: Discuss exercises\n13:50 - 14:10: Questions\n\n\n\nFuture Topics\nHere a list of possible topics for the next sessions.\n\ntidyverse\n\nIntroduction\nData wrangling\nPlotting with ggplot2\n\nRecap of “Advanced Basics”:\n\nOwn functions\nloops\napply-family\n\nPackage development and how it might be relevant for scientific analyses:\n\nOwn functions\nStructure of projects\nTesting!\n\nCode Review: How to improve code I (or somebody else) has written. You can send in your code, it might be a nice way of getting feedback you won’t get otherwise. (Code review is very common in programming, as it can be very helpful to get some feedback or learn about different ways of doing stuff).\nCoding Kata: The website Codewars let’s you solve different coding challenges.\n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\nReading Time\n\n\n\n\n\n\n\n\n\nJun 3, 2024\n\n\nPlotting with ggplot2\n\n\nNicklas Hafiz\n\n\n1 min\n\n\n\n\n\n\n\nApr 8, 2024\n\n\nColumn-wise operations in the tidyverse\n\n\nNicklas Hafiz\n\n\n6 min\n\n\n\n\n\n\n\nMar 25, 2024\n\n\nData wrangling in the tidyverse\n\n\nNicklas Hafiz\n\n\n12 min\n\n\n\n\n\n\n\nMar 22, 2024\n\n\nData sets\n\n\nNicklas Hafiz\n\n\n2 min\n\n\n\n\n\n\n\nFeb 26, 2024\n\n\nIntroduction to the tidyverse\n\n\nNicklas Hafiz\n\n\n7 min\n\n\n\n\n\n\n\nDec 18, 2023\n\n\nCase_when() function\n\n\nNicklas Hafiz\n\n\n5 min\n\n\n\n\n\n\n\nOct 23, 2023\n\n\nReproducability with renv\n\n\nNicklas Hafiz\n\n\n2 min\n\n\n\n\n\n\n\nOct 9, 2023\n\n\nCleaner Scripts\n\n\nNicklas Hafiz\n\n\n1 min\n\n\n\n\n\n\n\nJul 31, 2023\n\n\nThe apply family\n\n\nNicklas Hafiz\n\n\n4 min\n\n\n\n\n\n\n\nMar 20, 2023\n\n\nfor-loops\n\n\nNicklas Hafiz\n\n\n1 min\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "docs/discussions/code_conventions.html",
    "href": "docs/discussions/code_conventions.html",
    "title": "Code-Konventionen",
    "section": "",
    "text": "Diese Seite dient als Zusammenfassung unserer Beschlüsse hinsichtlich bestimmter Code-Konventionen, die wir im Team verfolgen wollen. Zum Absprechen dieser Themen treffen wir uns regelmäßig einmal im Monat."
  },
  {
    "objectID": "docs/discussions/code_conventions.html#überblick",
    "href": "docs/discussions/code_conventions.html#überblick",
    "title": "Code-Konventionen",
    "section": "",
    "text": "Diese Seite dient als Zusammenfassung unserer Beschlüsse hinsichtlich bestimmter Code-Konventionen, die wir im Team verfolgen wollen. Zum Absprechen dieser Themen treffen wir uns regelmäßig einmal im Monat."
  },
  {
    "objectID": "docs/discussions/code_conventions.html#allgemeine-konventionen",
    "href": "docs/discussions/code_conventions.html#allgemeine-konventionen",
    "title": "Code-Konventionen",
    "section": "Allgemeine Konventionen",
    "text": "Allgemeine Konventionen\n\nUmfang von Code-Abschnitten\n\nGenerell sollte innerhalb einer Zeile möglichst wenig passieren. Als Orientierung: eine Zeile sollte nicht mehr als 100 Zeichen beinhalten.\nGleiches gilt für eine Funktion: sie sollte maximal 100 Zeilen lang sein, und eher in Sub-Funktionen aufgeteilt werden.\nIn R-Paketen sollte es pro exportierter Funktion ein eigenes Skript geben. Zu Hilsfunktionen haben wir noch nichts beschlossen.\n\nBei Funktionen mit vielen Funktionsargumenten soll eine Liste von Funktionsargumenten innerhalb der internen Funktionsköpfe übergeben werden.\nRigoroses testen kann helfen bei Ergänzung oder Löschung von Funktionsargumenten den Überblick zu behalten.\n\nhttps://uptake.github.io/pkgnet/articles/pkgnet-intro.html\n\n\n\n\nBenennungskonventionen\n\nBei längeren Objektnamen sollten Punkte vermieden werden und entweder CamelCases oder snake_cases genutzt werden. Das aber jeweils konsistent innerhalb von Paketen.\nkurze Namen vs sprechende Namen =&gt; eher sprechende Namen\nFunktionen: eher Verben\nObjekte (die keine Funktionen sind): eher Substantive\nallgemein keine Dopplungen mit existierenden R-Objekten!\nObjekt-Modifikation: Sprechende Namen, Nummern oder Überschreiben?\n\nwenn sich Objekte substanziell ändern, nicht überschreiben\n\nhäufige Argumentnamen: dat, path/file/filePath/filename, dir/folder, …\nArgumentreihenfolge? (Pipebarkeit =&gt; auch: Output-Steuerung)"
  },
  {
    "objectID": "docs/discussions/code_conventions.html#code-review",
    "href": "docs/discussions/code_conventions.html#code-review",
    "title": "Code-Konventionen",
    "section": "Code Review",
    "text": "Code Review\nOverview of the Git-Workflow can be found here.\n\nVorgehen\n\nPerson, die das Review anfordert, schlägt Personen für das Review for, in dem diese zur Pull-Request assigned werden.\nSind mehrere Reviewer zum Review assigned, reicht es i.d.R. wenn eine:r das Review übernimmt (es sei denn, es wird explizit angefordert, dass alle das Review übernehmen)\nÜbernimmt man ein Review, assigned man sich selbst den Pull-Request, dann wissen alle potenziell angesprochenen Reviewer gleich Bescheid, dass man übernimmt, auch wenn man noch nicht angefangen hat (bzw. noch keine Kommentare in den Code gesetzt hat)\n\n\n\nWas muss bei der Anforderung eines Reviews beachtet werden?\n\nEher kleinschrittige, abgeschlossene Bestandteile reviewen lassen.\nPriorität festlegen\n\nhigh: innerhalb eines Tages\nmedium: innerhalb einer Woche\nlow: keine Zeitbegrenzung\n\n\n\n\nWas sollen die Reviewer machen?\n\nSich zum Review assignen, wenn man anfängt.\nBenennungskonventionen, Formatkonventionen\nVerständlichkeit\nTests auf Vollständigkeit überprüfen (Edge Cases, möglichst alles abgedeckt?)\n\n\nOptional:\n\n\nMit den Tests rumspielen, versuchen die Funktion failen zu lassen.\n\n\n\nPersonelle Aufteilung\n\neatPrepTBA: PF, NH, KAS, … (mal schauen)\neatPrep: KAS, PF, NH\neatPlot: NH, PF, KAS\neatModel: SW, KAS, BB\neatRep: SW, BB, KAS\neatTools: SW, KAS, BB, NH, PF\neatAnalysis: BB, SW, KAS\neatGADS: BB, KAS, NH\neatDB: BB, PF, NH\neatFDZ: BB, NH\neatCodebook: BB, SW, PF, NH\neatRecode: BB, NH\neatATA: BB, DD, ?\n\n\n\nKommunikation & Zeiterwartung\n\nPerson, die das Review anfordert, schreibt ein paar Sätze dazu, worauf besonders geachtete werden sollte als Kommentar in den Pull-Request. Das können grobe Erwartungen an das Review sein (macht das konzeptuell Sinn, decken die Tests alle möglichen Edge cases ab …), oder eine Prioritätenfestlegung.\nIn Zukunft soll ein Standardprozedere definiert werden, in welchem festgelegt wird, in welcher Tiefe das Review erfolgen soll, und was standardmäßig gecheckt werden soll.\nLabel sollen einheitlich über die Repositories erstell und gentutzt werden (Bug/Enhancement …, Prio-Label)"
  },
  {
    "objectID": "docs/discussions/code_conventions.html#issues",
    "href": "docs/discussions/code_conventions.html#issues",
    "title": "Code-Konventionen",
    "section": "Issues",
    "text": "Issues\n\nWir nutzen GitHub-Projects um alle ToDos aus verschiedenen Repos an einem Ort zu sammeln.\n\nWichtige Issues aus jedem Repo sollten im Projekt hinzugefügt werden.\n\n\nIssues aus einem anderen Repository zum Projekt hinzufügen\n\nClick on Add item\n#beckerbenj/eatGADS\nFrom the suggested list you can choose the issue you want to add to the project, or create a new one.\n\nYou can filter for all open issues with is:issue is:open.\n\n\n\nIssue sorting\n\nColumn “Done” contains all finished issues. They will be discussed one last time at the jour fix, and than the issue will be closed together.\nEverything should be an issue, not a draft! Drafts without a project can fit into iqb-research/to-dos."
  },
  {
    "objectID": "docs/discussions/code_conventions.html#mögliche-nächste-themen",
    "href": "docs/discussions/code_conventions.html#mögliche-nächste-themen",
    "title": "Code-Konventionen",
    "section": "Mögliche nächste Themen",
    "text": "Mögliche nächste Themen\n\nIndentierung?\nHäufige Argumentnamen\nDplyr und/oder pipen?\nKommentar- & Austauschsprache\n“Sprechender Code”? Vgl. best Coding Practices…\nfinales Ziel: styleR?\nTests (Abdeckung, Umsetzung, Style, …)\nschematische Paket-Dokumentationen (nächstes Thema!)\n\npotentiell interessantes R Paket zur Visualisierung: https://uptake.github.io/pkgnet/articles/pkgnet-intro.html\n\nPaketstruktur-Vignette/Dokumentation auf Quarto-Homepage\nLabels bei Pull-Requests und Issues\nUmgang mit failed Tests bei Pull-Requests (ggf. differenziert nach Stumi/Wimi)\nWorkflow Update Pull Requests (Wiedervorlage nach Einarbeitung von requested Changes)"
  },
  {
    "objectID": "docs/git/index.html",
    "href": "docs/git/index.html",
    "title": "Pull requests with Github",
    "section": "",
    "text": "When people collaboratively develop software (R packages) and use Github as a repository, colleagues can review software parts before they are included in an updated package version. Since I always forget how the workflow for this works, I’ll write it down here step by step. These steps refer to the use of GitKraken; if you do this in RStudio, it may work differently.",
    "crumbs": [
      "R-Sig",
      "GitHub",
      "Pull requests with Github"
    ]
  },
  {
    "objectID": "docs/git/index.html#following-steps-are-necessary",
    "href": "docs/git/index.html#following-steps-are-necessary",
    "title": "Pull requests with Github",
    "section": "Following steps are necessary",
    "text": "Following steps are necessary\n\nA change has been made in the local repository (on your local hard disc copy of the repository).\nThe change is committed in GitKraken, but not yet pushed.\nInstead, right-click on “master” to open a menu and select “create branch here”.\nAssign a name for this branch.\nPush by pressing “Push”.\nChange to the the Github page of the package (for example, eatTools repository) and start the pull request via “Compare & pull request”.\nChoose your favorite reviewer under “Reviewer”\nIf necessary, enter a comment for the request.\nClick on “create pull request” to start the request.\nOnce the author and reviewer have reached an agreement, the review branch can be merged with the master branch (this is not done in GitKraken, but on the GitHub website: select the pull request, scroll down the page and click on “merge pull request into master”)\nFinally, the review branch can be deleted. Choose “delete” on the Github homepage. Then delete the local branch (i.e. in GitKraken) in the same way if necessary",
    "crumbs": [
      "R-Sig",
      "GitHub",
      "Pull requests with Github"
    ]
  },
  {
    "objectID": "docs/git/index.html#please-note",
    "href": "docs/git/index.html#please-note",
    "title": "Pull requests with Github",
    "section": "Please note",
    "text": "Please note\nAs long as the master branch and the new branch are not merged again, there are two “parallel” branches. The background to this is that - as long as developers are working in the new branch - users can always download the latest working version (i.e. the master branch) of the package. As a developer, you always have to check in GitKraken which branch is currently stored in your local repository. If you need to make changes in the new branch, you must first save it locally by double-clicking on the relevant branch.",
    "crumbs": [
      "R-Sig",
      "GitHub",
      "Pull requests with Github"
    ]
  },
  {
    "objectID": "docs/git/index.html#git-workflow-im-terminal-nh",
    "href": "docs/git/index.html#git-workflow-im-terminal-nh",
    "title": "Pull requests with Github",
    "section": "Git-Workflow im Terminal (NH)",
    "text": "Git-Workflow im Terminal (NH)\n\nGegebenenfalls: Auf den mainbranch wechseln: git checkout main\nVerifizieren, dass man auf dem richtigen branch ist: git status\nOnlinebranch lokal herunterladen: git pull\nGegebenenfalls: Neuen branch “branch_2” erstellen, und direkt darauf wechseln: git checkout -b branch_2\n(Alle) Änderungen stagen: git add .\nGestagte Änderungen commiten (mit aussagekräftiger Commitmessage): git commit -m \"implemented new function\"\nCommits hochladen: git push",
    "crumbs": [
      "R-Sig",
      "GitHub",
      "Pull requests with Github"
    ]
  },
  {
    "objectID": "docs/R/index.html",
    "href": "docs/R/index.html",
    "title": "Material for learning R",
    "section": "",
    "text": "R Introduction\nAn introduction to R with hands on examples and exercises can be found in Introduction to R.",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Material for learning R"
    ]
  },
  {
    "objectID": "docs/R/ws3.html",
    "href": "docs/R/ws3.html",
    "title": "Pakete(-Installation), Workspace, Daten laden und speichern in R",
    "section": "",
    "text": "Die Funktionalität von base R wird um ein vielfaches durch ein sehr umfangreiches Pakete-Universum ergänzt. Diese Erweiterungen werden für R packages oder libraries genannt. Im Prinzip kann jeder(r) eine solche library schreiben, deswegen ist bei der Nutzung neuer libraries etwas Vorsicht geboten. Es gibt jedoch eine Reihe sehr weit verbreiteter und hochwertiger libraries, deren Nutzung uneingeschränkt empfohlen werden kann.\nLiegen Pakete auf CRAN, können sie mithilfe von install.packages() installiert werden. Pakete, die ausschließlich auf Github verfügbar sind, können über devtools::install_github() installiert werden. Für nähere Informationen siehe auch: http://iqbstaff.pbworks.com/w/page/138429033/R-Pakete%20Installieren\n\n# Paket von CRAN installieren\ninstall.packages(\"car\")\n# Paket von Github installieren\nremotes::install_github(\"sachseka/eatPrep\", upgrade = \"never\")\n\nAchtung: Wenn ein Paket bereits geladen ist und eine Neuinstallation dieses Pakets versucht wird, kann dies zu Fehlern führen. In diesem Fall kann entweder die R Session neu gestartet oder das entsprechende Paket mit detach() “entladen” werden.\nZur Verwendung von Paketen können einzelne Funktionen explizit über ihren Namespace angesprochen werden, ohne dass sie dafür explizit geladen werden müssen:\n\n# Funktion verwenden, ohne Paket zu laden\nsome_data &lt;- c(1, 2, 1, 4)\ncar::recode(some_data, \"1 = 'a'; 2 = 'b'; 4 = 'd'\")\n\n[1] \"a\" \"b\" \"a\" \"d\"\n\n\nOder das Paket wird vollständig geladen mithilfe des library() Befehls\n\n# Paket laden\nlibrary(\"car\")\n\nLoading required package: carData\n\nsome_data &lt;- c(1, 2, 1, 4)\nrecode(some_data, \"1 = 'a'; 2 = 'b'; 4 = 'd'\")\n\n[1] \"a\" \"b\" \"a\" \"d\"\n\n\nFalls es mehrere Pakete gibt, die Funktionen mit demselben Namen beinhalten (zB dplyr::recode()), kann mit car::recode() sichergestellt werden, dass immer die gewünschte Funktion verwendet wird, auch wenn zusätzlich das Paket dplyr geladen wird.",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Pakete und Daten laden"
    ]
  },
  {
    "objectID": "docs/R/ws3.html#csv",
    "href": "docs/R/ws3.html#csv",
    "title": "Pakete(-Installation), Workspace, Daten laden und speichern in R",
    "section": ".csv",
    "text": ".csv\nBeim Speichern von comma seperated files (.csv) können die Funktionen write.csv() und write.csv2() verwendet werden, wobei letztere Funktion den deutschen Excel-Konventionen (“,” als Dezimaltrenner) entspricht.\n\n# Objekt speichern\nwrite.csv2(mtcars, \"Material_WSIII/mtcars.csv\")\n# Objekt laden\ndat &lt;- read.csv2(\"Material_WSIII/mtcars.csv\")\n# Objekt betrachten\nhead(dat)",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Pakete und Daten laden"
    ]
  },
  {
    "objectID": "docs/R/ws3.html#xlsx-excel",
    "href": "docs/R/ws3.html#xlsx-excel",
    "title": "Pakete(-Installation), Workspace, Daten laden und speichern in R",
    "section": ".xlsx (Excel)",
    "text": ".xlsx (Excel)\nZum Einlesen von Excel files empfiehlt sich die Funktion read_xlsx() aus dem Paket readxl. Achtung! Da das Paket standardmäßig einen tibble ausgibt, eine Spezialform von data.frames, empfiehlt sich die Umwandlung zu einem data.frame. Da das Paket leider kein Schreiben von Excel files unterstützt, empfiehlt sich hierfür die Funktion write_xlsx() aus dem Paket eatAnalysis.\n\n# Objekt speichern\neatAnalysis::write_xlsx(mtcars, \"Material_WSIII/mtcars.xlsx\", row.names = FALSE)\n# Objekt laden\ndat &lt;- readxl::read_xlsx(\"Material_WSIII/mtcars.xlsx\")\ndat &lt;- as.data.frame(dat)\nhead(dat)",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Pakete und Daten laden"
    ]
  },
  {
    "objectID": "docs/R/ws3.html#sav-spss",
    "href": "docs/R/ws3.html#sav-spss",
    "title": "Pakete(-Installation), Workspace, Daten laden und speichern in R",
    "section": ".sav (SPSS)",
    "text": ".sav (SPSS)\nZum Importieren von SPSS-Dateien bietet sich das Paket eatGADS an. Es ermöglicht das Einlesen von Daten in einem zwei-schrittigem Vorgehen. Zuerst werden die Daten eingelesen.\n\n# sav Datei einlesen\nspss &lt;- eatGADS::import_spss(\"Material_WSIII/example.sav\")\n\nDiese Datei enthält sämtliche Metadaten, die auch die originale spss-Datei beinhaltet (Variablen- und Wertelabel etc.). Diese können mithilfe von extractMeta abgefragt werden. Im Folgenden werden die Metadaten für die Variable \"PJgsep_a\" abgerufen:\n\n# sav Datei einlesen\neatGADS::extractMeta(spss, \"PJgsep_a\")\n\nUm Analysen in R durchzuführen, müssen die Daten aus diesem Objekt nun mithilfe der extractData()-Funktion extrahiert werden. Diese ermöglicht zum einen Missingcodes anzuwenden, zum anderen gelabelte Variablen entweder als numerische, character oder Faktor-Variablen auszugeben.\n\n# sav Datei einlesen\ndat &lt;- eatGADS::extractData(spss, convertLabel = \"character\", convertMiss = TRUE)\nhead(dat)",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Pakete und Daten laden"
    ]
  },
  {
    "objectID": "docs/R/ws3.html#dta-stata",
    "href": "docs/R/ws3.html#dta-stata",
    "title": "Pakete(-Installation), Workspace, Daten laden und speichern in R",
    "section": ".dta (Stata)",
    "text": ".dta (Stata)\nStata-Datein können mithilfe des Paktes haven sowohl gelesen als auch geschrieben werden.\n\n# Objekt speichern\nhaven::write_dta(mtcars, \"Material_WSIII/mtcars.dta\")\n# Objekt laden\ndat &lt;- haven::read_dta(\"Material_WSIII/mtcars.dta\")\ndat &lt;- as.data.frame(dat)\nhead(dat)",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Pakete und Daten laden"
    ]
  },
  {
    "objectID": "docs/R/ws3.html#dat-mplus",
    "href": "docs/R/ws3.html#dat-mplus",
    "title": "Pakete(-Installation), Workspace, Daten laden und speichern in R",
    "section": ".dat (Mplus)",
    "text": ".dat (Mplus)\nHäufig möchte man in Vorbereitung von Analysen mithilfe von Mplus Daten in R aufbereiten. Das Paket MplusAutomation beinhaltet die Funktion prepareMplusData(), die das schreiben von .dat Datein ermöglicht und zusätzlich einen Rohling für die Mplus-Analysesyntax erstellt. Außerdem beinhaltet das Paket zahlreiche Möglichkeiten verschiedene Analysen zu automatisieren.\n\n# Objekt speichern\nMplusAutomation::prepareMplusData(mtcars, filename = \"Material_WSIII/mtcars.dat\")",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Pakete und Daten laden"
    ]
  },
  {
    "objectID": "docs/eatPackages/eatRecode.html",
    "href": "docs/eatPackages/eatRecode.html",
    "title": "eatRecode",
    "section": "",
    "text": "Info\n\n\n\n\n\ncontact\nlatest version\nsource\n\n\n\n\nBenjamin Becker, Nicklas Hafiz\nDESCRIPTION on github\ngithub page\n\n\n\n\n\n\nDescription\nCreate and apply recoding databases.\n\n\n\n\n\nDocumentation",
    "crumbs": [
      "R-Sig",
      "eat Packages",
      "eatRecode"
    ]
  },
  {
    "objectID": "docs/eatPackages/eatModel.html",
    "href": "docs/eatPackages/eatModel.html",
    "title": "eatModel",
    "section": "",
    "text": "Info\n\n\n\n\n\ncontact\nlatest version\nsource\n\n\n\n\nSebastian Weirich\nDESCRIPTION on github\ngithub page, intern\n\n\n\n\n\n\nDescription\nServes as an interface for the ConQuest software. The required control files (script, labels, data set in ‘fixed width’ format) are automatically generated and ConQuest is called via the command line. The resulting files (showfile, WLEs, PVs, etc.) can be imported back into R and edited further. Newer versions of ‘eatModel’ also allow the integration of the R package ‘tam’ and parallelisation.\n\n\n\n\n\nDocumentation\n\n\n\n\ninternal",
    "crumbs": [
      "R-Sig",
      "eat Packages",
      "eatModel"
    ]
  },
  {
    "objectID": "docs/eatPackages/eatTools.html",
    "href": "docs/eatPackages/eatTools.html",
    "title": "eatTools",
    "section": "",
    "text": "Info\n\n\n\n\n\ncontact\nlatest version\nsource\n\n\n\n\nSebastian Weirich, Benjamin Becker, Karoline Sachse\nCRAN page\nCRAN page\n\n\n\n\n\n\nDescription\nVarious help functions that are also required by the packages ‘eatPrep’, ‘eatModel’, ‘eatGADS’ and ‘eatRep’, among others.\n\n\n\n\n\nDocumentation\n\n\n\n\nReference manual",
    "crumbs": [
      "R-Sig",
      "eat Packages",
      "eatTools"
    ]
  },
  {
    "objectID": "docs/eatPackages/eatGADS.html",
    "href": "docs/eatPackages/eatGADS.html",
    "title": "eatGADS",
    "section": "",
    "text": "Info\n\n\n\n\n\ncontact\nlatest version\nsource\n\n\n\n\nBenjamin Becker\nCRAN page\nCRAN page\n\n\n\n\n\n\nDescription\nAllows import and data preparation of SPSS data sets in R. Generates the General Analysis Data Set (GADS) for IQB Bildungstrend studies as a SQLite3 database. Parts of the data set can then be loaded into R using the package. It also allows the export of SPSS files to and from R.\n\n\n\n\n\nDocumentation\n\n\n\n\nInfo page with several vignettes",
    "crumbs": [
      "R-Sig",
      "eat Packages",
      "eatGADS"
    ]
  },
  {
    "objectID": "docs/eatPackages/eatPrep.html",
    "href": "docs/eatPackages/eatPrep.html",
    "title": "eatPrep",
    "section": "",
    "text": "Info\n\n\n\n\n\ncontact\nlatest version\nsource\n\n\n\n\nKaroline Sachse\nDESCRIPTION on github\ngithub page, internal\n\n\n\n\n\n\nDescription\nPreparation of test item data for IRT scaling using metadata provided by a predefined list structure as well as several tools and checks. Raw data can be read in and will be subjected to plausibility checks. Multiple datasets can be merged in a single step, incorporating detailed diagnostics for non-identical values among identical cases and variables. Data will be recoded according to the provided meta data, aggregated and scored. Handling different types of missing data is customizable according to user specifications. Further, missing patterns can be checked, various rater agreement measures and category discriminations can be calculated. The input metadata can be generated by the IQB-internal tool “AnalyseInput”, which extracts item and test design information from the IQB database and formats it into a standardized xlsx file. This file can then be read by functions specifically designed for this task. Alternatively, the metadata can be provided in R-specific data formats.\n\n\n\n\n\nDocumentation\n\n\n\n\ninternal: “i:/Methoden/02_IQB-interne_eat_Workshops/eatPrep_2021”",
    "crumbs": [
      "R-Sig",
      "eat Packages",
      "eatPrep"
    ]
  },
  {
    "objectID": "docs/eatPackages/eatPlot.html",
    "href": "docs/eatPackages/eatPlot.html",
    "title": "eatPlot",
    "section": "",
    "text": "Info\n\n\n\n\n\ncontact\nlatest version\nsource\n\n\n\n\nNicklas Hafiz, Philipp Franikowski\nDESCRIPTION on github\ngithub page\n\n\n\n\n\n\nDescription\nCreating plots from the eatRep output (main use: Bilduntstrend).\nDokumentation:\n\n\n\n\n\nDocumentation\n\n\n\n\nInfo page with several vignettes",
    "crumbs": [
      "R-Sig",
      "eat Packages",
      "eatPlot"
    ]
  },
  {
    "objectID": "docs/quarto/index.html",
    "href": "docs/quarto/index.html",
    "title": "Updating the website",
    "section": "",
    "text": "This website was created using Quarto. It is hosted on GitHub. In this chapter we will look at the underlying structure of this website, and how to update it."
  },
  {
    "objectID": "docs/quarto/index.html#setup",
    "href": "docs/quarto/index.html#setup",
    "title": "Updating the website",
    "section": "Setup",
    "text": "Setup\n\nAs the website is hosted on GitHub, you can just clone the repository.\nOpen the RStudio project with RStudio.\nThis website uses renv to keep the project specific package library up to date. The needed packages are recorded in the .lock-file, but not uploaded to GitHub. So the first thing you need to do is to install the necessary packages into your local project library:\n\n\n# install.packages(\"renv\")\nrenv::restore()\n\nIf your files need their own packages, just install them like you would normally do with either:\n\ninstall.packages(\"eatGADS\")\nrenv::install(\"eatGADS\")\n\nYou need to do this even if you have them already installed on your PC locally, because renv uses a project specific library."
  },
  {
    "objectID": "docs/quarto/index.html#file-structure",
    "href": "docs/quarto/index.html#file-structure",
    "title": "Updating the website",
    "section": "File structure",
    "text": "File structure\nBasically you just need to know where to put your files. Everything else will be taken care of by pushing to GitHub. Files can go into one of two folders: docs or posts. docs contains most of the tutorial files: They are structured into sub folders, like eatPackages or R. Here the quarto-files can be found that contain the actual website content. Edit them or add new ones. Make sure they are quarto-files with the .qmd ending.\n\n_quarto.yml\nOn the highest directory level you can find the _quarto.yml file. It defines the structure of the website. If you want your new page to be displayed in the website navigation, you have to add it here. You can define different sections and give name the links to the websites:\n    contents:\n      - section: \"R Tutorials\"\n        contents:\n          - section: \"Introduction\"\n            contents:\n             - docs/R/index.qmd\n             - href: https://nickhaf.github.io/r_tutorial/\n               text: Selfpaced R Workshop\n             - href: docs/R/ws1.qmd\n               text: Einführung\nThis creates the section R Tutorials with the subsection Introduction. Introduction consists of three pages: the index.qmd page, which is like the main page of this section, the page Selfpaced R Workshop, which actually is only a link to another website, and the page Einführung, which links to the qmd-file ws1.qmd. Just add your pages where appropriate.\n\n\nquarto-files\nThe quarto-files contain the actual content of the website. Just edit them like you would edit .qmd-files (or .rmd-files, as the rmarkdown syntax is quite similar). Here are some useful tips:\n\nLinking\nYou can easily link to other pages of this website, or to other websites:\n[displayed text](link.de)\nYou might need to use relative paths: [renv](../../posts/r_sig/23_11_06_renv/index.qmd). This will link to the renv page in the posts directory.\n\n\nPictures\nTo add a picture to your website, save the picture in the same folder as your .qmd-file. Then you can display it with:\n![](my_image.jpg)\n1\n\n\nFootnotes\nYou can add footnotes with:\nAdd a footnote[^2].\n\n[^2]: My Footnote.\nAdd a footnote2.\n\n\nCallouts\nYou can add little information boxes like this:\n::: callout-tip\nThe R-SIG meets each every two weeks on Monday from 13:00 - 14:00.\n:::\n\n\n\n\n\n\nTip\n\n\n\nThe R-SIG meets each every two weeks on Monday from 13:00 - 14:00.\n\n\nThere are multiple different options, take a look at the documentation for more.\n\n\nCSS styles\nYou can tweak the appearence even more by using you own CSS-styles.\n\n\n\nEditing on the web page\nYou can also find a small button called Edit this page next to the GitHub logo. This allows you to edit the page directly on GitHub."
  },
  {
    "objectID": "docs/quarto/index.html#building-the-website",
    "href": "docs/quarto/index.html#building-the-website",
    "title": "Updating the website",
    "section": "Building the website",
    "text": "Building the website\nTo get a preview of your website, click on the Render button in R Studio. Make sure you are not working locally and not on the network drive, because you might run into admin right problems otherwise. The rendering is not really necessary, because the website will only be built online when you push to GitHub. It will take a while (up to 20 min or more, depending on the size of the website) until the website is updated, as some checks are run first. The website will already get updated if you just open a pull request that wants to merge into main."
  },
  {
    "objectID": "docs/quarto/index.html#further-reading",
    "href": "docs/quarto/index.html#further-reading",
    "title": "Updating the website",
    "section": "Further reading",
    "text": "Further reading\nThe official documentation can be found here. A nice hands on tutorial on adding blog posts to an existing Quarto website can be found here, along with some additional tips on citations, footnotes etc."
  },
  {
    "objectID": "docs/quarto/index.html#footnotes",
    "href": "docs/quarto/index.html#footnotes",
    "title": "Updating the website",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Sinjin Thomas on Unsplash.↩︎\nMy Footnote.↩︎"
  },
  {
    "objectID": "posts_newsletter.html",
    "href": "posts_newsletter.html",
    "title": "Newsletter",
    "section": "",
    "text": "12-01-2024\n\n\nNewsletter\n\n\n\nNicklas Hafiz\n\n\nDec 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n09-08-2023\n\n\nNewsletter\n\n\n\nBenjamin Becker\n\n\nSep 8, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/r_sig/23_07_31_apply/index.html",
    "href": "posts/r_sig/23_07_31_apply/index.html",
    "title": "The apply family",
    "section": "",
    "text": "I can highly recommend the according chapter in R for Data Science in case you want to dive deeper."
  },
  {
    "objectID": "posts/r_sig/23_07_31_apply/index.html#for-loops",
    "href": "posts/r_sig/23_07_31_apply/index.html#for-loops",
    "title": "The apply family",
    "section": "For-loops",
    "text": "For-loops\nIn the last SIG we talked about for-loops.\nWhile for is definitely the most flexible of the looping options, we suggest you avoid it wherever you can, for the following two reasons:\n\n\nIt is not very expressive, i.e. takes a lot of code to do what you want.\n\n\nIt permits you to write horrible code.\n\n\nLet’s consider this example:\n\nexample_list &lt;- list(\n  \"vec_1\" = c(1:10),\n  \"vec_2\" = c(100:400),\n  \"vec_3\" = c(80:97, NA)\n)\nstr(example_list)\n\nList of 3\n $ vec_1: int [1:10] 1 2 3 4 5 6 7 8 9 10\n $ vec_2: int [1:301] 100 101 102 103 104 105 106 107 108 109 ...\n $ vec_3: int [1:19] 80 81 82 83 84 85 86 87 88 89 ...\n\n\nHere we have a list consisting of three vectors. Our goal is to sum them an output the result into a new vector. We could use a for-loop to do that:\n\nvec_sum &lt;- c()\nfor(i in 1: length(example_list)){\n  vec_sum[i] &lt;- sum(example_list[[i]], na.rm = TRUE)\n}\nvec_sum\n\n[1]    55 75250  1593\n\n\nOkay, that doesn’t look that complicated. But still, we need to define an empty vector at the beginning so we can save our sums, we need to iterate from 1:length(example_list), and manually select the \\(i^{th}\\) from the input list. That is not very expressive, and can be solved a lot easier. Enter, the apply-family:"
  },
  {
    "objectID": "posts/r_sig/23_07_31_apply/index.html#the-apply-family",
    "href": "posts/r_sig/23_07_31_apply/index.html#the-apply-family",
    "title": "The apply family",
    "section": "The apply-family",
    "text": "The apply-family\nThe apply-functions apply a function to a vector, list, matrix … and also always return a vector, list matrix …, depending on the specific function. Let’s rewrite our for-loop with sapply():\n\nvec_sum &lt;- sapply(example_list, sum)\nvec_sum\n\nvec_1 vec_2 vec_3 \n   55 75250    NA \n\n\nA lot less code and easier to understand! We just go over every list element and calculate its sum.\nIf we want to add another function argument, we can do that as well:\n\nvec_sum &lt;- sapply(example_list, sum, na.rm = TRUE)\nvec_sum\n\nvec_1 vec_2 vec_3 \n   55 75250  1593 \n\n\nWe can also define our own function:\n\nvec_sum &lt;- sapply(example_list, function(x){\n  res_sum &lt;- sum(x, na.rm = TRUE)\n  print(res_sum)\n  return(res_sum)\n})\n\n[1] 55\n[1] 75250\n[1] 1593\n\n\nHere we calculate the sum of object x, and then print it.\nFinally, which makes for even nicer code, we can define the function externally, to give it a concise name:\n\nprint_sum &lt;- function(vec){\n  res_sum &lt;- sum(vec, na.rm = TRUE)\n  print(res_sum)\n  return(res_sum)\n}\n\nvec_sum &lt;- sapply(example_list, print_sum)\n\n[1] 55\n[1] 75250\n[1] 1593\n\nvec_sum\n\nvec_1 vec_2 vec_3 \n   55 75250  1593 \n\n\nDepending of the output we want, we can choose different apply-functions:\n\nsapply()\nsapply() simplifies the result, so, e.g., it will return a vector if possible:\n\nsapply(example_list, print_sum)\n\n[1] 55\n[1] 75250\n[1] 1593\n\n\nvec_1 vec_2 vec_3 \n   55 75250  1593 \n\n\n\n\nvapply()\nSimilar to sapply(), but we can pre-specify a return value, so it might be safer to use:\n\nvapply(example_list, print_sum, integer(1))\n\n[1] 55\n[1] 75250\n[1] 1593\n\n\nvec_1 vec_2 vec_3 \n   55 75250  1593 \n\n\nBecause the result is an integer vector, we don’t get an error, but if we write this:\n\nvapply(example_list, print_sum, character(1))\n\n[1] 55\n\n\nError in vapply(example_list, print_sum, character(1)): values must be type 'character',\n but FUN(X[[1]]) result is type 'integer'\n\n\nThe function returns an error, because its output is an integer, and not a character vector.\n\n\nlapply()\nReturns a list:\n\nlapply(example_list, print_sum)\n\n[1] 55\n[1] 75250\n[1] 1593\n\n\n$vec_1\n[1] 55\n\n$vec_2\n[1] 75250\n\n$vec_3\n[1] 1593\n\n\n\n\n\n\n\n\nExercises\n\n\n\nWork with the iris data.frame (it is already included in Base R):\n\nExercise 1\nWrite a for-loop to determine the median of each column, if it is numeric. If not, return the column class with class(). Save the results in a character vector, so every element should be converted to character before saving it in the vector.\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\nvec_median &lt;- c()\nfor(i in 1:ncol(iris)){\n  if(is.numeric(iris[, i])){\n    vec_median[i] &lt;- as.character(median(iris[, i], na.rm = TRUE))\n  } else{\n    vec_median[i] &lt;- class(iris[, i])\n  }\n}\n\nvec_median\n\n[1] \"5.8\"    \"3\"      \"4.35\"   \"1.3\"    \"factor\"\n\n\n\n\n\n\n\nExercise 2\n\nDefine the body of the for loop as its own function. This function should take a vector, and, if this vector is numeric, output the median as a character, otherwise the class of the vector.\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\ncheck_median &lt;- function(vec){\n  if(is.numeric(vec)){\n    result &lt;- median(vec, na.rm = TRUE)\n  } else{\n    result &lt;- class(vec)\n  }\n  ## Convert to character, so our function always returns the correct type\n  result &lt;- as.character(result)\n  return(result)\n}\n\n## Check it:\ncheck_median(c(100, 1000))\n\n[1] \"550\"\n\ncheck_median(c(\"a\", \"b\"))\n\n[1] \"character\"\n\n\n\n\n\n\nUse it in the for-loop.\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\nvec_median &lt;- c()\nfor(i in 1:ncol(iris)){\n  vec_median[i] &lt;- check_median(iris[, i])\n}\n\nvec_median\n\n[1] \"5.8\"    \"3\"      \"4.35\"   \"1.3\"    \"factor\"\n\n\n\n\n\n\n\nExercise 3\nRewrite the for-loop from Exercise 1 with functions from the apply-family, so it returns the following objects. Define the function that gets applied on every input element externally, so we have cleaner code.\n\nA vector.\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\nsapply(iris, check_median)\n\nSepal.Length  Sepal.Width Petal.Length  Petal.Width      Species \n       \"5.8\"          \"3\"       \"4.35\"        \"1.3\"     \"factor\" \n\n\nOr, even better:\n\nvapply(iris, check_median, character(1))\n\nSepal.Length  Sepal.Width Petal.Length  Petal.Width      Species \n       \"5.8\"          \"3\"       \"4.35\"        \"1.3\"     \"factor\" \n\n\nWow, that’s pretty nice, we condensed our function to half a line by defining the function somewhere else, and not using a for-loop!\n\n\n\n\nA list.\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\nlapply(iris, check_median)\n\n$Sepal.Length\n[1] \"5.8\"\n\n$Sepal.Width\n[1] \"3\"\n\n$Petal.Length\n[1] \"4.35\"\n\n$Petal.Width\n[1] \"1.3\"\n\n$Species\n[1] \"factor\""
  },
  {
    "objectID": "posts/r_sig/23_07_31_apply/index.html#exercise-2",
    "href": "posts/r_sig/23_07_31_apply/index.html#exercise-2",
    "title": "The apply family",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nDefine the body of the for loop as its own function. This function should take a vector, and, if this vector is numeric, output the median as a character, otherwise the class of the vector.\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\ncheck_median &lt;- function(vec){\n  if(is.numeric(vec)){\n    result &lt;- median(vec, na.rm = TRUE)\n  } else{\n    result &lt;- class(vec)\n  }\n  ## Convert to character, so our function always returns the correct type\n  result &lt;- as.character(result)\n  return(result)\n}\n\n## Check it:\ncheck_median(c(100, 1000))\n\n[1] \"550\"\n\ncheck_median(c(\"a\", \"b\"))\n\n[1] \"character\"\n\n\n\n\n\n\nUse it in the for-loop.\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\nvec_median &lt;- c()\nfor(i in 1:ncol(iris)){\n  vec_median[i] &lt;- check_median(iris[, i])\n}\n\nvec_median\n\n[1] \"5.8\"    \"3\"      \"4.35\"   \"1.3\"    \"factor\""
  },
  {
    "objectID": "posts/r_sig/23_07_31_apply/index.html#exercise-3",
    "href": "posts/r_sig/23_07_31_apply/index.html#exercise-3",
    "title": "The apply family",
    "section": "Exercise 3",
    "text": "Exercise 3\nRewrite the for-loop from Exercise 1 with functions from the apply-family, so it returns the following objects. Define the function that gets applied on every input element externally, so we have cleaner code.\n\nA vector.\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\nsapply(iris, check_median)\n\nSepal.Length  Sepal.Width Petal.Length  Petal.Width      Species \n       \"5.8\"          \"3\"       \"4.35\"        \"1.3\"     \"factor\" \n\n\nOr, even better:\n\nvapply(iris, check_median, character(1))\n\nSepal.Length  Sepal.Width Petal.Length  Petal.Width      Species \n       \"5.8\"          \"3\"       \"4.35\"        \"1.3\"     \"factor\" \n\n\nWow, that’s pretty nice, we condensed our function to half a line by defining the function somewhere else, and not using a for-loop!\n\n\n\n\nA list.\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\nlapply(iris, check_median)\n\n$Sepal.Length\n[1] \"5.8\"\n\n$Sepal.Width\n[1] \"3\"\n\n$Petal.Length\n[1] \"4.35\"\n\n$Petal.Width\n[1] \"1.3\"\n\n$Species\n[1] \"factor\""
  },
  {
    "objectID": "posts/r_sig/24_06_03_ggplot2/index.html",
    "href": "posts/r_sig/24_06_03_ggplot2/index.html",
    "title": "Plotting with ggplot2",
    "section": "",
    "text": "1\nA ggplot2-tutorial I’ve created can be found here."
  },
  {
    "objectID": "posts/r_sig/24_06_03_ggplot2/index.html#footnotes",
    "href": "posts/r_sig/24_06_03_ggplot2/index.html#footnotes",
    "title": "Plotting with ggplot2",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Bing Copilot.↩︎"
  },
  {
    "objectID": "posts/r_sig/23_12_18_case_when/index.html",
    "href": "posts/r_sig/23_12_18_case_when/index.html",
    "title": "Case_when() function",
    "section": "",
    "text": "The case_when() function from the dplyr package of the tidyverse is a useful function for combining multiple ifelse() statements."
  },
  {
    "objectID": "posts/r_sig/23_12_18_case_when/index.html#how-to-use-it",
    "href": "posts/r_sig/23_12_18_case_when/index.html#how-to-use-it",
    "title": "Case_when() function",
    "section": "How to use it",
    "text": "How to use it\nLet’s take a look at a little example. Let’s consider a very simple data frame containing only a column of different countries:\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\ndf &lt;- data.frame(country = c(rep(\"Deu\", 4), \"Mexico\", \"Peru\", \"Ghana\", \"China\", \"Spanien\"))\n\nNow, let’s suppose we want to add a second column containing the continent of the country. We can either use nested ifelse() statements, which makes the coed quite hard to read:\n\ndf$continent &lt;- ifelse(df$country %in% c(\"Deu\", \"Spanien\"), \n                       yes = \"Europe\", \n                       no = ifelse(\n                         df$country == \"Mexico\" | df$country == \"Peru\", \n                         yes = \"America\",\n                         no = ifelse(\n                           df$country == \"Ghana\", \n                           yes = \"Africa\",\n                           no = \"Asia\"\n                       )\n                       ))\n\ndf\n\n  country continent\n1     Deu    Europe\n2     Deu    Europe\n3     Deu    Europe\n4     Deu    Europe\n5  Mexico   America\n6    Peru   America\n7   Ghana    Africa\n8   China      Asia\n9 Spanien    Europe\n\n\ncase_when() has a slightly different syntax, but is not nested, which makes it easier to read. Condition and output are seperated by ~. So if the condition on the left side is met in a row, the function returns the value on the right side of ~:\n\ndf_2 &lt;- df %&gt;%\n  mutate(continent = case_when(country %in% c(\"Deu\", \"Spanien\") ~ \"Europe\", \n                               country %in% c(\"Mexico\", \"Peru\") ~ \"America\",\n                               country == \"Ghana\" ~ \"Africa\", \n                               TRUE ~ \"Another continent\"\n                                 )\n         )\ndf_2\n\n  country         continent\n1     Deu            Europe\n2     Deu            Europe\n3     Deu            Europe\n4     Deu            Europe\n5  Mexico           America\n6    Peru           America\n7   Ghana            Africa\n8   China Another continent\n9 Spanien            Europe\n\n\nWe wrap this statement into a mutate function to automatically create the new column continent from the output of case_when. The TRUE in the last row catches all conditions we haven’t dealt with further above. So all rows wich haven’t met any of the above conditions will get the label “Another continent”."
  },
  {
    "objectID": "posts/r_sig/23_12_18_case_when/index.html#evaluation-order",
    "href": "posts/r_sig/23_12_18_case_when/index.html#evaluation-order",
    "title": "Case_when() function",
    "section": "Evaluation order",
    "text": "Evaluation order\ncase_when() goes from the top to the bottom. So if a row has met a statement, it is not considered further down. That’s why it makes sense to go from the most specific statements to the less specific ones. Otherwise the least specific ones might overwrite everything in the beginning:\n\ndf_3 &lt;- df %&gt;%\n  mutate(continent = case_when(country %in% c(df$country) ~ \"Other country\", \n                               country %in% c(\"Mexico\", \"Peru\") ~ \"America\",\n                               country == \"Ghana\" ~ \"Africa\", \n                               TRUE ~ \"Another continent\"\n                                 )\n         )\n\ndf_3  \n\n  country     continent\n1     Deu Other country\n2     Deu Other country\n3     Deu Other country\n4     Deu Other country\n5  Mexico Other country\n6    Peru Other country\n7   Ghana Other country\n8   China Other country\n9 Spanien Other country\n\n\nBecause our first statement already covers all rows, the rest is obsolete. This top-down working also makes the TRUE condition in our last line possible, because only those rows that haven’t been used yet will come this far, and all of them are catched (because TRUE always is true)."
  },
  {
    "objectID": "posts/r_sig/24_01_26_tidyverse_intro/index.html",
    "href": "posts/r_sig/24_01_26_tidyverse_intro/index.html",
    "title": "Introduction to the tidyverse",
    "section": "",
    "text": "1\nlibrary(tidyverse)"
  },
  {
    "objectID": "posts/r_sig/24_01_26_tidyverse_intro/index.html#introduction",
    "href": "posts/r_sig/24_01_26_tidyverse_intro/index.html#introduction",
    "title": "Introduction to the tidyverse",
    "section": "1 Introduction",
    "text": "1 Introduction\nTidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. (Wickham, 2014).\nThe tidyverse is composed of multiple packages, all following a common philosophy, and facilitating many aspects of coding in R, for example data wrangling and plotting. It is not really necessary to learn the tidyverse syntax in order to be proficient in R. However, I find it easier to understand and write Code in, at least in most cases. In the end, it is a question of preference what you want to learn and use. Most code will probably be composed from base R functions and tidyverse functions.\nYou can find an overview of the included packages at the offical tidyverse documentation.\nA more thorough introduction into the tidyverse can be found here."
  },
  {
    "objectID": "posts/r_sig/24_01_26_tidyverse_intro/index.html#some-tidyverse-features",
    "href": "posts/r_sig/24_01_26_tidyverse_intro/index.html#some-tidyverse-features",
    "title": "Introduction to the tidyverse",
    "section": "2 Some tidyverse features",
    "text": "2 Some tidyverse features\n\n2.1 Tibbles\nA special type of data frame are the so called tibbles. Tibbles are a modern version of data frames and the standard data frame type of the tidyverse, as they have some advantageous characteristics (e.g., note the more informative printing of the data frame). So don’t be confused if you run into them, in general they behave like data frames. Take a look at the Exercises, or at a more thorough Example if you want to learn more.\n\n\n2.2 The Pipe Operator\ntidyverse code is often written using the pipe operator %&gt;% (read as ‘then do’), which makes it easy to connect multiple function calls.\nSome notes on the pipe syntax, also see Exercises:\n\nIf we don’t have any additional arguments we want to put into the function, we can just write the function name without any brackets.\nThe pipe operator will give the result of the last function as input into the next function.\nIf we want to clearly state which of the function arguments should receive the input, we can write a ., which can be read as output of the previous function call."
  },
  {
    "objectID": "posts/r_sig/24_01_26_tidyverse_intro/index.html#workstation-organization",
    "href": "posts/r_sig/24_01_26_tidyverse_intro/index.html#workstation-organization",
    "title": "Introduction to the tidyverse",
    "section": "3 Workstation organization",
    "text": "3 Workstation organization\n\n3.1 RStudio Projects\nOver time, it will become increasingly hard to organize all your files, working directories and workspaces in a sensible manner. A reasonable big project will consist of multiple script files, data, output and plots. To keep everything toghether, RStudio Projects can be used (highly recommended). Therefore, when starting a new project in R, the first thing you should do is to create a RStudio project.\nYou can create a new RStudio project by clicking on File - New Project in the RStudio window. You can either create a totally new directory, or choose an already existing folder for the project.\n\n\n3.2 Code organization\nWithin your project folder, I would suggest that you create subfolders to save your Scripts, data, outputs … in. For example, you could create a folder named R, where all your R Scripts will go. You can do the same for data, plots etc. This will help you to structure your working directory and make it easier to find specific files.\n\n\n3.3 Absolute paths vs. relative paths\nI can head to a specific file by using the full path (absolute path): \"C:/Users/hafiznij/Documents/GitHub/IQB-Methods/posts/r_sig/24_01_26_tidyverse_intro/raw_data/winners.rda\". This approach has some disadvantages: it will only work on my notebook. If I want to continue my project on another device, I will have to change the path. The same goes for other people who want to work with my project. So, to keep these paths more reproducable, we should always use relative paths: \"./raw_data/winners.rda\". This will always work independently of the device I am working on, as long as I am in the correct working directory.\n\n\n\n\n\n\nNetwork drives\n\n\n\nOne exception might be paths to files on the IQB network drives, like T: … Because these are always the same for every one, absolute paths will work just fine for everything lying on here.\n\n\nThe working directory is the path R is currently working in. I can obtain it by typing:\n\ngetwd()\n\n[1] \"/home/runner/work/IQB-Methods/IQB-Methods/posts/r_sig/24_01_26_tidyverse_intro\"\n\n\nLuckily, RStudio projects set the working directory automatically, so we don’t really have to deal with that.\nNow take a look at the working directory and the relative path I used for loading the winners.rda. Notice something? Correct, both paths combined equal the absolute path to the file. So by splitting it up, we obtain a more reproducible path, that works independently of where the current working directory is.\n\n\n\n\n\n\nThe here package\n\n\n\nAnother great way to deal with the path confusion is to use the here package. It can build the paths relative to the directory where your R Studio project is saved in. For example, \"./raw_data/winners.rda\" becomes here::here(\"raw_data\", \"winners.rda\"). This is not incredibly important right now, especially if you have all your files in the same folder. But it can become very valuable with increasing project complexity and file structure, so look into it if you want to get a head start! I also I have to use it sometimes during the tutorial because of the way I have organized my project, so don’t be confused! It is just another way to build file paths. Look here (:D) if you want to learn more about the package."
  },
  {
    "objectID": "posts/r_sig/24_01_26_tidyverse_intro/index.html#exercise",
    "href": "posts/r_sig/24_01_26_tidyverse_intro/index.html#exercise",
    "title": "Introduction to the tidyverse",
    "section": "4 Exercise",
    "text": "4 Exercise\n\nCreate a new RStudio project. Create the folders R, data and plots. Create a new R-Script which lies in your R folder.\nWrite the following code using the pipe-operator from the tidyverse:\n\n\nsum(seq(from = 1, to = mean(c(45:100), na.rm = TRUE), by = 0.1))\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(tidyverse)\n\nc(45:100) %&gt;%\n  mean(na.rm = TRUE) %&gt;%\n  seq(from = 1, to = ., by = 0.1) %&gt;%\n  sum\n\n[1] 26313\n\n\nMuch nicer to read, right?\n\nIf we don’t have any additional arguments we want to put into the function, we can just write the function name without any brackets, like we do at the end with sum.\nThe pipe operator will give the result of the last function as input into the next function. That’s why we don’t have to specify the vector within the mean() function.\nIf we want to clearly state which of the function arguments should receive the input, we can write a ., which can be read as output of the previous function call. That’s what we do in the seq() function. It calculates a sequence from 1 to the mean of c(45:100).\n\n\n\n\n\nInstall and load the palmerpenguins package.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# install.packages(\"palmerpenguins\")\nlibrary(palmerpenguins)\n\n\n\n\n\nTransform the penguins-tibble (available after loading the package) into a data.frame.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npenguins_frame &lt;- as.data.frame(penguins)\n\n\n\n\n\nCompare how both objects (tibble and data.frame) are printed into the console. Which differences can you see?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npenguins\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\npenguins_frame\n\n      species    island bill_length_mm bill_depth_mm flipper_length_mm\n1      Adelie Torgersen           39.1          18.7               181\n2      Adelie Torgersen           39.5          17.4               186\n3      Adelie Torgersen           40.3          18.0               195\n4      Adelie Torgersen             NA            NA                NA\n5      Adelie Torgersen           36.7          19.3               193\n6      Adelie Torgersen           39.3          20.6               190\n7      Adelie Torgersen           38.9          17.8               181\n8      Adelie Torgersen           39.2          19.6               195\n9      Adelie Torgersen           34.1          18.1               193\n10     Adelie Torgersen           42.0          20.2               190\n11     Adelie Torgersen           37.8          17.1               186\n12     Adelie Torgersen           37.8          17.3               180\n13     Adelie Torgersen           41.1          17.6               182\n14     Adelie Torgersen           38.6          21.2               191\n15     Adelie Torgersen           34.6          21.1               198\n16     Adelie Torgersen           36.6          17.8               185\n17     Adelie Torgersen           38.7          19.0               195\n18     Adelie Torgersen           42.5          20.7               197\n19     Adelie Torgersen           34.4          18.4               184\n20     Adelie Torgersen           46.0          21.5               194\n21     Adelie    Biscoe           37.8          18.3               174\n22     Adelie    Biscoe           37.7          18.7               180\n23     Adelie    Biscoe           35.9          19.2               189\n24     Adelie    Biscoe           38.2          18.1               185\n25     Adelie    Biscoe           38.8          17.2               180\n26     Adelie    Biscoe           35.3          18.9               187\n27     Adelie    Biscoe           40.6          18.6               183\n28     Adelie    Biscoe           40.5          17.9               187\n29     Adelie    Biscoe           37.9          18.6               172\n30     Adelie    Biscoe           40.5          18.9               180\n31     Adelie     Dream           39.5          16.7               178\n32     Adelie     Dream           37.2          18.1               178\n33     Adelie     Dream           39.5          17.8               188\n34     Adelie     Dream           40.9          18.9               184\n35     Adelie     Dream           36.4          17.0               195\n36     Adelie     Dream           39.2          21.1               196\n37     Adelie     Dream           38.8          20.0               190\n38     Adelie     Dream           42.2          18.5               180\n39     Adelie     Dream           37.6          19.3               181\n40     Adelie     Dream           39.8          19.1               184\n41     Adelie     Dream           36.5          18.0               182\n42     Adelie     Dream           40.8          18.4               195\n43     Adelie     Dream           36.0          18.5               186\n44     Adelie     Dream           44.1          19.7               196\n45     Adelie     Dream           37.0          16.9               185\n46     Adelie     Dream           39.6          18.8               190\n47     Adelie     Dream           41.1          19.0               182\n48     Adelie     Dream           37.5          18.9               179\n49     Adelie     Dream           36.0          17.9               190\n50     Adelie     Dream           42.3          21.2               191\n51     Adelie    Biscoe           39.6          17.7               186\n52     Adelie    Biscoe           40.1          18.9               188\n53     Adelie    Biscoe           35.0          17.9               190\n54     Adelie    Biscoe           42.0          19.5               200\n55     Adelie    Biscoe           34.5          18.1               187\n56     Adelie    Biscoe           41.4          18.6               191\n57     Adelie    Biscoe           39.0          17.5               186\n58     Adelie    Biscoe           40.6          18.8               193\n59     Adelie    Biscoe           36.5          16.6               181\n60     Adelie    Biscoe           37.6          19.1               194\n61     Adelie    Biscoe           35.7          16.9               185\n62     Adelie    Biscoe           41.3          21.1               195\n63     Adelie    Biscoe           37.6          17.0               185\n64     Adelie    Biscoe           41.1          18.2               192\n65     Adelie    Biscoe           36.4          17.1               184\n66     Adelie    Biscoe           41.6          18.0               192\n67     Adelie    Biscoe           35.5          16.2               195\n68     Adelie    Biscoe           41.1          19.1               188\n69     Adelie Torgersen           35.9          16.6               190\n70     Adelie Torgersen           41.8          19.4               198\n71     Adelie Torgersen           33.5          19.0               190\n72     Adelie Torgersen           39.7          18.4               190\n73     Adelie Torgersen           39.6          17.2               196\n74     Adelie Torgersen           45.8          18.9               197\n75     Adelie Torgersen           35.5          17.5               190\n76     Adelie Torgersen           42.8          18.5               195\n77     Adelie Torgersen           40.9          16.8               191\n78     Adelie Torgersen           37.2          19.4               184\n79     Adelie Torgersen           36.2          16.1               187\n80     Adelie Torgersen           42.1          19.1               195\n81     Adelie Torgersen           34.6          17.2               189\n82     Adelie Torgersen           42.9          17.6               196\n83     Adelie Torgersen           36.7          18.8               187\n84     Adelie Torgersen           35.1          19.4               193\n85     Adelie     Dream           37.3          17.8               191\n86     Adelie     Dream           41.3          20.3               194\n87     Adelie     Dream           36.3          19.5               190\n88     Adelie     Dream           36.9          18.6               189\n89     Adelie     Dream           38.3          19.2               189\n90     Adelie     Dream           38.9          18.8               190\n91     Adelie     Dream           35.7          18.0               202\n92     Adelie     Dream           41.1          18.1               205\n93     Adelie     Dream           34.0          17.1               185\n94     Adelie     Dream           39.6          18.1               186\n95     Adelie     Dream           36.2          17.3               187\n96     Adelie     Dream           40.8          18.9               208\n97     Adelie     Dream           38.1          18.6               190\n98     Adelie     Dream           40.3          18.5               196\n99     Adelie     Dream           33.1          16.1               178\n100    Adelie     Dream           43.2          18.5               192\n101    Adelie    Biscoe           35.0          17.9               192\n102    Adelie    Biscoe           41.0          20.0               203\n103    Adelie    Biscoe           37.7          16.0               183\n104    Adelie    Biscoe           37.8          20.0               190\n105    Adelie    Biscoe           37.9          18.6               193\n106    Adelie    Biscoe           39.7          18.9               184\n107    Adelie    Biscoe           38.6          17.2               199\n108    Adelie    Biscoe           38.2          20.0               190\n109    Adelie    Biscoe           38.1          17.0               181\n110    Adelie    Biscoe           43.2          19.0               197\n111    Adelie    Biscoe           38.1          16.5               198\n112    Adelie    Biscoe           45.6          20.3               191\n113    Adelie    Biscoe           39.7          17.7               193\n114    Adelie    Biscoe           42.2          19.5               197\n115    Adelie    Biscoe           39.6          20.7               191\n116    Adelie    Biscoe           42.7          18.3               196\n117    Adelie Torgersen           38.6          17.0               188\n118    Adelie Torgersen           37.3          20.5               199\n119    Adelie Torgersen           35.7          17.0               189\n120    Adelie Torgersen           41.1          18.6               189\n121    Adelie Torgersen           36.2          17.2               187\n122    Adelie Torgersen           37.7          19.8               198\n123    Adelie Torgersen           40.2          17.0               176\n124    Adelie Torgersen           41.4          18.5               202\n125    Adelie Torgersen           35.2          15.9               186\n126    Adelie Torgersen           40.6          19.0               199\n127    Adelie Torgersen           38.8          17.6               191\n128    Adelie Torgersen           41.5          18.3               195\n129    Adelie Torgersen           39.0          17.1               191\n130    Adelie Torgersen           44.1          18.0               210\n131    Adelie Torgersen           38.5          17.9               190\n132    Adelie Torgersen           43.1          19.2               197\n133    Adelie     Dream           36.8          18.5               193\n134    Adelie     Dream           37.5          18.5               199\n135    Adelie     Dream           38.1          17.6               187\n136    Adelie     Dream           41.1          17.5               190\n137    Adelie     Dream           35.6          17.5               191\n138    Adelie     Dream           40.2          20.1               200\n139    Adelie     Dream           37.0          16.5               185\n140    Adelie     Dream           39.7          17.9               193\n141    Adelie     Dream           40.2          17.1               193\n142    Adelie     Dream           40.6          17.2               187\n143    Adelie     Dream           32.1          15.5               188\n144    Adelie     Dream           40.7          17.0               190\n145    Adelie     Dream           37.3          16.8               192\n146    Adelie     Dream           39.0          18.7               185\n147    Adelie     Dream           39.2          18.6               190\n148    Adelie     Dream           36.6          18.4               184\n149    Adelie     Dream           36.0          17.8               195\n150    Adelie     Dream           37.8          18.1               193\n151    Adelie     Dream           36.0          17.1               187\n152    Adelie     Dream           41.5          18.5               201\n153    Gentoo    Biscoe           46.1          13.2               211\n154    Gentoo    Biscoe           50.0          16.3               230\n155    Gentoo    Biscoe           48.7          14.1               210\n156    Gentoo    Biscoe           50.0          15.2               218\n157    Gentoo    Biscoe           47.6          14.5               215\n158    Gentoo    Biscoe           46.5          13.5               210\n159    Gentoo    Biscoe           45.4          14.6               211\n160    Gentoo    Biscoe           46.7          15.3               219\n161    Gentoo    Biscoe           43.3          13.4               209\n162    Gentoo    Biscoe           46.8          15.4               215\n163    Gentoo    Biscoe           40.9          13.7               214\n164    Gentoo    Biscoe           49.0          16.1               216\n165    Gentoo    Biscoe           45.5          13.7               214\n166    Gentoo    Biscoe           48.4          14.6               213\n167    Gentoo    Biscoe           45.8          14.6               210\n168    Gentoo    Biscoe           49.3          15.7               217\n169    Gentoo    Biscoe           42.0          13.5               210\n170    Gentoo    Biscoe           49.2          15.2               221\n171    Gentoo    Biscoe           46.2          14.5               209\n172    Gentoo    Biscoe           48.7          15.1               222\n173    Gentoo    Biscoe           50.2          14.3               218\n174    Gentoo    Biscoe           45.1          14.5               215\n175    Gentoo    Biscoe           46.5          14.5               213\n176    Gentoo    Biscoe           46.3          15.8               215\n177    Gentoo    Biscoe           42.9          13.1               215\n178    Gentoo    Biscoe           46.1          15.1               215\n179    Gentoo    Biscoe           44.5          14.3               216\n180    Gentoo    Biscoe           47.8          15.0               215\n181    Gentoo    Biscoe           48.2          14.3               210\n182    Gentoo    Biscoe           50.0          15.3               220\n183    Gentoo    Biscoe           47.3          15.3               222\n184    Gentoo    Biscoe           42.8          14.2               209\n185    Gentoo    Biscoe           45.1          14.5               207\n186    Gentoo    Biscoe           59.6          17.0               230\n187    Gentoo    Biscoe           49.1          14.8               220\n188    Gentoo    Biscoe           48.4          16.3               220\n189    Gentoo    Biscoe           42.6          13.7               213\n190    Gentoo    Biscoe           44.4          17.3               219\n191    Gentoo    Biscoe           44.0          13.6               208\n192    Gentoo    Biscoe           48.7          15.7               208\n193    Gentoo    Biscoe           42.7          13.7               208\n194    Gentoo    Biscoe           49.6          16.0               225\n195    Gentoo    Biscoe           45.3          13.7               210\n196    Gentoo    Biscoe           49.6          15.0               216\n197    Gentoo    Biscoe           50.5          15.9               222\n198    Gentoo    Biscoe           43.6          13.9               217\n199    Gentoo    Biscoe           45.5          13.9               210\n200    Gentoo    Biscoe           50.5          15.9               225\n201    Gentoo    Biscoe           44.9          13.3               213\n202    Gentoo    Biscoe           45.2          15.8               215\n203    Gentoo    Biscoe           46.6          14.2               210\n204    Gentoo    Biscoe           48.5          14.1               220\n205    Gentoo    Biscoe           45.1          14.4               210\n206    Gentoo    Biscoe           50.1          15.0               225\n207    Gentoo    Biscoe           46.5          14.4               217\n208    Gentoo    Biscoe           45.0          15.4               220\n209    Gentoo    Biscoe           43.8          13.9               208\n210    Gentoo    Biscoe           45.5          15.0               220\n211    Gentoo    Biscoe           43.2          14.5               208\n212    Gentoo    Biscoe           50.4          15.3               224\n213    Gentoo    Biscoe           45.3          13.8               208\n214    Gentoo    Biscoe           46.2          14.9               221\n215    Gentoo    Biscoe           45.7          13.9               214\n216    Gentoo    Biscoe           54.3          15.7               231\n217    Gentoo    Biscoe           45.8          14.2               219\n218    Gentoo    Biscoe           49.8          16.8               230\n219    Gentoo    Biscoe           46.2          14.4               214\n220    Gentoo    Biscoe           49.5          16.2               229\n221    Gentoo    Biscoe           43.5          14.2               220\n222    Gentoo    Biscoe           50.7          15.0               223\n223    Gentoo    Biscoe           47.7          15.0               216\n224    Gentoo    Biscoe           46.4          15.6               221\n225    Gentoo    Biscoe           48.2          15.6               221\n226    Gentoo    Biscoe           46.5          14.8               217\n227    Gentoo    Biscoe           46.4          15.0               216\n228    Gentoo    Biscoe           48.6          16.0               230\n229    Gentoo    Biscoe           47.5          14.2               209\n230    Gentoo    Biscoe           51.1          16.3               220\n231    Gentoo    Biscoe           45.2          13.8               215\n232    Gentoo    Biscoe           45.2          16.4               223\n233    Gentoo    Biscoe           49.1          14.5               212\n234    Gentoo    Biscoe           52.5          15.6               221\n235    Gentoo    Biscoe           47.4          14.6               212\n236    Gentoo    Biscoe           50.0          15.9               224\n237    Gentoo    Biscoe           44.9          13.8               212\n238    Gentoo    Biscoe           50.8          17.3               228\n239    Gentoo    Biscoe           43.4          14.4               218\n240    Gentoo    Biscoe           51.3          14.2               218\n241    Gentoo    Biscoe           47.5          14.0               212\n242    Gentoo    Biscoe           52.1          17.0               230\n243    Gentoo    Biscoe           47.5          15.0               218\n244    Gentoo    Biscoe           52.2          17.1               228\n245    Gentoo    Biscoe           45.5          14.5               212\n246    Gentoo    Biscoe           49.5          16.1               224\n247    Gentoo    Biscoe           44.5          14.7               214\n248    Gentoo    Biscoe           50.8          15.7               226\n249    Gentoo    Biscoe           49.4          15.8               216\n250    Gentoo    Biscoe           46.9          14.6               222\n251    Gentoo    Biscoe           48.4          14.4               203\n252    Gentoo    Biscoe           51.1          16.5               225\n253    Gentoo    Biscoe           48.5          15.0               219\n254    Gentoo    Biscoe           55.9          17.0               228\n255    Gentoo    Biscoe           47.2          15.5               215\n256    Gentoo    Biscoe           49.1          15.0               228\n257    Gentoo    Biscoe           47.3          13.8               216\n258    Gentoo    Biscoe           46.8          16.1               215\n259    Gentoo    Biscoe           41.7          14.7               210\n260    Gentoo    Biscoe           53.4          15.8               219\n261    Gentoo    Biscoe           43.3          14.0               208\n262    Gentoo    Biscoe           48.1          15.1               209\n263    Gentoo    Biscoe           50.5          15.2               216\n264    Gentoo    Biscoe           49.8          15.9               229\n265    Gentoo    Biscoe           43.5          15.2               213\n266    Gentoo    Biscoe           51.5          16.3               230\n267    Gentoo    Biscoe           46.2          14.1               217\n268    Gentoo    Biscoe           55.1          16.0               230\n269    Gentoo    Biscoe           44.5          15.7               217\n270    Gentoo    Biscoe           48.8          16.2               222\n271    Gentoo    Biscoe           47.2          13.7               214\n272    Gentoo    Biscoe             NA            NA                NA\n273    Gentoo    Biscoe           46.8          14.3               215\n274    Gentoo    Biscoe           50.4          15.7               222\n275    Gentoo    Biscoe           45.2          14.8               212\n276    Gentoo    Biscoe           49.9          16.1               213\n277 Chinstrap     Dream           46.5          17.9               192\n278 Chinstrap     Dream           50.0          19.5               196\n279 Chinstrap     Dream           51.3          19.2               193\n280 Chinstrap     Dream           45.4          18.7               188\n281 Chinstrap     Dream           52.7          19.8               197\n282 Chinstrap     Dream           45.2          17.8               198\n283 Chinstrap     Dream           46.1          18.2               178\n284 Chinstrap     Dream           51.3          18.2               197\n285 Chinstrap     Dream           46.0          18.9               195\n286 Chinstrap     Dream           51.3          19.9               198\n287 Chinstrap     Dream           46.6          17.8               193\n288 Chinstrap     Dream           51.7          20.3               194\n289 Chinstrap     Dream           47.0          17.3               185\n290 Chinstrap     Dream           52.0          18.1               201\n291 Chinstrap     Dream           45.9          17.1               190\n292 Chinstrap     Dream           50.5          19.6               201\n293 Chinstrap     Dream           50.3          20.0               197\n294 Chinstrap     Dream           58.0          17.8               181\n295 Chinstrap     Dream           46.4          18.6               190\n296 Chinstrap     Dream           49.2          18.2               195\n297 Chinstrap     Dream           42.4          17.3               181\n298 Chinstrap     Dream           48.5          17.5               191\n299 Chinstrap     Dream           43.2          16.6               187\n300 Chinstrap     Dream           50.6          19.4               193\n301 Chinstrap     Dream           46.7          17.9               195\n302 Chinstrap     Dream           52.0          19.0               197\n303 Chinstrap     Dream           50.5          18.4               200\n304 Chinstrap     Dream           49.5          19.0               200\n305 Chinstrap     Dream           46.4          17.8               191\n306 Chinstrap     Dream           52.8          20.0               205\n307 Chinstrap     Dream           40.9          16.6               187\n308 Chinstrap     Dream           54.2          20.8               201\n309 Chinstrap     Dream           42.5          16.7               187\n310 Chinstrap     Dream           51.0          18.8               203\n311 Chinstrap     Dream           49.7          18.6               195\n312 Chinstrap     Dream           47.5          16.8               199\n313 Chinstrap     Dream           47.6          18.3               195\n314 Chinstrap     Dream           52.0          20.7               210\n315 Chinstrap     Dream           46.9          16.6               192\n316 Chinstrap     Dream           53.5          19.9               205\n317 Chinstrap     Dream           49.0          19.5               210\n318 Chinstrap     Dream           46.2          17.5               187\n319 Chinstrap     Dream           50.9          19.1               196\n320 Chinstrap     Dream           45.5          17.0               196\n321 Chinstrap     Dream           50.9          17.9               196\n322 Chinstrap     Dream           50.8          18.5               201\n323 Chinstrap     Dream           50.1          17.9               190\n324 Chinstrap     Dream           49.0          19.6               212\n325 Chinstrap     Dream           51.5          18.7               187\n326 Chinstrap     Dream           49.8          17.3               198\n327 Chinstrap     Dream           48.1          16.4               199\n328 Chinstrap     Dream           51.4          19.0               201\n329 Chinstrap     Dream           45.7          17.3               193\n330 Chinstrap     Dream           50.7          19.7               203\n331 Chinstrap     Dream           42.5          17.3               187\n332 Chinstrap     Dream           52.2          18.8               197\n333 Chinstrap     Dream           45.2          16.6               191\n334 Chinstrap     Dream           49.3          19.9               203\n335 Chinstrap     Dream           50.2          18.8               202\n336 Chinstrap     Dream           45.6          19.4               194\n337 Chinstrap     Dream           51.9          19.5               206\n338 Chinstrap     Dream           46.8          16.5               189\n339 Chinstrap     Dream           45.7          17.0               195\n340 Chinstrap     Dream           55.8          19.8               207\n341 Chinstrap     Dream           43.5          18.1               202\n342 Chinstrap     Dream           49.6          18.2               193\n343 Chinstrap     Dream           50.8          19.0               210\n344 Chinstrap     Dream           50.2          18.7               198\n    body_mass_g    sex year\n1          3750   male 2007\n2          3800 female 2007\n3          3250 female 2007\n4            NA   &lt;NA&gt; 2007\n5          3450 female 2007\n6          3650   male 2007\n7          3625 female 2007\n8          4675   male 2007\n9          3475   &lt;NA&gt; 2007\n10         4250   &lt;NA&gt; 2007\n11         3300   &lt;NA&gt; 2007\n12         3700   &lt;NA&gt; 2007\n13         3200 female 2007\n14         3800   male 2007\n15         4400   male 2007\n16         3700 female 2007\n17         3450 female 2007\n18         4500   male 2007\n19         3325 female 2007\n20         4200   male 2007\n21         3400 female 2007\n22         3600   male 2007\n23         3800 female 2007\n24         3950   male 2007\n25         3800   male 2007\n26         3800 female 2007\n27         3550   male 2007\n28         3200 female 2007\n29         3150 female 2007\n30         3950   male 2007\n31         3250 female 2007\n32         3900   male 2007\n33         3300 female 2007\n34         3900   male 2007\n35         3325 female 2007\n36         4150   male 2007\n37         3950   male 2007\n38         3550 female 2007\n39         3300 female 2007\n40         4650   male 2007\n41         3150 female 2007\n42         3900   male 2007\n43         3100 female 2007\n44         4400   male 2007\n45         3000 female 2007\n46         4600   male 2007\n47         3425   male 2007\n48         2975   &lt;NA&gt; 2007\n49         3450 female 2007\n50         4150   male 2007\n51         3500 female 2008\n52         4300   male 2008\n53         3450 female 2008\n54         4050   male 2008\n55         2900 female 2008\n56         3700   male 2008\n57         3550 female 2008\n58         3800   male 2008\n59         2850 female 2008\n60         3750   male 2008\n61         3150 female 2008\n62         4400   male 2008\n63         3600 female 2008\n64         4050   male 2008\n65         2850 female 2008\n66         3950   male 2008\n67         3350 female 2008\n68         4100   male 2008\n69         3050 female 2008\n70         4450   male 2008\n71         3600 female 2008\n72         3900   male 2008\n73         3550 female 2008\n74         4150   male 2008\n75         3700 female 2008\n76         4250   male 2008\n77         3700 female 2008\n78         3900   male 2008\n79         3550 female 2008\n80         4000   male 2008\n81         3200 female 2008\n82         4700   male 2008\n83         3800 female 2008\n84         4200   male 2008\n85         3350 female 2008\n86         3550   male 2008\n87         3800   male 2008\n88         3500 female 2008\n89         3950   male 2008\n90         3600 female 2008\n91         3550 female 2008\n92         4300   male 2008\n93         3400 female 2008\n94         4450   male 2008\n95         3300 female 2008\n96         4300   male 2008\n97         3700 female 2008\n98         4350   male 2008\n99         2900 female 2008\n100        4100   male 2008\n101        3725 female 2009\n102        4725   male 2009\n103        3075 female 2009\n104        4250   male 2009\n105        2925 female 2009\n106        3550   male 2009\n107        3750 female 2009\n108        3900   male 2009\n109        3175 female 2009\n110        4775   male 2009\n111        3825 female 2009\n112        4600   male 2009\n113        3200 female 2009\n114        4275   male 2009\n115        3900 female 2009\n116        4075   male 2009\n117        2900 female 2009\n118        3775   male 2009\n119        3350 female 2009\n120        3325   male 2009\n121        3150 female 2009\n122        3500   male 2009\n123        3450 female 2009\n124        3875   male 2009\n125        3050 female 2009\n126        4000   male 2009\n127        3275 female 2009\n128        4300   male 2009\n129        3050 female 2009\n130        4000   male 2009\n131        3325 female 2009\n132        3500   male 2009\n133        3500 female 2009\n134        4475   male 2009\n135        3425 female 2009\n136        3900   male 2009\n137        3175 female 2009\n138        3975   male 2009\n139        3400 female 2009\n140        4250   male 2009\n141        3400 female 2009\n142        3475   male 2009\n143        3050 female 2009\n144        3725   male 2009\n145        3000 female 2009\n146        3650   male 2009\n147        4250   male 2009\n148        3475 female 2009\n149        3450 female 2009\n150        3750   male 2009\n151        3700 female 2009\n152        4000   male 2009\n153        4500 female 2007\n154        5700   male 2007\n155        4450 female 2007\n156        5700   male 2007\n157        5400   male 2007\n158        4550 female 2007\n159        4800 female 2007\n160        5200   male 2007\n161        4400 female 2007\n162        5150   male 2007\n163        4650 female 2007\n164        5550   male 2007\n165        4650 female 2007\n166        5850   male 2007\n167        4200 female 2007\n168        5850   male 2007\n169        4150 female 2007\n170        6300   male 2007\n171        4800 female 2007\n172        5350   male 2007\n173        5700   male 2007\n174        5000 female 2007\n175        4400 female 2007\n176        5050   male 2007\n177        5000 female 2007\n178        5100   male 2007\n179        4100   &lt;NA&gt; 2007\n180        5650   male 2007\n181        4600 female 2007\n182        5550   male 2007\n183        5250   male 2007\n184        4700 female 2007\n185        5050 female 2007\n186        6050   male 2007\n187        5150 female 2008\n188        5400   male 2008\n189        4950 female 2008\n190        5250   male 2008\n191        4350 female 2008\n192        5350   male 2008\n193        3950 female 2008\n194        5700   male 2008\n195        4300 female 2008\n196        4750   male 2008\n197        5550   male 2008\n198        4900 female 2008\n199        4200 female 2008\n200        5400   male 2008\n201        5100 female 2008\n202        5300   male 2008\n203        4850 female 2008\n204        5300   male 2008\n205        4400 female 2008\n206        5000   male 2008\n207        4900 female 2008\n208        5050   male 2008\n209        4300 female 2008\n210        5000   male 2008\n211        4450 female 2008\n212        5550   male 2008\n213        4200 female 2008\n214        5300   male 2008\n215        4400 female 2008\n216        5650   male 2008\n217        4700 female 2008\n218        5700   male 2008\n219        4650   &lt;NA&gt; 2008\n220        5800   male 2008\n221        4700 female 2008\n222        5550   male 2008\n223        4750 female 2008\n224        5000   male 2008\n225        5100   male 2008\n226        5200 female 2008\n227        4700 female 2008\n228        5800   male 2008\n229        4600 female 2008\n230        6000   male 2008\n231        4750 female 2008\n232        5950   male 2008\n233        4625 female 2009\n234        5450   male 2009\n235        4725 female 2009\n236        5350   male 2009\n237        4750 female 2009\n238        5600   male 2009\n239        4600 female 2009\n240        5300   male 2009\n241        4875 female 2009\n242        5550   male 2009\n243        4950 female 2009\n244        5400   male 2009\n245        4750 female 2009\n246        5650   male 2009\n247        4850 female 2009\n248        5200   male 2009\n249        4925   male 2009\n250        4875 female 2009\n251        4625 female 2009\n252        5250   male 2009\n253        4850 female 2009\n254        5600   male 2009\n255        4975 female 2009\n256        5500   male 2009\n257        4725   &lt;NA&gt; 2009\n258        5500   male 2009\n259        4700 female 2009\n260        5500   male 2009\n261        4575 female 2009\n262        5500   male 2009\n263        5000 female 2009\n264        5950   male 2009\n265        4650 female 2009\n266        5500   male 2009\n267        4375 female 2009\n268        5850   male 2009\n269        4875   &lt;NA&gt; 2009\n270        6000   male 2009\n271        4925 female 2009\n272          NA   &lt;NA&gt; 2009\n273        4850 female 2009\n274        5750   male 2009\n275        5200 female 2009\n276        5400   male 2009\n277        3500 female 2007\n278        3900   male 2007\n279        3650   male 2007\n280        3525 female 2007\n281        3725   male 2007\n282        3950 female 2007\n283        3250 female 2007\n284        3750   male 2007\n285        4150 female 2007\n286        3700   male 2007\n287        3800 female 2007\n288        3775   male 2007\n289        3700 female 2007\n290        4050   male 2007\n291        3575 female 2007\n292        4050   male 2007\n293        3300   male 2007\n294        3700 female 2007\n295        3450 female 2007\n296        4400   male 2007\n297        3600 female 2007\n298        3400   male 2007\n299        2900 female 2007\n300        3800   male 2007\n301        3300 female 2007\n302        4150   male 2007\n303        3400 female 2008\n304        3800   male 2008\n305        3700 female 2008\n306        4550   male 2008\n307        3200 female 2008\n308        4300   male 2008\n309        3350 female 2008\n310        4100   male 2008\n311        3600   male 2008\n312        3900 female 2008\n313        3850 female 2008\n314        4800   male 2008\n315        2700 female 2008\n316        4500   male 2008\n317        3950   male 2008\n318        3650 female 2008\n319        3550   male 2008\n320        3500 female 2008\n321        3675 female 2009\n322        4450   male 2009\n323        3400 female 2009\n324        4300   male 2009\n325        3250   male 2009\n326        3675 female 2009\n327        3325 female 2009\n328        3950   male 2009\n329        3600 female 2009\n330        4050   male 2009\n331        3350 female 2009\n332        3450   male 2009\n333        3250 female 2009\n334        4050   male 2009\n335        3800   male 2009\n336        3525 female 2009\n337        3950   male 2009\n338        3650 female 2009\n339        3650 female 2009\n340        4000   male 2009\n341        3400 female 2009\n342        3775   male 2009\n343        4100   male 2009\n344        3775 female 2009\n\n\n\ntibbles only print 10 rows by default, data.frames a lot more.\ntibbles only print as many columns as possible in one row, which looks a lot cleaner.\nOn top, the tibble shows us how many rows and columns there are in our data.\nNAs are printed in red in tibbles (not in this output, but try it yourself).\nThe data-type of each column is printed on top of the column in tibbles.\n\n\n\n\n\nSave your penguins data.frame and your penguins tibble as .RDS files in a dedicated data folder in your R-project. Use relative paths!\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nsaveRDS(penguins, file = \"./data/penguins.RDS\")\nsaveRDS(penguins_frame, file = \"./data/penguins_frame.RDS\")\n\n\n\n\n\nLoad your penguins data.frame and your penguins tibble into R. Use the here package.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(here)\n\nreadRDS(here::here(\"data\", \"penguins.RDS\"))\nreadRDS(here::here(\"data\", \"penguins_frame.RDS\"))"
  },
  {
    "objectID": "posts/r_sig/24_01_26_tidyverse_intro/index.html#footnotes",
    "href": "posts/r_sig/24_01_26_tidyverse_intro/index.html#footnotes",
    "title": "Introduction to the tidyverse",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Barn Images on Unsplash.↩︎"
  },
  {
    "objectID": "posts/r_sig/23_11_06_renv/index.html",
    "href": "posts/r_sig/23_11_06_renv/index.html",
    "title": "Reproducability with renv",
    "section": "",
    "text": "Package versions will change over time. The same goes for R versions. As a consequence, they might work different in the future, which can make it difficult to reproduce your scripts. Therefore it is considered good practice to note down the package and R-versions you use. The package renv can help you with that."
  },
  {
    "objectID": "posts/r_sig/23_11_06_renv/index.html#motivation",
    "href": "posts/r_sig/23_11_06_renv/index.html#motivation",
    "title": "Reproducability with renv",
    "section": "",
    "text": "Package versions will change over time. The same goes for R versions. As a consequence, they might work different in the future, which can make it difficult to reproduce your scripts. Therefore it is considered good practice to note down the package and R-versions you use. The package renv can help you with that."
  },
  {
    "objectID": "posts/r_sig/23_11_06_renv/index.html#workflow",
    "href": "posts/r_sig/23_11_06_renv/index.html#workflow",
    "title": "Reproducability with renv",
    "section": "Workflow",
    "text": "Workflow\nFirst, initialize the project:\n\n# install.packages(renv)\nrenv::init()\n\nThis mainly will do two things:\n\nCreate a project specific package library, which contains all the packages currently used by the project. This means different projects can use different package versions.\nA .lock file, where the package versions get documented.\n\nBy the way, it doesn’t matter if you do this in the beginning of your project, in between or at the end. renv::init() will automatically setup the project with all the packages you have used in the project.\nThe rest of your workflow is pretty similar to what you are used to: If you need a new package for you project, you install it like you normally would. You can also use renv::install() which has some additional features compared to install.packages()). For example, you can install specific package versions: renv::install(\"dplyr@1.1.1\"). No matter which one you use: The package will be installed into a global cache, and a link to that package will be put into your project specific library. Then you load your package like you normally would with library().\nThe next step is to write the package into your .lock file:\n\nrenv::snapshot()\n\nThis will update the .lock file with your new package.\nIf on the other hand you want to restore the packages from the .lock file, use:\n\nrenv::restore()\n\nThis will install the package version that is documented in the lock file into your project specific library.\nYou can update your dependencies to the latest version using:\n\nrenv::update()\n\nLook here for the offical documentation."
  },
  {
    "objectID": "posts/newsletter/23_08_09/index.html",
    "href": "posts/newsletter/23_08_09/index.html",
    "title": "09-08-2023",
    "section": "",
    "text": "eatGADS\nDie Funktion insertVariable() wurde in relocateVariable() umbenannt. Die Funktion erlaubt die Einsortierung einer Variable innerhalb eines GADSdat-Ojekts, nun auch ganz an den Anfang eines Datensatzes.\nEine neue Funktion, recodeNA2missing(), erlaubt es NAs (in SPSS auch Sysmis genannt) automatisch in spezifische Missing Codes umzuwandeln (z.B. -99 = \"Missing By Design\").\nDie Funktion emptyTheseVariables() erlaubt es nun, mehrere Variablen gleichzeitig zu leeren (= auf NA zu setzen), was z.B. aus Datenschutzgründen relevant sein kann.\nBesonders hervoheben möchten wir an dieser Stelle noch die Funktion fixEncoding(), die es erlaubt, automatisch Umlaute und Sonderzeichen aus Variablennamen, Variablen- und Wertelabeln, sowie Variablen an sich zu entfernen (z.B. “ü” wird zu “ue”).\nDie Dokumentation des Pakets ist nun übrigens leicht einsehbar hier zu finden.\nAlle Änderungen finden sich wie immer erst einmal in der Github-Version des Pakets."
  },
  {
    "objectID": "posts/newsletter/24_01_12/index.html",
    "href": "posts/newsletter/24_01_12/index.html",
    "title": "12-01-2024",
    "section": "",
    "text": "Webseite\nDas Methoden-Team hat jetzt eine eigene Webseite, auf der das gesamte Material vom Methoden-Team gesammelt werden soll. Das betrifft vor allem Tutorials und Workshop-Material, Infos zu den verschiedenen eat-Paketen, Zusammenfassungen aus der R-SIG, den Newsletter und vieles mehr. Aktuell sind wir noch dabei, Material zusammenzutragen, schaut aber gerne schon einmal vorbei:\nhttps://iqb-research.github.io/IQB-Methods/\n\n\nAnsprechpartner:innen während Benjamins Elternzeit\nBenjamin als Hauptverantwortlicher für die folgenden Pakete wird nun temporär durch die genannten Personen als Ansprechpartner:innen bei Problemen und Bugs aber auch Feature Requests u.ä. vertreten:\n\nGADS BT22 - Sebastian\nFDZ Reporting - Nicklas\neatFDZ - Karoline\neatGADS - Philipp\n\n\n\neatTools\nDie Version 0.7.5 liegt nun auf CRAN und beinhaltet hauptsächlich kleinere Bugfixes in den Funktionen halveString() und mergeAttr(). Wenn ihr eine ältere Version habt, ist eine Aktualisierung nicht zwingend notwendig, aber empfehlenswert, u.a., weil damit auch Fehlermeldungen in anderen eat-Paketen etwas instruktiver und leichter verständlich werden."
  },
  {
    "objectID": "posts/r_sig/24_04_08_tidyverse_column_wise/index.html",
    "href": "posts/r_sig/24_04_08_tidyverse_column_wise/index.html",
    "title": "Column-wise operations in the tidyverse",
    "section": "",
    "text": "1\nlibrary(tidyverse)\n\nathletes &lt;- readRDS(file = here::here(  \"raw_data\", \"athletes.rds\"))"
  },
  {
    "objectID": "posts/r_sig/24_04_08_tidyverse_column_wise/index.html#column-wise-operations-with-across",
    "href": "posts/r_sig/24_04_08_tidyverse_column_wise/index.html#column-wise-operations-with-across",
    "title": "Column-wise operations in the tidyverse",
    "section": "Column-wise operations with across()",
    "text": "Column-wise operations with across()\nInstead of looping over columns with a for-loop, we can also use across() in combination with other tidyverse functions.\n\n\n\n\n\n\nmutate_...()\n\n\n\nThe functions mutate_all(), mutate_at(), and mutate_if() do the same, but are superseded. This means they still work, but the tidyverse team recommends to use across() instead.\n\n\nAcross can take column names and a function that should be applied to the selected columns:\n\n## Here we transform the Height and Weight columns to the type character:\nathletes %&gt;%\n  mutate(across(c(Height, Weight), as.character)) %&gt;%\n  str\n\n'data.frame':   270767 obs. of  16 variables:\n $ NOC   : chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ ID    : int  132181 87371 44977 502 109153 29626 1076 121376 80210 87374 ...\n $ Name  : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Mohammad Halilula\" \"Ahmad Shah Abouwi\" ...\n $ Sex   : chr  \"M\" \"M\" \"M\" \"M\" ...\n $ Age   : int  NA NA 28 NA 24 28 28 NA NA NA ...\n $ Height: chr  NA NA \"163\" NA ...\n $ Weight: chr  NA NA \"57\" NA ...\n $ Team  : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ Games : chr  \"1956 Summer\" \"1948 Summer\" \"1980 Summer\" \"1956 Summer\" ...\n $ Year  : int  1956 1948 1980 1956 1964 1960 1936 1956 1972 1956 ...\n $ Season: chr  \"Summer\" \"Summer\" \"Summer\" \"Summer\" ...\n $ City  : chr  \"Melbourne\" \"London\" \"Moskva\" \"Melbourne\" ...\n $ Sport : chr  \"Hockey\" \"Hockey\" \"Wrestling\" \"Hockey\" ...\n $ Event : chr  \"Hockey Men's Hockey\" \"Hockey Men's Hockey\" \"Wrestling Men's Bantamweight, Freestyle\" \"Hockey Men's Hockey\" ...\n $ Medal : chr  NA NA NA NA ...\n $ Region: chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n\n\nBut it is also possible to select columns based on a selection function:\n\n## And here we transform all numeric columns into character:\nathletes %&gt;%\n  mutate(across(where(is.numeric), as.character)) %&gt;%\n  str()\n\n'data.frame':   270767 obs. of  16 variables:\n $ NOC   : chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ ID    : chr  \"132181\" \"87371\" \"44977\" \"502\" ...\n $ Name  : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Mohammad Halilula\" \"Ahmad Shah Abouwi\" ...\n $ Sex   : chr  \"M\" \"M\" \"M\" \"M\" ...\n $ Age   : chr  NA NA \"28\" NA ...\n $ Height: chr  NA NA \"163\" NA ...\n $ Weight: chr  NA NA \"57\" NA ...\n $ Team  : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ Games : chr  \"1956 Summer\" \"1948 Summer\" \"1980 Summer\" \"1956 Summer\" ...\n $ Year  : chr  \"1956\" \"1948\" \"1980\" \"1956\" ...\n $ Season: chr  \"Summer\" \"Summer\" \"Summer\" \"Summer\" ...\n $ City  : chr  \"Melbourne\" \"London\" \"Moskva\" \"Melbourne\" ...\n $ Sport : chr  \"Hockey\" \"Hockey\" \"Wrestling\" \"Hockey\" ...\n $ Event : chr  \"Hockey Men's Hockey\" \"Hockey Men's Hockey\" \"Wrestling Men's Bantamweight, Freestyle\" \"Hockey Men's Hockey\" ...\n $ Medal : chr  NA NA NA NA ...\n $ Region: chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n\n\nWe can also specify our own transformation function."
  },
  {
    "objectID": "posts/r_sig/24_04_08_tidyverse_column_wise/index.html#using-tidyverse-functions-in-loops",
    "href": "posts/r_sig/24_04_08_tidyverse_column_wise/index.html#using-tidyverse-functions-in-loops",
    "title": "Column-wise operations in the tidyverse",
    "section": "Using tidyverse functions in loops",
    "text": "Using tidyverse functions in loops\nWhen using tidyverse syntax within a loop, we might run into the problem that the tidyverse function can’t deal with our iteration counter like we are used to:\n\n## Trying to transform the Height and Weight column to character using a for-loop.\n## Note: Normally across() would be a better option in this case (and most of the time anyways).\n##       But sometimes a good old fashioned for-loop might be easier to programm to get the job done, \n##       in which case one should keep some specifics in mind: \n\n## This throws an error: \nathletes_2 &lt;- athletes\n\nfor(i in c(\"Height\", \"Weight\")){\n  athletes_2 &lt;- athletes_2 %&gt;%\n    mutate(i = as.character(.$i))\n}\n\nThis doesn’t work, because we are trying to program a function using data masking. Data masking just means that we don’t have to type athletes$Height in a tidyverse function, but simply Height, because the function knows this refers to a column in the current data.frame.\n\nLoops\n\nIn the case of mutate(), we have to use dynamic dots, which need to used if we want to create names programmatically: := instead of =.\nWe need to embrace the changeable variable (either in a function or a loop) like this: {var}.\nIn mutate(), we can also simply write \"{var}_...\" to paste together a new column name.\nIf we just want to extract data, we can use the .data pronoun with [[ (see here). .data helps to clear up ambiguity, it makes clear you want to extract a column from the current data.frame. This is something different than the ., which can be read like “data up to this point” and references the data that gets put into the function where the . is used. The . actually stands for a data.frame, while .data is used for symbol evaluation.\n\n\nathletes_2 &lt;- athletes\n\nfor(i in c(\"Height\", \"Weight\")){\n  athletes_2 &lt;- athletes_2 %&gt;%\n    mutate({{i}} := as.character(.[[i]]))\n}\nstr(athletes_2)\n\n'data.frame':   270767 obs. of  16 variables:\n $ NOC   : chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ ID    : int  132181 87371 44977 502 109153 29626 1076 121376 80210 87374 ...\n $ Name  : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Mohammad Halilula\" \"Ahmad Shah Abouwi\" ...\n $ Sex   : chr  \"M\" \"M\" \"M\" \"M\" ...\n $ Age   : int  NA NA 28 NA 24 28 28 NA NA NA ...\n $ Height: chr  NA NA \"163\" NA ...\n $ Weight: chr  NA NA \"57\" NA ...\n $ Team  : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ Games : chr  \"1956 Summer\" \"1948 Summer\" \"1980 Summer\" \"1956 Summer\" ...\n $ Year  : int  1956 1948 1980 1956 1964 1960 1936 1956 1972 1956 ...\n $ Season: chr  \"Summer\" \"Summer\" \"Summer\" \"Summer\" ...\n $ City  : chr  \"Melbourne\" \"London\" \"Moskva\" \"Melbourne\" ...\n $ Sport : chr  \"Hockey\" \"Hockey\" \"Wrestling\" \"Hockey\" ...\n $ Event : chr  \"Hockey Men's Hockey\" \"Hockey Men's Hockey\" \"Wrestling Men's Bantamweight, Freestyle\" \"Hockey Men's Hockey\" ...\n $ Medal : chr  NA NA NA NA ...\n $ Region: chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n\nfor(i in c(\"Height\", \"Weight\")){\n  athletes_2 &lt;- athletes_2 %&gt;%\n    mutate({{i}} := as.character({{i}}))\n}\nstr(athletes_2)\n\n'data.frame':   270767 obs. of  16 variables:\n $ NOC   : chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ ID    : int  132181 87371 44977 502 109153 29626 1076 121376 80210 87374 ...\n $ Name  : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Mohammad Halilula\" \"Ahmad Shah Abouwi\" ...\n $ Sex   : chr  \"M\" \"M\" \"M\" \"M\" ...\n $ Age   : int  NA NA 28 NA 24 28 28 NA NA NA ...\n $ Height: chr  \"Height\" \"Height\" \"Height\" \"Height\" ...\n $ Weight: chr  \"Weight\" \"Weight\" \"Weight\" \"Weight\" ...\n $ Team  : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ Games : chr  \"1956 Summer\" \"1948 Summer\" \"1980 Summer\" \"1956 Summer\" ...\n $ Year  : int  1956 1948 1980 1956 1964 1960 1936 1956 1972 1956 ...\n $ Season: chr  \"Summer\" \"Summer\" \"Summer\" \"Summer\" ...\n $ City  : chr  \"Melbourne\" \"London\" \"Moskva\" \"Melbourne\" ...\n $ Sport : chr  \"Hockey\" \"Hockey\" \"Wrestling\" \"Hockey\" ...\n $ Event : chr  \"Hockey Men's Hockey\" \"Hockey Men's Hockey\" \"Wrestling Men's Bantamweight, Freestyle\" \"Hockey Men's Hockey\" ...\n $ Medal : chr  NA NA NA NA ...\n $ Region: chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n\n## With programmatically built new columns: \nathletes_3 &lt;- athletes\nfor(i in c(\"Height\", \"Weight\")){\n  athletes_3 &lt;- athletes_3 %&gt;%\n    mutate(\"{i}_char\" := as.character(.[[i]]))\n}\n\nstr(athletes_3)\n\n'data.frame':   270767 obs. of  18 variables:\n $ NOC        : chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ ID         : int  132181 87371 44977 502 109153 29626 1076 121376 80210 87374 ...\n $ Name       : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Mohammad Halilula\" \"Ahmad Shah Abouwi\" ...\n $ Sex        : chr  \"M\" \"M\" \"M\" \"M\" ...\n $ Age        : int  NA NA 28 NA 24 28 28 NA NA NA ...\n $ Height     : int  NA NA 163 NA NA 168 NA NA NA NA ...\n $ Weight     : num  NA NA 57 NA 74 73 NA NA 57 NA ...\n $ Team       : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ Games      : chr  \"1956 Summer\" \"1948 Summer\" \"1980 Summer\" \"1956 Summer\" ...\n $ Year       : int  1956 1948 1980 1956 1964 1960 1936 1956 1972 1956 ...\n $ Season     : chr  \"Summer\" \"Summer\" \"Summer\" \"Summer\" ...\n $ City       : chr  \"Melbourne\" \"London\" \"Moskva\" \"Melbourne\" ...\n $ Sport      : chr  \"Hockey\" \"Hockey\" \"Wrestling\" \"Hockey\" ...\n $ Event      : chr  \"Hockey Men's Hockey\" \"Hockey Men's Hockey\" \"Wrestling Men's Bantamweight, Freestyle\" \"Hockey Men's Hockey\" ...\n $ Medal      : chr  NA NA NA NA ...\n $ Region     : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ Height_char: chr  NA NA \"163\" NA ...\n $ Weight_char: chr  NA NA \"57\" NA ...\n\n\nBeware of overwriting the same data.frame you put into mutate()! Otherwise the resulting data.frame will always be overwritten by the old one that always gets put into the function.\n\n\nFunctions\nThis also applies if we want to define a function with column names as arguments, using tidyverse inside. Here we need to embrace our variable as well to make it data masking friendly:\n\n## This doesn't work:\nprint_col &lt;- function(dat, var){\n  print(dat %&gt;% pull(var))\n}\n\nathletes %&gt;%\n  print_col(Region)\n\n\n## This works:\nprint_col &lt;- function(dat, var){\n  print(dat %&gt;% pull({{var}}))\n}\n\nathletes %&gt;%\n  print_col(Region)\n\n    [1] \"Afghanistan\"                      \"Afghanistan\"                     \n    [3] \"Afghanistan\"                      \"Afghanistan\"                     \n    [5] \"Afghanistan\"                      \"Afghanistan\"                     \n    [7] \"Afghanistan\"                      \"Afghanistan\"                     \n...\n\n\n\n\n\n\n\n\n!!sym()\n\n\n\nIn previous SIG-Sessions we have used !!sym() for this, which also works, but is more to remember:\n\nathletes_2 &lt;- athletes\nfor(i in c(\"Height\", \"Weight\")){\n  athletes_2 &lt;- athletes_2 %&gt;%\n    mutate(!!sym(i) := as.character(!!sym(i)))\n}\n\nstr(athletes_2)\n\n'data.frame':   270767 obs. of  16 variables:\n $ NOC   : chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ ID    : int  132181 87371 44977 502 109153 29626 1076 121376 80210 87374 ...\n $ Name  : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Mohammad Halilula\" \"Ahmad Shah Abouwi\" ...\n $ Sex   : chr  \"M\" \"M\" \"M\" \"M\" ...\n $ Age   : int  NA NA 28 NA 24 28 28 NA NA NA ...\n $ Height: chr  NA NA \"163\" NA ...\n $ Weight: chr  NA NA \"57\" NA ...\n $ Team  : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ Games : chr  \"1956 Summer\" \"1948 Summer\" \"1980 Summer\" \"1956 Summer\" ...\n $ Year  : int  1956 1948 1980 1956 1964 1960 1936 1956 1972 1956 ...\n $ Season: chr  \"Summer\" \"Summer\" \"Summer\" \"Summer\" ...\n $ City  : chr  \"Melbourne\" \"London\" \"Moskva\" \"Melbourne\" ...\n $ Sport : chr  \"Hockey\" \"Hockey\" \"Wrestling\" \"Hockey\" ...\n $ Event : chr  \"Hockey Men's Hockey\" \"Hockey Men's Hockey\" \"Wrestling Men's Bantamweight, Freestyle\" \"Hockey Men's Hockey\" ...\n $ Medal : chr  NA NA NA NA ...\n $ Region: chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ..."
  },
  {
    "objectID": "posts/r_sig/24_04_08_tidyverse_column_wise/index.html#footnotes",
    "href": "posts/r_sig/24_04_08_tidyverse_column_wise/index.html#footnotes",
    "title": "Column-wise operations in the tidyverse",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Darryl Low on Unsplash.↩︎"
  },
  {
    "objectID": "posts/r_sig/23_10_09_cleaner/index.html",
    "href": "posts/r_sig/23_10_09_cleaner/index.html",
    "title": "Cleaner Scripts",
    "section": "",
    "text": "Markdown vs. Quarto vs. R-Skripte\n\n\nQuarto is more up to date than R-Markdown\nMarkdown has more dependencies, so I would now use .R-Scripts instead, if I don’t need the markdown features.\nIn the end it’s a question of preference.\n\n\nWrite packages on top of the script.\n\n\nWrite down verion number (use sessionInfo()).\nOr, even better: use renv."
  },
  {
    "objectID": "posts/r_sig/23_10_09_cleaner/index.html#some-general-take-aways",
    "href": "posts/r_sig/23_10_09_cleaner/index.html#some-general-take-aways",
    "title": "Cleaner Scripts",
    "section": "",
    "text": "Markdown vs. Quarto vs. R-Skripte\n\n\nQuarto is more up to date than R-Markdown\nMarkdown has more dependencies, so I would now use .R-Scripts instead, if I don’t need the markdown features.\nIn the end it’s a question of preference.\n\n\nWrite packages on top of the script.\n\n\nWrite down verion number (use sessionInfo()).\nOr, even better: use renv."
  },
  {
    "objectID": "posts/r_sig/24_03_25_tidyverse_wrangling/index.html",
    "href": "posts/r_sig/24_03_25_tidyverse_wrangling/index.html",
    "title": "Data wrangling in the tidyverse",
    "section": "",
    "text": "1\nlibrary(tidyverse)\nThe tidyverse provides many tools for wrangling data, from selecting, sorting or renaming columns over filtering specific rows according to complex conditions to building new columns according to values in other columns. Let’s take a look at the most important ones. We will use the (athletes)[] dataset in the examples:"
  },
  {
    "objectID": "posts/r_sig/24_03_25_tidyverse_wrangling/index.html#select-columns",
    "href": "posts/r_sig/24_03_25_tidyverse_wrangling/index.html#select-columns",
    "title": "Data wrangling in the tidyverse",
    "section": "1 select() columns",
    "text": "1 select() columns\nSelecting columns from a data.frame is pretty straight forward:\n\nathletes %&gt;%\n  select(Year, Sport)\n\n      Year                     Sport\n1     1956                    Hockey\n2     1948                    Hockey\n3     1980                 Wrestling\n...\n\n\nNote how we don’t have to put the columns in \"\", and how we can simply seperate them by ,.\nselect() becomes especially useful when combined with selection helpers:\n\n## Select all columns starting with a Se\nathletes %&gt;%\n  select(starts_with(\"Se\"))\n\n      Sex Season\n1       M Summer\n2       M Summer\n3       M Summer\n...\n\n## Select all columns containing the letters \"ea\"\nathletes %&gt;%\n  select(contains(\"ea\"))\n\n                                         Team Year Season\n1                                 Afghanistan 1956 Summer\n2                                 Afghanistan 1948 Summer\n3                                 Afghanistan 1980 Summer\n...\n\n## Or, we can combine them:\nathletes %&gt;% \n  select(ends_with(\"t\") & contains(\"igh\"))\n\n      Height Weight\n1         NA     NA\n2         NA     NA\n3        163   57.0\n..."
  },
  {
    "objectID": "posts/r_sig/24_03_25_tidyverse_wrangling/index.html#filter-rows",
    "href": "posts/r_sig/24_03_25_tidyverse_wrangling/index.html#filter-rows",
    "title": "Data wrangling in the tidyverse",
    "section": "2 filter() rows",
    "text": "2 filter() rows\nWe can use filter to subset rows according to their values in specific columns:\n\n## All Volleyballers\nathletes %&gt;%\n  filter(Sport == \"Volleyball\") %&gt;%\n  str\n\n'data.frame':   3404 obs. of  16 variables:\n $ NOC   : chr  \"ALG\" \"ALG\" \"ALG\" \"ALG\" ...\n $ ID    : int  122168 73155 47642 74593 74593 117675 249 249 90117 90100 ...\n $ Name  : chr  \"Faza Tsabet\" \"Narimne Madani\" \"Sehryne Hennaoui\" \"Nawal Mansouri\" ...\n...\n\n## All Judoka between 50 and 100 kg\nathletes %&gt;%\n  filter(Sport == \"Judo\", between(Weight, 50, 100)) %&gt;%\n  str()\n\n'data.frame':   2916 obs. of  16 variables:\n $ NOC   : chr  \"AFG\" \"AFG\" \"AFG\" \"ALB\" ...\n $ ID    : int  99303 33817 7050 58601 121096 9593 78883 5689 78882 9593 ...\n $ Name  : chr  \"Friba Razayee\" \"Ajmal Faizzada\" \"Mohammad Tawfiq Bakhshi\" \"Majlinda Kelmendi\" ...\n...\n\n## All athletes with missing height\nathletes %&gt;%\n  filter(is.na(Height)) %&gt;%\n  str()\n\n'data.frame':   60083 obs. of  16 variables:\n $ NOC   : chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ ID    : int  132181 87371 502 109153 1076 121376 80210 87374 6323 59344 ...\n $ Name  : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Ahmad Shah Abouwi\" \"Shakar Khan Shakar\" ...\n...\n\n\nNote how we can just write our conditions without connecting them with & (filter() does that automatically for us). Also, we don’t have to put the column names into ““, because filter() knows that this are column names of the athletes data frame, which makes coding a bit more pleasant. Also, missing rows are automatically removed, which makes sense in many cases!"
  },
  {
    "objectID": "posts/r_sig/24_03_25_tidyverse_wrangling/index.html#pivot_...-longwide-format",
    "href": "posts/r_sig/24_03_25_tidyverse_wrangling/index.html#pivot_...-longwide-format",
    "title": "Data wrangling in the tidyverse",
    "section": "3 pivot_...() long/wide format",
    "text": "3 pivot_...() long/wide format\nTo reshape data.frames from long to wide or wide to long format we can use pivot_wider() and pivot_longer():\nLet’s define a simpler data.frame first:\n\ninhabitants_wide &lt;- data.frame(\n  country = c(\"China\", \"India\", \"USA\"),\n  inhabitants_2021 = c(1425893465, 1407563842, NA),\n  inhabitants_2022 = c(1425857720, 1420939232, 338903174)\n)\ninhabitants_wide\n\n  country inhabitants_2021 inhabitants_2022\n1   China       1425893465       1425857720\n2   India       1407563842       1420939232\n3     USA               NA        338903174\n\n\n\ninhabitants_long &lt;- inhabitants_wide %&gt;%\n  pivot_longer(\n    ## Select the columns we want to reshape:\n    cols = starts_with(\"inhabitants\"),\n    names_prefix = \"inhabitants_\",\n    ## Define a new column where the column names will go to:\n    names_to = \"year\",\n    ## Define a new column where the values will go to:\n    values_to = \"inhabitants\"\n  )\n\nhead(inhabitants_long)\n\n# A tibble: 6 × 3\n  country year  inhabitants\n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt;\n1 China   2021   1425893465\n2 China   2022   1425857720\n3 India   2021   1407563842\n4 India   2022   1420939232\n5 USA     2021           NA\n6 USA     2022    338903174\n\n\nIn other cases, it might happen that multiple variables are put into the same column, together with an identifier column:\n\ninhabitants_long_2\n\n  country         variable      value\n1   China             area    9597000\n2   China inhabitants_2022 1425857720\n3   India             area    3287000\n4   India inhabitants_2022 1420939232\n5     USA             area    9834000\n6     USA inhabitants_2022  338903174\n\n\nIn that case it can make sense to spread the the distinct variables into two columns:\n\ninhabitants_wide_2 &lt;- inhabitants_long_2 %&gt;%\n  pivot_wider(\n    id_cols = \"country\",\n    names_from = \"variable\",\n    values_from = \"value\"\n  )\n\ninhabitants_wide_2\n\n# A tibble: 3 × 3\n  country    area inhabitants_2022\n  &lt;chr&gt;     &lt;dbl&gt;            &lt;dbl&gt;\n1 China   9597000       1425857720\n2 India   3287000       1420939232\n3 USA     9834000        338903174"
  },
  {
    "objectID": "posts/r_sig/24_03_25_tidyverse_wrangling/index.html#mutate",
    "href": "posts/r_sig/24_03_25_tidyverse_wrangling/index.html#mutate",
    "title": "Data wrangling in the tidyverse",
    "section": "4 mutate()",
    "text": "4 mutate()\nWith mutate() we can add new columns to a data.frame or edit existing ones:\n\nathletes %&gt;%\n  mutate(new_column = NA) %&gt;%\n  mutate(ID = as.character(ID)) %&gt;%\n  str()\n\n'data.frame':   270767 obs. of  17 variables:\n $ NOC       : chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ ID        : chr  \"132181\" \"87371\" \"44977\" \"502\" ...\n $ Name      : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Mohammad Halilula\" \"Ahmad Shah Abouwi\" ...\n...\n\n\n\n4.1 Useful helpers\nLike select(), mutate() really starts to shine when helper functions are added. For example we can fill a new column according to values in other columns:\n\n## Build a new column indicating if this is a contact sport athlete\nathletes %&gt;%\n  mutate(contact_sport = ifelse(Sport %in% c(\"Wrestling\", \"Boxing\", \"Judo\", \"Rugby\", \"Taekwondo\", \"Rugby Sevens\"), \n                                yes = TRUE, \n                                no = FALSE)\n         ) %&gt;%\n  select(Name, Sport, contact_sport) %&gt;%\n  str\n\n'data.frame':   270767 obs. of  3 variables:\n $ Name         : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Mohammad Halilula\" \"Ahmad Shah Abouwi\" ...\n $ Sport        : chr  \"Hockey\" \"Hockey\" \"Wrestling\" \"Hockey\" ...\n $ contact_sport: logi  FALSE FALSE TRUE FALSE TRUE TRUE ...\n\n\nIf we have to connect multiple ifelse() functions, it’s better to use dplyrs case_when():\n\n## This gets complicated pretty quickly:\nathletes %&gt;%\n  mutate(judo_weightclass = if_else(str_detect(Event, \"Middleweight\"), \n                                  true = \"Middleweight\", \n                                  false = if_else(str_detect(Event, \"Half-Lightweight\"), \n                                        true = \"Half-Lightweight\", \n                                        false = if_else(str_detect(Event, \"Lightweight\"), \n                                                    true = \"Lightweight\", \n                                                    false = NA)\n                                        ) \n                                        )\n                                  ) %&gt;% \n  filter(Sport == \"Judo\") %&gt;%\n  select(Name, Sport, Event, judo_weightclass) %&gt;%\n  str\n\n'data.frame':   3799 obs. of  4 variables:\n $ Name            : chr  \"Friba Razayee\" \"Ajmal Faizzada\" \"Mohammad Tawfiq Bakhshi\" \"Sergio Murray\" ...\n $ Sport           : chr  \"Judo\" \"Judo\" \"Judo\" \"Judo\" ...\n $ Event           : chr  \"Judo Women's Middleweight\" \"Judo Men's Half-Lightweight\" \"Judo Men's Half-Heavyweight\" \"Judo Men's Middleweight\" ...\n $ judo_weightclass: chr  \"Middleweight\" \"Half-Lightweight\" NA \"Middleweight\" ...\n\n## so do this instead:\nathletes %&gt;%\n  mutate(judo_weightclass = case_when(str_detect(Event, \"Middleweight\") ~ \"Middleweight\", \n                                      str_detect(Event, \"Half-Lightweight\") ~ \"Half-Lightweight\", \n                                      str_detect(Event, \"Lightweight\") ~ \"Lightweight\",\n                                      TRUE ~ \"other Weightclass\" )\n         ) %&gt;%\n  filter(Sport == \"Judo\") %&gt;%\n  select(Name, Sport, Event, judo_weightclass) %&gt;%\n  str()\n\n'data.frame':   3799 obs. of  4 variables:\n $ Name            : chr  \"Friba Razayee\" \"Ajmal Faizzada\" \"Mohammad Tawfiq Bakhshi\" \"Sergio Murray\" ...\n $ Sport           : chr  \"Judo\" \"Judo\" \"Judo\" \"Judo\" ...\n $ Event           : chr  \"Judo Women's Middleweight\" \"Judo Men's Half-Lightweight\" \"Judo Men's Half-Heavyweight\" \"Judo Men's Middleweight\" ...\n $ judo_weightclass: chr  \"Middleweight\" \"Half-Lightweight\" \"other Weightclass\" \"Middleweight\" ...\n\n\n\n\n4.2 Programmatically using mutate()\nIf you want to use mutate() programmatically within a loop or a function, take a look at Column-wise operations in the tidyverse"
  },
  {
    "objectID": "posts/r_sig/24_03_25_tidyverse_wrangling/index.html#replace_...",
    "href": "posts/r_sig/24_03_25_tidyverse_wrangling/index.html#replace_...",
    "title": "Data wrangling in the tidyverse",
    "section": "5 ..._replace_...()",
    "text": "5 ..._replace_...()\nWe can easily replace values in a column using str_replace() or replace_na():\n\nathletes %&gt;%\n  mutate(Sex = str_replace(Sex, \"M\", \"Male\")) %&gt;%\n  mutate(Sex = str_replace(Sex, \"F\", \"Female\")) %&gt;%\n  mutate(Height = replace_na(Height, 0)) %&gt;%\n  select(Sex, Height) %&gt;%\n  str()\n\n'data.frame':   270767 obs. of  2 variables:\n $ Sex   : chr  \"Male\" \"Male\" \"Male\" \"Male\" ...\n $ Height: int  0 0 163 0 0 168 0 0 0 0 ..."
  },
  {
    "objectID": "posts/r_sig/24_03_25_tidyverse_wrangling/index.html#group_by",
    "href": "posts/r_sig/24_03_25_tidyverse_wrangling/index.html#group_by",
    "title": "Data wrangling in the tidyverse",
    "section": "6 group_by()",
    "text": "6 group_by()\nWe can group our data by values in specific columns and perform some sort of operation on the groups. If we wanted to know the number of medals each region has won, we can for example group by region and medal type, and then count() (another tidyverse function) the number of cases in each group:\n\nmedal_counts &lt;- athletes %&gt;%\n  group_by(Region, Medal) %&gt;%\n  count(Medal) \n\nmedal_counts\n\n# A tibble: 533 × 3\n# Groups:   Region, Medal [533]\n   Region         Medal      n\n   &lt;chr&gt;          &lt;chr&gt;  &lt;int&gt;\n 1 Afghanistan    Bronze     2\n 2 Afghanistan    &lt;NA&gt;     124\n 3 Albania        &lt;NA&gt;      70\n 4 Algeria        Bronze     8\n 5 Algeria        Gold       5\n 6 Algeria        Silver     4\n...\n\n\nWe can also summarize() data:\n\n## Let's see what the mean, min and max age of athletes was in each Region:\nathletes %&gt;%\n  group_by(Region) %&gt;%\n      summarize(mean_age = mean(Age, na.rm = TRUE), \n                min_age = min(Age, na.rm = TRUE), \n                max_age = max(Age, na.rm = TRUE)\n                )\n\n# A tibble: 206 × 4\n   Region         mean_age min_age max_age\n   &lt;chr&gt;             &lt;dbl&gt;   &lt;int&gt;   &lt;int&gt;\n 1 Afghanistan        23.5      17      35\n 2 Albania            25.3      16      46\n 3 Algeria            24.4      14      38\n 4 American Samoa     27.2      16      43\n 5 Andorra            23.1      15      61\n 6 Angola             24.9      13      51\n 7 Antigua            23.2      14      38\n..."
  },
  {
    "objectID": "posts/r_sig/24_03_25_tidyverse_wrangling/index.html#join_..-data.frames",
    "href": "posts/r_sig/24_03_25_tidyverse_wrangling/index.html#join_..-data.frames",
    "title": "Data wrangling in the tidyverse",
    "section": "7 ..._join_..() data.frames",
    "text": "7 ..._join_..() data.frames\nWe have multiple options for merging data.frames in the tidyverse. left_join() can be used if we want to keep all rows of the first data.frame and only adds the rows of the second data.frame that have an identifier in the first data.frame, right_join() keeps all rows of the second data frame, and full_join() keeps all rows of both data frames.\nLet’s merge a world coordinate data set onto our medal counts. This can be helpful if we want to plot the number of won medals in each country later on:\n\nworld_coordinates &lt;- readRDS(here::here(\"raw_data\", \"world_coordinates.rds\"))\n\nOnly take gold medals into account:\n\nmedal_counts &lt;- medal_counts %&gt;% filter(Medal == \"Gold\")\n\nTo merge two data frames that include information that belongs together, we need a common column, on which we can combine them. In our case, this is the column containing the country. They are both named region, but one with an upper case R. This doesn’t pose a problem, as we can define which columns should be taken from which data frame for merging with join_by(). Let’s take a quick look before merging to check if there are any countries named differently in both data sets:\n\nmedal_counts$Region[!(medal_counts$Region %in% world_coordinates$region)]\n\n[1] \"Individual Olympic Athletes\"\n\n\nLooks like all of the countries in our medal_countries data frame can also be found in our world_coordinates frame. Only athletes without a country will be lost when merging, but that’s ok for now, as we are interested in the country specific gold medal counts. So let’s merge:\n\nmedal_countries &lt;- world_coordinates %&gt;%\n  left_join(medal_counts, join_by(region == Region))\n\nhead(medal_countries)\n\n       long      lat group order region subregion Medal  n\n1 -69.89912 12.45200     1     1  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n2 -69.89571 12.42300     1     2  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n3 -69.94219 12.43853     1     3  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n4 -70.00415 12.50049     1     4  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n5 -70.06612 12.54697     1     5  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n6 -70.05088 12.59707     1     6  Aruba      &lt;NA&gt;  &lt;NA&gt; NA"
  },
  {
    "objectID": "posts/r_sig/24_03_25_tidyverse_wrangling/index.html#exercise",
    "href": "posts/r_sig/24_03_25_tidyverse_wrangling/index.html#exercise",
    "title": "Data wrangling in the tidyverse",
    "section": "8 Exercise",
    "text": "8 Exercise\n\nRead the characters.rds and the psych_stats.csv into R (download here).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ncharacters &lt;- readRDS(here::here(  \"raw_data\", \"characters.rds\"))\npsych_stats &lt;- read.csv(here::here(  \"raw_data\", \"psych_stats.csv\"), sep = \";\")\n\n\n\n\n\nReshape the psych_stats data frame so there are only three columns in the data set: char_id, question and rating.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can select multiple columns like this: column_1:column_10.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npsych_stats_long &lt;- psych_stats %&gt;%\n  pivot_longer(cols = messy_neat:innocent_jaded, \n               names_to = \"question\", \n               values_to = \"rating\")\n\nhead(psych_stats_long)\n\n# A tibble: 6 × 3\n  char_id question                      rating\n  &lt;chr&gt;   &lt;chr&gt;                          &lt;dbl&gt;\n1 F2      messy_neat                     95.7 \n2 F2      disorganized_self.disciplined  95.2 \n3 F2      diligent_lazy                   6.10\n4 F2      on.time_tardy                   6.2 \n5 F2      competitive_cooperative         6.40\n6 F2      scheduled_spontaneous           6.60\n\n\nNow we have multiple rows for every character, but all question ratings are nicely aligned in one column.\n\n\n\n\nMerge the characters data frame and the psych_stats_long data frame on a common column.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nIdentify the common columns. Are they named the same in both data frames? Look at the documentation of ?join_by() to see, how you can merge data frames that don’t have identically named columns.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFirst, let’s take a look at both data sets again:\n\nstr(characters)\n\n'data.frame':   889 obs. of  7 variables:\n $ id        : chr  \"F2\" \"F1\" \"F5\" \"F4\" ...\n $ name      : chr  \"Monica Geller\" \"Rachel Green\" \"Chandler Bing\" \"Joey Tribbiani\" ...\n $ uni_id    : chr  \"F\" \"F\" \"F\" \"F\" ...\n $ uni_name  : chr  \"Friends\" \"Friends\" \"Friends\" \"Friends\" ...\n $ notability: num  79.7 76.7 74.4 74.3 72.6 51.6 86.5 84.2 82.6 65.6 ...\n $ link      : chr  \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/1\" \"https://openpsychometrics.org/tests/characters/stats/F/5\" \"https://openpsychometrics.org/tests/characters/stats/F/4\" ...\n $ image_link: chr  \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/5.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/4.jpg\" ...\n\nstr(psych_stats)\n\n'data.frame':   889 obs. of  365 variables:\n $ char_id                                     : chr  \"F2\" \"F1\" \"F5\" \"F4\" ...\n $ messy_neat                                  : num  95.7 30.2 45.3 13 20.9 ...\n $ disorganized_self.disciplined               : num  95.2 25.9 42.4 11 20.9 75.6 10.4 31.9 39.6 31.1 ...\n $ diligent_lazy                               : num  6.1 51.8 52.2 78.1 45.2 ...\n $ on.time_tardy                               : num  6.2 77.9 57.1 84.1 74 20.6 85.7 68.3 73.6 58.2 ...\n $ competitive_cooperative                     : num  6.4 28.9 42.8 44.2 55.3 ...\n $ scheduled_spontaneous                       : num  6.6 72.3 54.9 91.3 94.9 ...\n $ ADHD_OCD                                    : num  92.9 31.8 26.7 10.4 12.8 70.1 35.5 30.1 51.8 39.2 ...\n $ chaotic_orderly                             : num  92.2 27 38.2 12.6 11.2 68.8 6.8 20.6 23.4 28.8 ...\n $ motivated_unmotivated                       : num  7.8 31.8 52.3 45.6 24.7 31.5 80.9 30.5 40.8 50.7 ...\n $ bossy_meek                                  : num  7.9 30.6 64.8 60.8 40.1 ...\n $ persistent_quitter                          : num  7.9 35.8 43.9 33.8 21.3 ...\n $ overachiever_underachiever                  : num  8.2 43.8 55.8 68.8 51.3 23.2 67.7 36.7 44.1 44.4 ...\n $ muddy_washed                                : num  91 80.2 58.7 42.7 48.1 64.6 27.6 62.4 70.1 69.2 ...\n $ beautiful_ugly                              : num  9.2 5.3 26.2 11 11.4 ...\n $ slacker_workaholic                          : num  90.8 45.9 53.4 17.6 32 81.5 23.8 30.1 33.2 34.6 ...\n $ driven_unambitious                          : num  9.5 30.3 49.8 49.4 43.4 22.7 58.5 34.1 32 47.4 ...\n $ outlaw_sheriff                              : num  90.3 39.3 46.7 23.8 16.1 85.4 21.4 22.7 27.3 30.1 ...\n $ precise_vague                               : num  9.9 64.7 53.2 78 78.1 25.4 68.4 60.1 47.3 61.7 ...\n $ bad.cook_good.cook                          : num  90 11.1 28.2 31.2 29.4 35.9 27.3 46.2 43.8 52.8 ...\n $ manicured_scruffy                           : num  10.6 7.7 45.6 47.6 62.5 20.5 81.3 37.3 20.3 20.9 ...\n $ lenient_strict                              : num  89.3 34.2 28.8 11 15.4 76.7 15.2 24.2 38.9 21.5 ...\n $ relaxed_tense                               : num  89 58.8 66.4 10.4 16.9 88.9 69.9 64.2 54.5 64.8 ...\n $ demanding_unchallenging                     : num  11 23.9 58.3 66.3 57.1 28.5 35.9 37.8 16.8 60.3 ...\n $ drop.out_valedictorian                      : num  88.9 32.5 47 14.9 22.1 87.7 12.5 29.6 36.5 51.2 ...\n $ go.getter_slugabed                          : num  11.7 31.3 52.6 48.1 27.6 41.8 62.6 33.9 27.3 51.1 ...\n $ competent_incompetent                       : num  11.9 47.1 37.1 77.2 53.6 37.8 51.9 41.1 35.2 56.1 ...\n $ aloof_obsessed                              : num  88.1 62.3 52.3 35.1 33.2 80.8 75.1 54.9 70.7 61.9 ...\n $ flexible_rigid                              : num  87.8 41.8 45.9 17.3 13.9 83.7 45.9 27.4 55 32.1 ...\n $ active_slothful                             : num  12.2 33.1 61.1 56.7 31.4 48.8 73.9 19.8 29.2 35.5 ...\n $ loose_tight                                 : num  87.4 43.2 44.3 14 15.3 82.5 28.1 26 44.8 43.6 ...\n $ pointed_random                              : num  12.8 49.9 67.1 86.2 87.4 36.7 65.4 53.1 36.9 56.2 ...\n $ fresh_stinky                                : num  12.9 14.6 31.9 44.3 39.2 44.3 64.4 30.2 18.2 24.6 ...\n $ dominant_submissive                         : num  13.6 41.6 73.7 40.2 30.9 69.5 43.5 52.6 36.9 77.9 ...\n $ anxious_calm                                : num  13.7 28.8 20 66.1 58 11.9 12 32.1 37.1 29.8 ...\n $ clean_perverted                             : num  13.7 42.5 56.8 77.5 59.4 44 53.1 51.2 61.9 50.6 ...\n $ neutral_opinionated                         : num  86.3 74.6 67.2 43.4 76.6 84.2 67.3 77.9 82.5 43.9 ...\n $ always.down_picky                           : num  85.9 72.6 49.8 27.1 35.2 71.9 23.6 36.2 71.8 36.2 ...\n $ hurried_leisurely                           : num  14.6 55.1 55.9 85.9 81 22.1 48.6 45.6 49 39.3 ...\n $ attractive_repulsive                        : num  14.7 9.4 28.5 15.7 18.2 ...\n $ devoted_unfaithful                          : num  14.8 29.1 22.6 41.5 19.6 47.5 34.1 55.7 42.7 48.2 ...\n $ helpless_resourceful                        : num  85 41.4 56.6 37.9 70.6 52.4 41.4 51.5 36.2 29.8 ...\n $ deliberate_spontaneous                      : num  15.1 71.7 56.5 89.1 92.9 20.9 78.6 88.3 64 60.9 ...\n $ plays.hard_works.hard                       : num  84.7 41.3 46.5 13.7 26 81.2 28.2 30 19.9 26.4 ...\n $ imaginative_practical                       : num  84.7 37.9 54.6 17 5.4 ...\n $ frenzied_sleepy                             : num  15.5 29.9 34.7 55.6 30 31.1 59.4 25.2 19 46 ...\n $ queer_straight                              : num  84.3 84.1 65.4 84.3 45.4 77.9 10.2 4.8 73.4 64.1 ...\n $ assertive_passive                           : num  15.8 40.4 66.3 44.3 39.3 60.9 45.1 45.8 23.4 63.3 ...\n $ fast.talking_slow.talking                   : num  15.9 20.8 18.3 42.2 21.7 49.6 69.5 34.3 32.5 44.5 ...\n $ astonishing_methodical                      : num  83.8 28 49.9 19.2 17.4 83 31.2 27.4 36 32.7 ...\n $ hoarder_unprepared                          : num  16.2 70 63.5 82 54.9 35.5 60.3 64.5 48.3 67.8 ...\n $ consistent_variable                         : num  16.6 60.2 46.3 63.1 79.3 39.5 72 65.3 69.7 62.3 ...\n $ involved_remote                             : num  16.7 26.3 42.7 30.2 36.7 36.6 62.2 39.3 26.4 38.7 ...\n $ backdoor_official                           : num  83.3 51.9 47.4 24.4 20.4 76.4 29.1 29.3 53.5 36.7 ...\n $ captain_first.mate                          : num  16.7 52.7 73.5 74.2 57.9 68.4 55.9 51 19 73.6 ...\n $ refined_rugged                              : num  17.3 18.9 48.4 74.4 69.9 24.4 81.6 48 31.4 40.7 ...\n $ accommodating_stubborn                      : num  82.7 77.2 48.2 43.9 48.3 78.5 78.1 69 85.9 41.5 ...\n $ barbaric_civilized                          : num  82.6 76.5 66.6 32.9 39.9 77 33.4 44.4 36.7 55.5 ...\n $ alpha_beta                                  : num  17.7 37.9 73.9 33.6 41.9 78.2 44.3 37.4 17.5 66.6 ...\n $ loyal_traitorous                            : num  17.8 32.3 20 15.3 14.5 40.3 29.2 43.1 47.2 33.2 ...\n $ trash_treasure                              : num  82 80.1 82.2 78.4 83.2 47.8 64.5 62.2 68.2 78.4 ...\n $ fast_slow                                   : num  18.1 43.7 38.1 69 55.3 60.4 57.8 29.4 30 54.5 ...\n $ perceptive_unobservant                      : num  18.3 59.5 41.5 80 41.1 48.6 21.6 33.3 28 49 ...\n $ goof.off_studious                           : num  81.4 33.2 20.7 7.4 16.6 ...\n $ feminist_sexist                             : num  18.6 23.3 43.9 62 10.5 ...\n $ desperate_high.standards                    : num  81.1 69.2 30.7 36.8 56.7 29.2 33.7 32.5 61.7 25.8 ...\n $ impatient_patient                           : num  18.9 21.9 34 25.7 39.1 25.8 23.8 35.1 18 57.2 ...\n $ preppy_punk.rock                            : num  18.9 16.4 41.5 49.5 73.2 14.4 87.7 74.4 26.4 18.2 ...\n $ naive_paranoid                              : num  80.7 35.5 66.6 22 39.7 71.6 69.6 45.6 50.7 32.1 ...\n $ important_irrelevant                        : num  19.3 22.3 24.6 24.7 26.4 47.4 12.5 14.8 16.4 33.4 ...\n $ apprentice_master                           : num  80.6 42.3 44.9 36.3 61.5 60.8 48 48 73 31.5 ...\n $ healthy_sickly                              : num  19.6 17.8 39.1 26.9 22.6 37 88.9 65.7 56.7 45.5 ...\n $ morning.lark_night.owl                      : num  19.6 69.9 58.3 80.4 61.9 23.2 90.6 81.9 90.1 78.3 ...\n $ alert_oblivious                             : num  19.6 70.7 55.5 87.6 78.9 57.1 54.7 48.9 38.3 67.4 ...\n $ f....the.police_tattle.tale                 : num  80 57.5 56.7 34.4 13.7 ...\n $ experimental_reliable                       : num  79.7 37.8 62 35 22.2 61.7 28 26.5 30.4 39.8 ...\n $ loud_quiet                                  : num  20.4 20.8 25 10.6 15.3 39.5 71.9 42.7 13.2 55.2 ...\n $ high.IQ_low.IQ                              : num  20.5 56.7 28.8 82.6 50.6 19.3 30.9 26.1 47.7 55.6 ...\n $ oppressed_privileged                        : num  79.2 85.4 67.2 66.5 42.1 84.3 22.4 19.6 59.9 63.4 ...\n $ animalistic_human                           : num  79.2 75.6 73.7 43.8 42.1 69.3 70.4 55.9 64.4 73.2 ...\n $ still_twitchy                               : num  79.2 68.6 79.9 76.9 83.6 81.9 77.9 67.4 60.1 58.4 ...\n $ thick_thin                                  : num  78.8 79.6 52.8 35.2 69.2 60.6 73.3 81.4 66.1 48.8 ...\n $ repetitive_varied                           : num  21.3 44.5 40.9 43.4 74.1 18.4 40.1 68.4 47.3 42.1 ...\n $ rational_whimsical                          : num  21.7 72.3 54.4 86.8 93 27.4 67 78.7 69.6 70.9 ...\n $ egalitarian_racist                          : num  21.7 27.8 24.7 24.3 10.7 ...\n $ disreputable_prestigious                    : num  78.2 66.2 47 32.5 36.7 68.2 21.2 42.5 65.2 45.8 ...\n $ ignorant_knowledgeable                      : num  78.2 37.7 66.9 22.2 59.9 68.5 60.8 68.1 44.2 42.6 ...\n $ hard.work_natural.talent                    : num  21.9 47.5 41.8 69.8 71.2 29.2 55.8 67.5 65.8 57.3 ...\n $ androgynous_gendered                        : num  78.1 89.4 68.5 82.5 60.1 78.1 32.6 43.4 88.3 87.9 ...\n $ dispassionate_romantic                      : num  77.9 80.5 64.7 69.6 74.9 67.2 61.5 64.8 59.1 82.3 ...\n $ eloquent_unpolished                         : num  22.1 32.1 56.1 79.8 69 33.7 76.3 45.2 35 42.9 ...\n $ permanent_transient                         : num  22.2 56.1 39 59.6 71.1 31.9 68.5 79.7 57.2 70.6 ...\n $ intense_lighthearted                        : num  22.2 50.8 73.8 79.8 64.2 28.2 22.4 34.7 18.2 44.3 ...\n $ mischievous_well.behaved                    : num  77.8 34.2 30.6 15.8 20.3 71.4 13.3 19.4 17.6 38.2 ...\n $ adventurous_stick.in.the.mud                : num  77.7 37.4 59.7 14.4 8 ...\n $ obedient_rebellious                         : num  22.3 69.2 42.9 72.9 86.2 16.5 92.3 87.1 84.2 38.1 ...\n $ authoritarian_democratic                    : num  22.4 55.2 70 72.1 75.4 41.6 68 67.4 21.8 68.9 ...\n $ city.slicker_country.bumpkin                : num  22.7 9 22.4 18.4 42.6 18.8 26.5 20.2 16.8 24 ...\n $ traditional_unorthodox                      : num  22.8 52.8 54.9 67.2 90 23.1 85.7 90.2 74.5 62.6 ...\n  [list output truncated]\n\n\nIt seems like both data frames have a column containing an ID for the character. We can use that column for merging:\n\ncharacters_stats &lt;- characters %&gt;%\n  right_join(psych_stats_long, join_by(id == char_id))\n\nstr(characters_stats)\n\n'data.frame':   323596 obs. of  9 variables:\n $ id        : chr  \"F2\" \"F2\" \"F2\" \"F2\" ...\n $ name      : chr  \"Monica Geller\" \"Monica Geller\" \"Monica Geller\" \"Monica Geller\" ...\n $ uni_id    : chr  \"F\" \"F\" \"F\" \"F\" ...\n $ uni_name  : chr  \"Friends\" \"Friends\" \"Friends\" \"Friends\" ...\n $ notability: num  79.7 79.7 79.7 79.7 79.7 79.7 79.7 79.7 79.7 79.7 ...\n $ link      : chr  \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/2\" ...\n $ image_link: chr  \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" ...\n $ question  : chr  \"messy_neat\" \"disorganized_self.disciplined\" \"diligent_lazy\" \"on.time_tardy\" ...\n $ rating    : num  95.7 95.2 6.1 6.2 6.4 ...\n\n\n\n\n\n\nRemove all columns from your merged data frame that start with \"uni\". Don’t overwrite your old data, this is just for exercise and won’t be worked with further on.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nTake a look at the examples in ?select to see how you can select all columns but those fulfilling a certain condition.\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\ncharacters_stats %&gt;%\n  select(!starts_with(\"uni\")) %&gt;%\n  str()\n\n'data.frame':   323596 obs. of  7 variables:\n $ id        : chr  \"F2\" \"F2\" \"F2\" \"F2\" ...\n $ name      : chr  \"Monica Geller\" \"Monica Geller\" \"Monica Geller\" \"Monica Geller\" ...\n $ notability: num  79.7 79.7 79.7 79.7 79.7 79.7 79.7 79.7 79.7 79.7 ...\n $ link      : chr  \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/2\" ...\n $ image_link: chr  \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" ...\n $ question  : chr  \"messy_neat\" \"disorganized_self.disciplined\" \"diligent_lazy\" \"on.time_tardy\" ...\n $ rating    : num  95.7 95.2 6.1 6.2 6.4 ...\n\n\n\n\n\n\nCalculate the mean rating of all characters by show and question, so you get the mean rating of all characters in a show on each item.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse group_by() and summarise().\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\ncharacters_summary &lt;- characters_stats %&gt;%\n  group_by(uni_name, question) %&gt;%\n  summarise(mean_rating = mean(rating, na.rm = TRUE))\n\n`summarise()` has grouped output by 'uni_name'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\nChoose two of your favorite shows. Build a data frame that has two mean_rating columns, one for each show.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can get an overview of the used shows with unique(characters_stats$uni_name) First, filter your two shows from the characters_stats data.frame.\nSecond, reshape this data.frame into long format.\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\ncompare_shows &lt;- characters_summary %&gt;%\n  filter(str_detect(uni_name, c(\"Friends|How I Met Your Mother\" ))) %&gt;%\n  pivot_wider(\n    names_from = \"uni_name\",\n    values_from = \"mean_rating\")\n\ncompare_shows\n\n# A tibble: 364 × 3\n   question               Friends `How I Met Your Mother`\n   &lt;chr&gt;                    &lt;dbl&gt;                   &lt;dbl&gt;\n 1 ADHD_OCD                  40.8                    46.6\n 2 Coke_Pepsi                49.2                    48.1\n 3 English_German            26.6                    31.3\n 4 French_Russian            30.7                    38.7\n 5 Greek_Roman               44.0                    47.9\n 6 Italian_Swedish           39.2                    44.5\n 7 abstract_concrete         46.0                    43.6\n 8 accepting_judgemental     52.0                    53.4\n 9 accommodating_stubborn    63.1                    63.6\n10 active_slothful           40.6                    37.0\n# ℹ 354 more rows\n\n\nNow we could look at specific questions. For example the How I Met Your Mother characters seem to be rated a bit more slothful than the Friends characters.\n\n\n\n\nNow, add a column containing the difference in rating between both shows for each question to your new comparison data.frame. Then, sort the rows by descending size of difference between the ratings. So the row with the highest difference in mean rating between your two shows should be on top.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo work with columns within mutate() you could for example use .$column_name.\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\ncompare_shows %&gt;%\n  mutate(diff_shows = .$Friends - .$\"How I Met Your Mother\") %&gt;%\n  arrange(desc(abs(diff_shows)))\n\n# A tibble: 364 × 4\n   question                            Friends How I Met Your Mothe…¹ diff_shows\n   &lt;chr&gt;                                 &lt;dbl&gt;                  &lt;dbl&gt;      &lt;dbl&gt;\n 1 cat.person_dog.person                  46.4                   65.1      -18.6\n 2 musical_off.key                        61.5                   44.8       16.7\n 3 nonpolitical_political                 40.2                   54.7      -14.5\n 4 gamer_non.gamer                        58.6                   44.8       13.8\n 5 focused.on.the.future_focused.on.t…    55.0                   41.8       13.2\n 6 gatherer_hunter                        38.8                   51.2      -12.5\n 7 captain_first.mate                     57.2                   44.9       12.3\n 8 flower.child_goth                      21.5                   33.6      -12.1\n 9 perceptive_unobservant                 48.2                   36.4       11.7\n10 dunce_genius                           46.4                   57.9      -11.4\n# ℹ 354 more rows\n# ℹ abbreviated name: ¹​`How I Met Your Mother`\n\n\ndesc() means descending, so we go from the largest value to the smallest.\nabs() means absolute, so we get the absolute value instead of negative values in some cases."
  },
  {
    "objectID": "posts/r_sig/24_03_25_tidyverse_wrangling/index.html#footnotes",
    "href": "posts/r_sig/24_03_25_tidyverse_wrangling/index.html#footnotes",
    "title": "Data wrangling in the tidyverse",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Bing Copilot↩︎"
  },
  {
    "objectID": "posts/r_sig/23_03_20_forloops/index.html",
    "href": "posts/r_sig/23_03_20_forloops/index.html",
    "title": "for-loops",
    "section": "",
    "text": "1"
  },
  {
    "objectID": "posts/r_sig/23_03_20_forloops/index.html#for-loops",
    "href": "posts/r_sig/23_03_20_forloops/index.html#for-loops",
    "title": "for-loops",
    "section": "For-loops",
    "text": "For-loops\nIn this session we talked about for-loops. Take a look here for the corresponding chapter in a workshop I’ve designed."
  },
  {
    "objectID": "posts/r_sig/23_03_20_forloops/index.html#footnotes",
    "href": "posts/r_sig/23_03_20_forloops/index.html#footnotes",
    "title": "for-loops",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Tine Ivanic on Unsplash.↩︎"
  },
  {
    "objectID": "posts/r_sig/24_03_22_datasets/index.html",
    "href": "posts/r_sig/24_03_22_datasets/index.html",
    "title": "Data sets",
    "section": "",
    "text": "We will use two data sets for some time in the R SIG now. One for the theory, and one for you to work on in the exercises."
  },
  {
    "objectID": "posts/r_sig/24_03_22_datasets/index.html#theory-olympic-athletes",
    "href": "posts/r_sig/24_03_22_datasets/index.html#theory-olympic-athletes",
    "title": "Data sets",
    "section": "1 Theory: Olympic athletes",
    "text": "1 Theory: Olympic athletes\n1\nFor the theory part of the workshop, we will mainly work with the athletes data set. It contains the Olympic athletes from 1896 to 2016, along with some basic stats, their sport and country, and the medals they won.\n\n\n\n\n\n\nGoal\n\n\n\nOur goal for the theory part of this workshop is to find the best country in each sport (operationalized by the number of gold medal winners from this country)."
  },
  {
    "objectID": "posts/r_sig/24_03_22_datasets/index.html#exercises-fictional-characters",
    "href": "posts/r_sig/24_03_22_datasets/index.html#exercises-fictional-characters",
    "title": "Data sets",
    "section": "2 Exercises: Fictional characters",
    "text": "2 Exercises: Fictional characters\n2\nOver the course of this workshop, you can work on exercises to put the theoretical knowledge you acquired in the chapters to use. Most of these exercises will use the characters data set, which contains psychometric ratings for different fictional characters, rated by a large number of people on a personality scale developed by the author of the questionnaire.\nYou will load the data, prepare it for analyses and also plot it in the end.\n\n\n\n\n\n\nGoal\n\n\n\nThe goal for the exercise part of this workshop is to build a character profile for a fictional universe of your choosing.\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe have looked at how to download these data sets in the this exercise."
  },
  {
    "objectID": "posts/r_sig/24_03_22_datasets/index.html#footnotes",
    "href": "posts/r_sig/24_03_22_datasets/index.html#footnotes",
    "title": "Data sets",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Florian Schmetz on Unsplash.↩︎\nImage by Ilse Orsen on Unsplash.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IQB Methods Team",
    "section": "",
    "text": "This website hosts all kind of material around R, programming, statistics and psychological methods."
  },
  {
    "objectID": "docs/eatPackages/eatFDZ.html",
    "href": "docs/eatPackages/eatFDZ.html",
    "title": "eatFDZ",
    "section": "",
    "text": "Info\n\n\n\n\n\ncontact\nlatest version\nsource\n\n\n\n\nBenjamin Becker\nDESCRIPTION on github\ngithub page\n\n\n\n\n\n\nDescription\nAutomated anonymisation of data sets; comparison of pdf documents (e.g. scale manuals) and data sets.\n\n\n\n\n\nDocumentation",
    "crumbs": [
      "R-Sig",
      "eat Packages",
      "eatFDZ"
    ]
  },
  {
    "objectID": "docs/eatPackages/eatRep.html",
    "href": "docs/eatPackages/eatRep.html",
    "title": "eatRep",
    "section": "",
    "text": "Info\n\n\n\n\n\ncontact\nlatest version\nsource\n\n\n\n\nSebastian Weirich, Benjamin Becker\nCRAN page\nCRAN page\n\n\n\n\n\n\nDescription\nCalculates means, standard deviations, variances, frequency tables, percentiles and linear (logistic) regressions, as well as trends for all these analyses in clustered multilevel structures with imputed data. The package implements part of the functionality of the WesVar computer software in R and is mainly relevant for the IQB Bildungstrend studies.\n\n\nDocumentation\n\nA vignette which demonstrates replication analyses with eatRep is here.\nThe internal structure of the package is documented here. This overview is primarily dedicated to developers who want to further improve or extend the package and therefore need to understand its structure.\nWorkshop materials concerning eatRep can also be found on the IQB network drives: i:\\Methoden\\02_IQB-interne_eat_Workshops\\eatRep_2021\\",
    "crumbs": [
      "R-Sig",
      "eat Packages",
      "eatRep"
    ]
  },
  {
    "objectID": "docs/eatPackages/eatCodebook.html",
    "href": "docs/eatPackages/eatCodebook.html",
    "title": "eatCodebook",
    "section": "",
    "text": "Info\n\n\n\n\n\ncontact\nlatest version\nsource\n\n\n\n\nBenjamin Becker\nDESCRIPTION on github\ngithub page\n\n\n\n\n\n\nDescription\nAutomated creation of scale manuals.\n\n\n\n\n\nDocumentation\n\n\n\n\nInfo page with several vignettes",
    "crumbs": [
      "R-Sig",
      "eat Packages",
      "eatCodebook"
    ]
  },
  {
    "objectID": "docs/eatPackages/index.html",
    "href": "docs/eatPackages/index.html",
    "title": "Info on eat Packages",
    "section": "",
    "text": "see table down below and click on the links for more information on a package.",
    "crumbs": [
      "R-Sig",
      "eat Packages",
      "Info on eat Packages"
    ]
  },
  {
    "objectID": "docs/eatPackages/index.html#internal-iqb-r-packages-from-the-eat-family",
    "href": "docs/eatPackages/index.html#internal-iqb-r-packages-from-the-eat-family",
    "title": "Info on eat Packages",
    "section": "internal IQB R packages from the ‘eat’-family",
    "text": "internal IQB R packages from the ‘eat’-family\nIn order to standardise and simplify the evaluation of the VERA pilot studies and the IQB educational trend, a number of R packages with the prefix eat (“educational assessment tools”) are continuously (further) developed. Currently, the following packages are maintained at the IQB:\n\n\n\n\n\npackage name\nbrief description\ncontact\n\n\n\n\neatPrep\nPreparation of data sets.\nKaroline Sachse\n\n\neatModel\nInterface for ConQuest software.\nSebastian Weirich\n\n\neatRep\ncalculates characteristics for data with clustered multi-level structures with imputed data.\nSebastian Weirich, Benjamin Becker\n\n\neatGADS\nImport and data preparation of SPSS data sets in R.\nBenjamin Becker\n\n\neatTools\nVarious help functions that are also required by the packages ‘eatPrep’, ‘eatModel’, ‘eatGADS’ and ‘eatRep’, among others.\nSebastian Weirich, Benjamin Becker, Karoline Sachse\n\n\neatAnalysis\nVarious useful help functions, such as saving Excel files, saving analysis results from lm4 and simulating IRT responses.\nBenjamin Becker, Sebastian Weirich, Karoline Sachse\n\n\neatATA\nAutomated block occupation/automated test booklet creation.\nBenjamin Becker\n\n\neatFDZ\nAutomated anonymisation of data sets, matching of pdf documents (e.g. scale manuals) and data sets.\nBenjamin Becker\n\n\neatCodebook\nAutomated creation of scale manuals.\nBenjamin Becker\n\n\neatRecode\nCreate and apply recoding databases.\nBenjamin Becker, Nicklas Hafiz\n\n\neatPlot\nCreating plots from the eatRep output (main use: Bilduntstrend).\nNicklas Hafiz, Philipp Franikowski",
    "crumbs": [
      "R-Sig",
      "eat Packages",
      "Info on eat Packages"
    ]
  },
  {
    "objectID": "docs/eatPackages/index.html#installing-r-packages",
    "href": "docs/eatPackages/index.html#installing-r-packages",
    "title": "Info on eat Packages",
    "section": "Installing R packages",
    "text": "Installing R packages\nDetailed instructions for installing the R packages can be found here: installing R packages",
    "crumbs": [
      "R-Sig",
      "eat Packages",
      "Info on eat Packages"
    ]
  },
  {
    "objectID": "docs/eatPackages/index.html#compatibility",
    "href": "docs/eatPackages/index.html#compatibility",
    "title": "Info on eat Packages",
    "section": "Compatibility",
    "text": "Compatibility\nMost packages of the “eat” family are not executable in isolation, which means that a package is usually dependent on another package in order to be executable. This means:\n\n“eatTools” is a package with help functions required by other packages. “eatTools” does not depend on other “eat” packages.\neatPrep” requires “eatTools”.\neatRep” needs “eatTools” and “eatGADS”.\neatModel” requires “eatTools” and “eatRep” (and thus also “eatGADS”). The package optionally accesses the computer programme Conquest or the R package “TAM” for parameter estimation. For Conquest, the command line executable is sufficient, e.g. “console_Feb2007.exe”; “TAM” is installed when the package is loaded. “TAM” and Conquest are based on the same statistical measurement model, and overlap considerably in their range of functions.\n“eatGADS” requires “eatTools” and “eatDB”.\n\nThe interdependence also extends to different versions of the packages. For example, old versions of “eatRep” are not always compatible with new versions of “eatTools” (and vice versa). The current package versions (see table above) should be compatible with each other. Usually (but not always) version conflicts are indicated by an error message. It is recommended to always have the latest package versions installed.\nSince individual functions have also changed substantially in the course of the package development, it may no longer be possible to replicate past analyses with new package versions and the identical script (e.g. from the Ländervergleich 2011). In this case, the old script would either have to be adapted or the package versions used at that time would have to be restored.",
    "crumbs": [
      "R-Sig",
      "eat Packages",
      "Info on eat Packages"
    ]
  },
  {
    "objectID": "docs/eatPackages/eatATA.html",
    "href": "docs/eatPackages/eatATA.html",
    "title": "eatATA",
    "section": "",
    "text": "Info\n\n\n\n\n\ncontact\nlatest version\nsource\n\n\n\n\nBenjamin Becker\nCRAN page\nCRAN page\n\n\n\n\n\n\nDescription\nAutomated block occupation/automated test booklet creation.\n\n\n\n\n\nDocumentation\n\n\n\n\ntypical use of ‘eat ATA’: a Minimal Example\n\n\n‘eatATA’ Functionality\n\n\na Pilot Study Example\n\n\nReference manual",
    "crumbs": [
      "R-Sig",
      "eat Packages",
      "eatATA"
    ]
  },
  {
    "objectID": "docs/eatPackages/eatAnalysis.html",
    "href": "docs/eatPackages/eatAnalysis.html",
    "title": "eatAnalysis",
    "section": "",
    "text": "Info\n\n\n\n\n\ncontact\nlatest version\nsource\n\n\n\n\nBenjamin Becker, Sebastian Weirich, Karoline Sachse\nDESCRIPTION on github\ngithub page\n\n\n\n\n\n\nDescription\nVarious useful help functions, such as saving Excel files, saving analysis results from lm4 and simulating IRT responses.\n\n\n\n\n\nDocumentation\n\n\n\n\n-",
    "crumbs": [
      "R-Sig",
      "eat Packages",
      "eatAnalysis"
    ]
  },
  {
    "objectID": "docs/checkmate/checkmate.html",
    "href": "docs/checkmate/checkmate.html",
    "title": "Using Checkmate",
    "section": "",
    "text": "With the checkmate package you can test, check and assert all kinds of arguments regarding type, length and much more. You can also write your own assert-functions.\nIn this Vignette you can get a broad understand how the package works, how the output looks like and some example functions. For more details and a complete overview go to CRAN, specifically the checkmate.pdf or use the following line of code:\n\nlsf.str(\"package:checkmate\")\n\n\n\nInstall the package from CRAN with the following code. Then load it in your library.\n\ninstall.packages(\"checkmate\")\n\n\nlibrary(checkmate)\n\n\n\n\nThere are three main functions that we use: test, check and assert, which do similar things but produce different outputs. All functions have two ways to write them: test_numeric() with an underscore and testNumeric() with a capital Letter, but they both work the same. For simplicity we’ll just use one option.\nTo show the differences in outputs we check arguments for numeric input, as an example. See below to see checks for different types or attributes.\nTest\nTest-functions test whether an argument has certain attributes and gives you TRUE or FALSE output.\n\ntest_numeric(c(6:1, 4))\n\n[1] TRUE\n\ntest_numeric(\"hallo\") \n\n[1] FALSE\n\n\nCheck\nCheck-functions check whether an argument has certain attributes and gives you TRUE or a string containing an error message as an output. In the string you can see what kind of argument you should have given, and what you did wrong.\n\ncheck_numeric(c(6:1, 4))\n\n[1] TRUE\n\ncheck_numeric(\"hallo\") \n\n[1] \"Must be of type 'numeric', not 'character'\"\n\n\nAssert\nAssert-functions assert whether an argument has certain attributes and throw an error message if you it doesn’t. When you did everything correct, it doesn’t create an output. The error message contains the string from the check-functions.\n\nassert_numeric(c(6:1, 4))\nassert_numeric(\"hallo\")\n\nError in eval(expr, envir, enclos): Assertion on '\"hallo\"' failed: Must be of type 'numeric', not 'character'.\n\n\nIf you save an assert_numeric() object into a variable x, it will contain the original object that you asserted.\n\nx &lt;- assert_numeric(c(6:1, 4))\nx\n\n[1] 6 5 4 3 2 1 4\n\n\n\n\n\nWith lsf.str() you can see all functions of the package.\n\nlsf.str(\"package:checkmate\")\n\nYou can check for specific types of arguments e.g. numeric, number, integer, double, character, string, logical, flag, missing, or data structure e.g. list, data_frame, array and so on. You can also look for attributes e.g. true, subset, named or atomic, and much more.\nDepending on what kind of output you want, you choose your function.\n\ncheck_list(list())\n\n[1] TRUE\n\ncheck_list(1:9)\n\n[1] \"Must be of type 'list', not 'integer'\"\n\n\nIf you are looking for a specific function you can use:\n\nls(\"package:checkmate\", pattern = \"atomic\") \n\n[1] \"assert_atomic\"        \"assert_atomic_vector\" \"check_atomic\"        \n[4] \"check_atomic_vector\"  \"expect_atomic\"        \"expect_atomic_vector\"\n[7] \"test_atomic\"          \"test_atomic_vector\"  \n\n\n\n\nIf you want to check the types of elements of a more complex data structure like a list or a data frame, you have to look at the arguments of the functions. Both have the argument types.\nFirst we create an example data frame with rows and columns named. It has numeric and character elements.\n\ndf &lt;- data.frame(klein = 1:3, mittel = 4:6, groß = c(\"7\", \"8\", \"9\"), row.names = c(\"A\", \"B\", \"C\"))\ndf\n\n  klein mittel groß\nA     1      4    7\nB     2      5    8\nC     3      6    9\n\n\nNow we can check for the types of the elements using the types argument. You can look at the whole data frame with df, at single columns using df[1] or df[klein] or at single rows using df[1,]. The error message will tell you the first element that has a type you didn’t check for.\n\n# checking the whole data frame\ncheck_data_frame(df, types = c(\"numeric\", \"character\"))\n\n[1] TRUE\n\ncheck_data_frame(df, types = \"numeric\")\n\n[1] \"May only contain the following types: {numeric}, but element 3 has type 'character'\"\n\n# checking individual columns\ncheck_data_frame(df[1], types = \"numeric\")\n\n[1] TRUE\n\ncheck_data_frame(df[\"klein\"], types = \"numeric\")\n\n[1] TRUE\n\ncheck_data_frame(df[3], types = \"numeric\")\n\n[1] \"May only contain the following types: {numeric}, but element 1 has type 'character'\"\n\n# checking for individual rows\ndf[1,]\n\n  klein mittel groß\nA     1      4    7\n\ncheck_data_frame(df[1,], types = \"numeric\")\n\n[1] \"May only contain the following types: {numeric}, but element 3 has type 'character'\"\n\n\nYou can also check the type of individual elements with df[1,1] or just the content of the columns by loosing the attributes of the data frame with df$klein or df[,1]. In this example they all have type integer. Now check_data_frame() doesn’t work anymore, because the data is no longer a data frame. You can use the normal checks from above.\n\ncheck_data_frame(df$klein, types = \"numeric\")\n\n[1] \"Must be of type 'data.frame', not 'integer'\"\n\ncheck_integer(df$klein)\n\n[1] TRUE\n\ncheck_numeric(df[,1])\n\n[1] TRUE\n\ncheck_double(df[1,1])\n\n[1] \"Must be of type 'double', not 'integer'\"\n\n\n\n\n\nLists work the same way. We create an example list a, with named elements of different types.\n\na &lt;- list(zahlen = 1:9, mon = month.abb, creator = \"IQB\")\nassert_list(a, types = c(\"numeric\", \"character\"))\nassert_character(a$mon)\n\n\n\n\n\nYou can check if an argument is scalar, but you cannot check for arbitrary lengths this way.\n\ncheck_scalar(1)\n\n[1] TRUE\n\ncheck_scalar(1:5)\n\n[1] \"Must have length 1\"\n\nls(\"package:checkmate\", pattern = \"length\")\n\ncharacter(0)\n\n\nTo check for arbitrary length of an argument, you have to use the len argument from the test, check or assert functions.\n\ncheck_character(month.abb, len = 12)\n\n[1] TRUE\n\ncheck_character(month.abb, len = 11)\n\n[1] \"Must have length 11, but has length 12\"\n\n\nThere are some other attributes you can check like this, e.g. min.len, max.len, unique or the length of elements in character vectors using n.chars, min.chars or max.chars.\n\ncheck_character(month.abb, n.chars = 3, min.chars = 2)\n\n[1] TRUE\n\ncheck_character(month.abb, n.chars = 2)\n\n[1] \"All elements must have exactly 2 characters, but element 1 has 3 chararacters\"\n\ncheck_character(month.abb, n.chars = 3, max.chars = 2)\n\n[1] \"All elements must have at most 2 characters, but element 1 has 3 characters\"\n\n\nFor more info what arguments you can check, type ?check_character in the console.\n\n?check_character\n\nYou can also check the lengths of lists or the length of columns/rows of a data frame in a similar way by using our example objects from above.\n\nassert_list(a, len = 3, min.len = 2, max.len = 3)\nassert_data_frame(df, min.cols = 1, max.cols = 3, ncols = 3)\n\n\n\n\nYou cannot check the names of complex objects directly. With the list or data_frame functions you can only check if the objects is named at all, or if the names are unique via the arguments names for lists and col.names or `row.names for data frames. Again using our example objects.\n\n# a &lt;- list(zahlen = 1:9, mon = month.abb, creator = \"IQB\")\n# df &lt;- data.frame(klein = 1:3, mittel = 4:6, groß = c(\"7\", \"8\", \"9\"), row.names = c(\"A\", \"B\", \"C\"))\n\nassert_list(a, names = \"named\")\nassert_data_frame(df, col.names = \"unique\")\n\nYou can check for specific names by using the subset functions. You can check whether the object give the argument choices contains x. If x is not a subset of choices you’ll get an error message.\n\n# lists\ncheck_subset(x = \"mon\", choices = names(a))\n\n[1] TRUE\n\n# data frames\ncheck_subset(c(\"klein\", \"mittel\", \"groß\", \"größer\"), choices = colnames(df))\n\n[1] \"Must be a subset of {'klein','mittel','groß'}, but has additional elements {'größer'}\"\n\n\nYou can also check for unique values or missings in a similar way. For more info see the help functions.\n\n?assert_list\n?assert_data_frame",
    "crumbs": [
      "R-Sig",
      "Asserting Code",
      "Using Checkmate"
    ]
  },
  {
    "objectID": "docs/checkmate/checkmate.html#setup",
    "href": "docs/checkmate/checkmate.html#setup",
    "title": "Using Checkmate",
    "section": "",
    "text": "Install the package from CRAN with the following code. Then load it in your library.\n\ninstall.packages(\"checkmate\")\n\n\nlibrary(checkmate)",
    "crumbs": [
      "R-Sig",
      "Asserting Code",
      "Using Checkmate"
    ]
  },
  {
    "objectID": "docs/checkmate/checkmate.html#different-outputs",
    "href": "docs/checkmate/checkmate.html#different-outputs",
    "title": "Using Checkmate",
    "section": "",
    "text": "There are three main functions that we use: test, check and assert, which do similar things but produce different outputs. All functions have two ways to write them: test_numeric() with an underscore and testNumeric() with a capital Letter, but they both work the same. For simplicity we’ll just use one option.\nTo show the differences in outputs we check arguments for numeric input, as an example. See below to see checks for different types or attributes.\nTest\nTest-functions test whether an argument has certain attributes and gives you TRUE or FALSE output.\n\ntest_numeric(c(6:1, 4))\n\n[1] TRUE\n\ntest_numeric(\"hallo\") \n\n[1] FALSE\n\n\nCheck\nCheck-functions check whether an argument has certain attributes and gives you TRUE or a string containing an error message as an output. In the string you can see what kind of argument you should have given, and what you did wrong.\n\ncheck_numeric(c(6:1, 4))\n\n[1] TRUE\n\ncheck_numeric(\"hallo\") \n\n[1] \"Must be of type 'numeric', not 'character'\"\n\n\nAssert\nAssert-functions assert whether an argument has certain attributes and throw an error message if you it doesn’t. When you did everything correct, it doesn’t create an output. The error message contains the string from the check-functions.\n\nassert_numeric(c(6:1, 4))\nassert_numeric(\"hallo\")\n\nError in eval(expr, envir, enclos): Assertion on '\"hallo\"' failed: Must be of type 'numeric', not 'character'.\n\n\nIf you save an assert_numeric() object into a variable x, it will contain the original object that you asserted.\n\nx &lt;- assert_numeric(c(6:1, 4))\nx\n\n[1] 6 5 4 3 2 1 4",
    "crumbs": [
      "R-Sig",
      "Asserting Code",
      "Using Checkmate"
    ]
  },
  {
    "objectID": "docs/checkmate/checkmate.html#checking-for-type",
    "href": "docs/checkmate/checkmate.html#checking-for-type",
    "title": "Using Checkmate",
    "section": "",
    "text": "With lsf.str() you can see all functions of the package.\n\nlsf.str(\"package:checkmate\")\n\nYou can check for specific types of arguments e.g. numeric, number, integer, double, character, string, logical, flag, missing, or data structure e.g. list, data_frame, array and so on. You can also look for attributes e.g. true, subset, named or atomic, and much more.\nDepending on what kind of output you want, you choose your function.\n\ncheck_list(list())\n\n[1] TRUE\n\ncheck_list(1:9)\n\n[1] \"Must be of type 'list', not 'integer'\"\n\n\nIf you are looking for a specific function you can use:\n\nls(\"package:checkmate\", pattern = \"atomic\") \n\n[1] \"assert_atomic\"        \"assert_atomic_vector\" \"check_atomic\"        \n[4] \"check_atomic_vector\"  \"expect_atomic\"        \"expect_atomic_vector\"\n[7] \"test_atomic\"          \"test_atomic_vector\"  \n\n\n\n\nIf you want to check the types of elements of a more complex data structure like a list or a data frame, you have to look at the arguments of the functions. Both have the argument types.\nFirst we create an example data frame with rows and columns named. It has numeric and character elements.\n\ndf &lt;- data.frame(klein = 1:3, mittel = 4:6, groß = c(\"7\", \"8\", \"9\"), row.names = c(\"A\", \"B\", \"C\"))\ndf\n\n  klein mittel groß\nA     1      4    7\nB     2      5    8\nC     3      6    9\n\n\nNow we can check for the types of the elements using the types argument. You can look at the whole data frame with df, at single columns using df[1] or df[klein] or at single rows using df[1,]. The error message will tell you the first element that has a type you didn’t check for.\n\n# checking the whole data frame\ncheck_data_frame(df, types = c(\"numeric\", \"character\"))\n\n[1] TRUE\n\ncheck_data_frame(df, types = \"numeric\")\n\n[1] \"May only contain the following types: {numeric}, but element 3 has type 'character'\"\n\n# checking individual columns\ncheck_data_frame(df[1], types = \"numeric\")\n\n[1] TRUE\n\ncheck_data_frame(df[\"klein\"], types = \"numeric\")\n\n[1] TRUE\n\ncheck_data_frame(df[3], types = \"numeric\")\n\n[1] \"May only contain the following types: {numeric}, but element 1 has type 'character'\"\n\n# checking for individual rows\ndf[1,]\n\n  klein mittel groß\nA     1      4    7\n\ncheck_data_frame(df[1,], types = \"numeric\")\n\n[1] \"May only contain the following types: {numeric}, but element 3 has type 'character'\"\n\n\nYou can also check the type of individual elements with df[1,1] or just the content of the columns by loosing the attributes of the data frame with df$klein or df[,1]. In this example they all have type integer. Now check_data_frame() doesn’t work anymore, because the data is no longer a data frame. You can use the normal checks from above.\n\ncheck_data_frame(df$klein, types = \"numeric\")\n\n[1] \"Must be of type 'data.frame', not 'integer'\"\n\ncheck_integer(df$klein)\n\n[1] TRUE\n\ncheck_numeric(df[,1])\n\n[1] TRUE\n\ncheck_double(df[1,1])\n\n[1] \"Must be of type 'double', not 'integer'\"\n\n\n\n\n\nLists work the same way. We create an example list a, with named elements of different types.\n\na &lt;- list(zahlen = 1:9, mon = month.abb, creator = \"IQB\")\nassert_list(a, types = c(\"numeric\", \"character\"))\nassert_character(a$mon)",
    "crumbs": [
      "R-Sig",
      "Asserting Code",
      "Using Checkmate"
    ]
  },
  {
    "objectID": "docs/checkmate/checkmate.html#checking-for-length",
    "href": "docs/checkmate/checkmate.html#checking-for-length",
    "title": "Using Checkmate",
    "section": "",
    "text": "You can check if an argument is scalar, but you cannot check for arbitrary lengths this way.\n\ncheck_scalar(1)\n\n[1] TRUE\n\ncheck_scalar(1:5)\n\n[1] \"Must have length 1\"\n\nls(\"package:checkmate\", pattern = \"length\")\n\ncharacter(0)\n\n\nTo check for arbitrary length of an argument, you have to use the len argument from the test, check or assert functions.\n\ncheck_character(month.abb, len = 12)\n\n[1] TRUE\n\ncheck_character(month.abb, len = 11)\n\n[1] \"Must have length 11, but has length 12\"\n\n\nThere are some other attributes you can check like this, e.g. min.len, max.len, unique or the length of elements in character vectors using n.chars, min.chars or max.chars.\n\ncheck_character(month.abb, n.chars = 3, min.chars = 2)\n\n[1] TRUE\n\ncheck_character(month.abb, n.chars = 2)\n\n[1] \"All elements must have exactly 2 characters, but element 1 has 3 chararacters\"\n\ncheck_character(month.abb, n.chars = 3, max.chars = 2)\n\n[1] \"All elements must have at most 2 characters, but element 1 has 3 characters\"\n\n\nFor more info what arguments you can check, type ?check_character in the console.\n\n?check_character\n\nYou can also check the lengths of lists or the length of columns/rows of a data frame in a similar way by using our example objects from above.\n\nassert_list(a, len = 3, min.len = 2, max.len = 3)\nassert_data_frame(df, min.cols = 1, max.cols = 3, ncols = 3)",
    "crumbs": [
      "R-Sig",
      "Asserting Code",
      "Using Checkmate"
    ]
  },
  {
    "objectID": "docs/checkmate/checkmate.html#checking-names-via-subset",
    "href": "docs/checkmate/checkmate.html#checking-names-via-subset",
    "title": "Using Checkmate",
    "section": "",
    "text": "You cannot check the names of complex objects directly. With the list or data_frame functions you can only check if the objects is named at all, or if the names are unique via the arguments names for lists and col.names or `row.names for data frames. Again using our example objects.\n\n# a &lt;- list(zahlen = 1:9, mon = month.abb, creator = \"IQB\")\n# df &lt;- data.frame(klein = 1:3, mittel = 4:6, groß = c(\"7\", \"8\", \"9\"), row.names = c(\"A\", \"B\", \"C\"))\n\nassert_list(a, names = \"named\")\nassert_data_frame(df, col.names = \"unique\")\n\nYou can check for specific names by using the subset functions. You can check whether the object give the argument choices contains x. If x is not a subset of choices you’ll get an error message.\n\n# lists\ncheck_subset(x = \"mon\", choices = names(a))\n\n[1] TRUE\n\n# data frames\ncheck_subset(c(\"klein\", \"mittel\", \"groß\", \"größer\"), choices = colnames(df))\n\n[1] \"Must be a subset of {'klein','mittel','groß'}, but has additional elements {'größer'}\"\n\n\nYou can also check for unique values or missings in a similar way. For more info see the help functions.\n\n?assert_list\n?assert_data_frame",
    "crumbs": [
      "R-Sig",
      "Asserting Code",
      "Using Checkmate"
    ]
  },
  {
    "objectID": "docs/R/ws1.html",
    "href": "docs/R/ws1.html",
    "title": "R Workshop Einführung",
    "section": "",
    "text": "R ist eine Programmiersprache für Datenmanipulation, statistische Datenanalyse und grafische Darstellung von Daten (Yanada, 2018).\nDatenmanipulation:\n\nImport und Export: Einlesen und Schreiben von SPSS-, Excel-, ASCII- oder trennzeichenbasierten Dateien\nKopieren, verschieben, löschen, packen und entpacken von Dateien und Verzeichnissen\nVariablen- und Fallselektion, Rekodieren/Aggregieren von Variablen\nUmstrukturieren von Datensätzen (long/wide)\nManipulation von Zeichenketten (Verknüpfen, extrahieren, ersetzen, z.B. auch mithilfe regulärer Ausdrücke: sehr mächtig, aber zuweilen kompliziert)\n\nstatistische Datenanalyse:\n\nlineare und nichtlineare Regression\nVarianzanalyse\nStrukturgleichungsmodelle\nMehrebenenanalyse\nMultiple Imputation\nItem-Response-Modelle\ndecision trees\nmixed models, u.v.m.\n\ngrafische Darstellung von Daten:\n\nBoxplots\nHistogramme\nHeat Maps",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Einführung"
    ]
  },
  {
    "objectID": "docs/R/ws1.html#einleitung",
    "href": "docs/R/ws1.html#einleitung",
    "title": "R Workshop Einführung",
    "section": "",
    "text": "R ist eine Programmiersprache für Datenmanipulation, statistische Datenanalyse und grafische Darstellung von Daten (Yanada, 2018).\nDatenmanipulation:\n\nImport und Export: Einlesen und Schreiben von SPSS-, Excel-, ASCII- oder trennzeichenbasierten Dateien\nKopieren, verschieben, löschen, packen und entpacken von Dateien und Verzeichnissen\nVariablen- und Fallselektion, Rekodieren/Aggregieren von Variablen\nUmstrukturieren von Datensätzen (long/wide)\nManipulation von Zeichenketten (Verknüpfen, extrahieren, ersetzen, z.B. auch mithilfe regulärer Ausdrücke: sehr mächtig, aber zuweilen kompliziert)\n\nstatistische Datenanalyse:\n\nlineare und nichtlineare Regression\nVarianzanalyse\nStrukturgleichungsmodelle\nMehrebenenanalyse\nMultiple Imputation\nItem-Response-Modelle\ndecision trees\nmixed models, u.v.m.\n\ngrafische Darstellung von Daten:\n\nBoxplots\nHistogramme\nHeat Maps",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Einführung"
    ]
  },
  {
    "objectID": "docs/R/ws1.html#r-als-taschenrechner",
    "href": "docs/R/ws1.html#r-als-taschenrechner",
    "title": "R Workshop Einführung",
    "section": "2. R als Taschenrechner",
    "text": "2. R als Taschenrechner\nIn der R Konsole kann man (mathematische) Funktionen eingeben und sie evaluieren lassen. Im einfachsten Fall funktioniert das wie ein Taschenrechner.\n\n2+3\n\n[1] 5\n\n2*3\n\n[1] 6\n\n\nDas Dezimaltrennzeichen in R ist ein Punkt, kein Komma.\n\n5/4\n\n[1] 1.25\n\n\nExponentialschreibweise:\n\n2^3\n\n[1] 8\n\n\nObwohl es nicht so aussieht, werden bei diesen Operationen im Hintergrund Funktionen ausgeführt. So kann man sich beispielsweise die Wurzel aus 2 einfach in Exponentialschreibweise oder mithilfe der Wurzelfunktion ausgeben lassen:\n\n2^0.5\n\n[1] 1.414214\n\n\nWurzelfunktion:\n\nsqrt(2)\n\n[1] 1.414214\n\n\nAllgemein gilt auch in R: “Punktrechnung vor Strichrechnung”:\n\n2*3+1\n\n[1] 7\n\n2*(3+1)\n\n[1] 8",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Einführung"
    ]
  },
  {
    "objectID": "docs/R/ws1.html#grundlagen",
    "href": "docs/R/ws1.html#grundlagen",
    "title": "R Workshop Einführung",
    "section": "3. Grundlagen",
    "text": "3. Grundlagen\nR ist zugleich eine Sprache und eine Umgebung für statistische Datenbearbeitung. R ist objektbasiert. Alles in R ist ein Objekt: Zahlen, Vektoren, Matrizen, Funktionen. Das grundlegende Funktionsprinzip ist dabei: “Definiere ein Objekt und weise ihm einen Wert zu.” Im einfachsten Fall wird im folgenden Beispiel das Objekt b erzeugt und ihm der Wert 2 zugewiesen. Um sich den Wert von b anzeigen zu lassen, kann man b einfach in die Konsole tippen:\n\nb &lt;- 2\nb\n\n[1] 2\n\n\nb** ist nun intern gespeichert und kann ebenfalls für Zuweisungen benutzt werden. Hier wird ein neues Objekt d erzeugt und ihm als Wert die Quadratwurzel von b zugewiesen:\n\nd &lt;- sqrt(b)\n\nMöglich ist es auch, b wieder mit einem anderen Wert zu überschreiben:\n\nb &lt;- 100 * b\nb\n\n[1] 200\n\n\nMit dem Befehl class kann man sich die Klasse von b anzeigen lassen.\n\nclass(b)\n\n[1] \"numeric\"\n\n\nDie wichtigsten Klassen für skalare Objekt (also solche, die nur aus einem einzigen Element bestehen), sind\n\nnumeric: reelle Ziffer oder Zahlen\ncharacter: Zeichenkette\nlogical: logischer Wert, der nur zwei Zustände annehmen kann, TRUE oder FALSE\n\nIm folgenden verschiedene Beispiele für character- bzw. logische Zuweisungen, hier jeweils wiederum nur für die Länge 1. Zuweisungen der Klasse character erfolgen mit hochgestellten Anführungszeichen:\n\nd &lt;- \"hallo\"\nclass(d)\n\n[1] \"character\"\n\nlength(d)\n\n[1] 1\n\n\nWenn einem Objekt die Zahl 220 in hochgestellten Anführungszeichen zugewiesen wird, wird der Wert nicht als numerisch, sondern als character behandelt:\n\ne &lt;- \"220\"\nclass(e)\n\n[1] \"character\"\n\n\nWenn einem Objekt der Austruck TRUE in hochgestellten Anführungszeichen zugewiesen wird, wird der Wert nicht als logical, sondern als character behandelt:\n\nf &lt;- TRUE\nclass(f)\n\n[1] \"logical\"\n\ng &lt;- \"TRUE\"\nclass(g)\n\n[1] \"character\"\n\n\n\n3.1 Vektoren\nVektoren sind definiert als eine Reihe von Elementen derselben Klasse. Sie können unter anderem mit der Funktion c() erzeugt werden:\n\na &lt;- c(1,4,2,2,89)\nb &lt;- c(\"gut\", \"schlecht\")\nd &lt;- c(TRUE, TRUE, TRUE, FALSE, TRUE, TRUE)\n\nÄhnlich wie in den vorher aufgeführten Beispielen kann man sich mit verschiedenen Befehlen verschiedene Eigenschaften dieser Vektoren zeigen lassen, etwa ihre Länge (= die Anzahl ihrer Elemente) mit length(), oder ihre Klasse mit class(). Bestimmte Funktionen wiederum kann man sinnvoll nur für numerische Vektoren anweden (z.B. sum(), mean(), min(), max() etc. Andere wiederum sind nur für Vektoren der Klasse character sinnvoll, etwa nchar(), das einem die Anzahl der Zeichen einer Zeichenkette gibt. Ganz allgemein gilt: Funktionen, die man auf Skalare anwenden kann, kann man in der Regel auch auf Vektoren anwenden:\n\nskalar &lt;- 2\nsqrt(skalar)\n\n[1] 1.414214\n\nvektor &lt;- c(1,4,2,2,89)\nsqrt(vektor)\n\n[1] 1.000000 2.000000 1.414214 1.414214 9.433981\n\n\nDie Funktion sqrt gibt dabei genauso viele Elemente zurück, wie der Vektor besitzt, den man der Funktion übergeben hat. Das ist nicht bei allen Funktionen so; die mean-Funktion gibt (sinnvollerweise) immer nur ein Element zurück.\n\nskalar &lt;- 2\nmean(skalar)\n\n[1] 2\n\nvektor &lt;- c(1,4,2,2,89)\nmean(vektor)\n\n[1] 19.6\n\n\nWas passiert, wenn man Vektoren “unzulässig” definiert, also beispielsweise die Regel, dass alle Elemente dieselbe Klasse haben müssen, missachtet? Vektoren werden in die “kleinste gemeinsame Klasse” umgewandelt. Es gibt hier keine Warnmeldung, und manchmal führt das zu unerwünschten Nebenwirkungen. Zuerst betrachten wir einen Vektor, der aus Elementen der Klasse numeric, character und logical besteht:\n\nb &lt;- c(1,6,\"hallo\",TRUE,11,FALSE)\nb\n\n[1] \"1\"     \"6\"     \"hallo\" \"TRUE\"  \"11\"    \"FALSE\"\n\n\nDer gesamte Vektor wird als character definiert:\n\nclass(b)\n\n[1] \"character\"\n\n\nBesteht der Vektor nur aus Elementen der Klassen numeric und logical, wird der Vektor als numeric definiert:\n\nb &lt;- c(1,6,TRUE,11,FALSE)\nb\n\n[1]  1  6  1 11  0\n\nclass(b)\n\n[1] \"numeric\"\n\n\nAn diesen Bespielen erkennt man prototypisch, wie R sich bei “widersinnigen” Benutzereingaben verhält: Anstatt bei formal falschen oder unsinnigen Eingaben wie nchar(15) eine Fehlermeldung auszugeben, wird versucht zu “antizipieren”, was der Benutzer gemeint oder beabsichtigt haben könnte. Bei nchar(15) wird also zunächst der numerische Ausdruck in einen character-Ausdruck umgewandelt und anschließend die Anzahl der Zeichen dieses Ausdrucks ausgegeben. Intern wertet R statt nchar(15) folgenden Ausdruck aus: nchar(\"15\") bzw. nchar(as.character(15)). Ein solches oder ähnliches Verhalten wendet R in unzähligen Fällen an, und daraus ergeben sich zugleich Vor- und Nachteile: es erlaubt dem Anwender, syntaktisch “unsauberen” Code zu verwenden, ohne dass es zu Fehlermeldungen kommt. In der Regel erhält man das gewünschte Ergebnis. Außerdem kann man R-Syntaxen teils sehr sparsam und “schreibfaul” erstellen; nchar(15) ist ja viel kürzer als nchar(as.character(15)). Dass R diese Nachlässigkeiten erlaubt, hat aber auch Nachteile: die syntaktische Logik der R-Sprache ist dadurch weniger transparent, und falls es doch zu Fehlermeldungen kommt, sind diese erstmal weniger verständlich.\nAlternative Möglichkeiten, Vektoren zu erzeugen. Alle Zahlen von 1 bis 20:\n\na &lt;- 1:20\n\nErzeuge eine Zahlenreihe von -2 bis +2 in Intervallen von 0.2:\n\na &lt;- seq(-2,2,0.2) \n\nRepliziere die Ziffer 4 dreimal:\n\na &lt;- rep(4,3)\n\nRepliziere die Zahlenfolge von 1 bis 4 dreimal:\n\na &lt;- rep(1:4,3)\n\nRepliziere in der Zahlenfolge von 1 bis 4 jede einzelne Ziffer dreimal:\n\na &lt;- rep(1:4,each=3)\n\nRepliziere in der Zahlenfolge von 1 bis 4 jede einzelne Ziffer dreimal, und repliziere den egsamten Vektor zweimal:\n\na &lt;- rep(1:4,each=3, times = 2)\n\nRepliziere in der Zahlenfolge von 1 bis 4 die 1 einmal, die 2 zweimal, die 3 dreimal, etc.:\n\na &lt;- rep(1:4,1:4)\n\n\n\n3.2 Navigation in Vektoren (subsetting)\nMithilfe eckiger Klammern kann man sich einzelne Elemente eines Vektors anzeigen lassen oder auch verändern.\n\nb &lt;- sqrt(1:5)\n\nDer gesamte Vektor b besteht aus fünf Zahlen:\n\nb\n\n[1] 1.000000 1.414214 1.732051 2.000000 2.236068\n\n\nMit b[2] kann man sich nur das zweite Element des Vektors anzeigen lassen; mit b[2] &lt;- 1000 kann man das zweite Element durch die Zahl 1000 ersetzen:\n\nb[2] &lt;- 1000\nb\n\n[1]    1.000000 1000.000000    1.732051    2.000000    2.236068\n\n\nMit b[4:5] &lt;- c(400, 500) kann man das vierte und fünfte Element durch die Zahlen 400 und 500 ersetzen:\n\nb[4:5] &lt;- c(400, 500)\nb\n\n[1]    1.000000 1000.000000    1.732051  400.000000  500.000000\n\n\nHier ein weiteres Beispiel für ein syntaktisch “fehlerhaftes” Subsetting, das trotzdem funktioniert. Man würde erwarten, dass b[4:5] &lt;- 45 eine Fehlermeldung gibt: zwei Elemente in einem Vektor sollen durch eine Zahl ersetzt werden. Die “sauberere” Lösung wäre b[4:5] &lt;- c(45, 45). Dennoch funktionier auch b[4:5] &lt;- 45:\n\nb[4:5] &lt;- 45\nb\n\n[1]    1.000000 1000.000000    1.732051   45.000000   45.000000\n\n\nWeitere “unzulässige” Operationen haben wieder denselben Effekt wie oben beschrieben. Ersetze ich ein Element des numerischen Vektors durch ein character-Element, wird der gesamte Vektor ebenfalls nach character umgewandelt.\n\nb[1] &lt;- \"hallo\"\nclass(b)\n\n[1] \"character\"\n\nb\n\n[1] \"hallo\"            \"1000\"             \"1.73205080756888\" \"45\"              \n[5] \"45\"              \n\n\n\n\n3.3 Funktionsliste I: Deskriptive Statistiken für numerische Vektoren\nAlle Funktionen, die sich sinnvoll auf numerische Vektoren anwenden lassen, können hier in ihrer Vollständigkeit nicht aufgeführt werden. Im Folgenden sollen jedoch die gebräuchlichsten und am häufigsten verwendeten aufgelistet werden:\n\nsum(). Berechnet die Summe aller Elemente eines Vektors. Nicht definiert für nicht-numerische Vektoren.\nmean(). Arithmetischer Mittelwert aller Elemente eines Vektors. Nicht definiert für nicht-numerische Vektoren.\nsd(). Standardabweichung\nvar(). Varianz\nmin(). Minimum\nmax(). Maximum\nscale(). Funktion zum Zentrieren oder z-Standardisieren. Die Funktion besitzt zusätzliche Argumente, je nachdem ob standardisiert oder nur zentriert werden soll. Für die zusätzlichen Argumente sind Standardeinstellungen (defaults) definiert – also “Voreinstellungen” der Argumente, die benutzt werden, wenn der Anwender die Funktionsargumente selbst nicht explizit definiert. Ein Vektor a &lt;- rnorm(100, mean = 2, sd = 8) mit Mittelwert 2 und Standardabweichung 8 wird mit scale(a, center = TRUE, scale = FALSE) zentriert und mit scale(a, center = TRUE, scale = TRUE) standardisiert. (Bei scale(a, center = FALSE, scale = FALSE) passiert einfach gar nichts; der Vektor wird 1:1 so zurückgegeben, wie er war.)\ntable() gibt eine Häufigkeitsverteilung aller Werte eines Vektors. Das ist sowohl für numerische als auch für nicht-numerische Vektoren möglich und für letztere häufig sinnvoller.\nsort(). Elemente auf- oder absteigend sortieren. Geht auch für nicht-numerische Vektoren (bei character-Vektoren wird in diesem Fall sortiert, bei Faktoren nach Ordnung der factor levels). Auch sort() enthält zusätzliche Argumente mit Voreinstellungen, z.B. das Argument decreasing, das angibt, ob auf- oder absteigend sortiert werden soll. Der default ist hier decreasing = FALSE; es wird also standardmäßig aufsteigend sortiert.\norder() funktioniert ähnlich wie sort(), gibt aber anstelle des Vektor-Wertes die Position zurück. Am einfachsten lässt sich das mit einem character-Vektor veranschaulichen – hier erkennt man auch, dass verschiedene R-Funktionen zueinander häufig redundant sind; es gibt verschiedene syntaktische Möglichkeiten, ein und dasselbe Ergebnis zu erhalten. Das macht R zum einen recht flexibel, zum anderen nicht unbedingt übersichtlich.\n\n\nvek &lt;- c(\"oh\", \"je\", \"mi\", \"neh\")\nsort(vek)\n\n[1] \"je\"  \"mi\"  \"neh\" \"oh\" \n\norder(vek)\n\n[1] 2 3 4 1\n\nvek[order(vek)]\n\n[1] \"je\"  \"mi\"  \"neh\" \"oh\" \n\n\n\nrev() kehrt die Reihenfolge der Elemente eines Vektors um\nunique() zeigt die Elemente des Vektors und lässt alle mehrfach vorhandenen Werte aus.\nduplicated() gibt einen logischen Vektor zurück, der für jedes Element anzeigt, ob es einzigartig ist (FALSE) oder mindestens zweimal vorkommt (TRUE)\nwhich() gibt zurück, an welcher Stelle (oder welchen Stellen) eines Vektors sich ein bestimmtes Element befindet, z.B. which(x == 5), oder eine bestimmte Bedingung erfüllt ist which(x &gt; 5), oder which(x != 5)\n\nDas sind, wie gesagt, bei weitem nicht alle Funktionen für numerische Vektoren. Wenn man eine bestimmte Operation durchführen möchte und den R-Befehl nicht kennt, hilft es häufig, die gewünschte Operation bei Google mit dem Zusatz “R” oder “R CRAN” einzugeben, vorzugsweise in englisch, z.B. “R sort by more than one variable”.\n\n\n3.4 Funktionsliste II: Bearbeiten von character-Vektoren\nIm Anwendungsfall von Large-scale Assessments im Bildungsforschungsbereich kommen character-Vektoren bspw. in Variablen- oder Itemnamen vor. Weniger häufig begegnet man ihnen unter anderem auch in Freitextfeldern in Schülerfragebögen. R bietet zahlreiche Möglichkeiten zur Bearbeitung von character-Vektoren, die auch reguläre Ausdrücke einschließen. Hier sollen nur die wichtigsten anhand prominenter Anwendungsfälle genannt werden. Man könnte sich beispielsweise vorstellen, in einem großen Datensatz mit vielen Variablen bestimmte Spalten oder Variablen identifizieren beziehungsweise verändern zu wollen. Der beispielhaft verwendete Vektor mit Variablennamen sei der folgende:\n\nvarnamen &lt;- c(\"idstud\", \"idclass\", \"D10101a\", \"D10102a\", \"D10102b\", \"D10103a\", \"D10201a\", \"D10301\", \"sex\", \"M15511a\", \"M15612a\", \"M15712b\", \"M15712c\", \"M15712d\", \"hisced\", \"parid\")\n\nInsgesamt gibt es hier nur 14 Variablen – in großen Large-scale Datensätzen hat man es ja zuweilen mit 1000 variablen und mehr zu tun.\n\nDie Funktion grep()\ngrep() erlaubt, einen character-vektor nach einem bestimmten Muster zu durchsuchen. Zurückgegeben werden alle Positionen, an denen dieses Muster auftritt. Man kann sich das ein bisschen wie die Suchfunktion in Word vorstellen. grep() hat verschiedene Argumente – pattern gibt das Muster an, was gesucht werden soll, x gibt den character-Vektor an, in dem gesucht werden soll, und value gibt als logisches Argument an, ob der Wert selbst oder seine Position zurückgegeben werden soll. Die Flexibilität von grep() rührt unter anderem auch daher, dass man als Suchmuster (pattern) auch reguläre Ausdrücke verwenden kann.\n\ngrep(pattern=\"id\", x=varnamen) findet die Positionen der Variablennamen, die ein “id” im Variablennamen haben.\ngrep(pattern=\"id\", x=varnamen, value=TRUE) zeigt die Variablennamen an, die ein “id” im Variablennamen haben.\ngrep(pattern=\"^id\", x=varnamen, value=TRUE) zeigt die Variablennamen an, die mit einem “id” im Variablennamen beginnen. (Der “Haken” vor dem “id” besagt, dass der Variablenname mit “id” beginnen muss)\nWenn ich id-Variablen finden will, mit aber nicht sicher bin, ob die in dem Datensatz groß oder klein geschrieben sind, ich aber im Zweifel beide haben will, kann man die “Oder”-verknüpfung nehmen (genaueres im Abschnitt “Logische Operatoren”): grep(pattern=\"ID|id\", x=varnamen, value=TRUE)\nAuch den letzten Befehl kann man “einengen”, dass nur die Variablennamen gesucht werden sollen, die mit einem groß oder kleingeschriebenen “ID” beginnen: grep(pattern=\"^ID|^id\", x=varnamen, value=TRUE)\nDas ist auch sinnvoll, wenn ich beispielsweise alle Variablennamen der Deutsch-Items identifizieren will und weiß, Deutsch-Items beginnen mit einem groß geschriebenen “D”: grep(pattern=\"^D\", x=varnamen, value=TRUE)\nGenauso kann man auch nur die Variablennamen suchen, die mit einem klein geschriebenen “a” aufhören: grep(pattern=\"a$\", x=varnamen, value=TRUE). Das “$”-Zeichen gibt an, dass nach dem Zeichen “a” der Variablenname zuende sein muss.\nMöglich (aber etwas komplizierter) sind auch Verknüpfungen der Art: Finde alle Variablennamen, die mit einem “D” beginnen und einem “a” aufhören. Hier handelt es sich um eine logische Verknüpfung zweier Bedingungen – genauer wird darauf im folgenden Abschnitt “Logische Operatoren” eingegangen. In R kann man das auf verschiedenen Wegen realisieren; eine Möglichkeit soll hier kurz demonstriert werden:\n\n\nbeginnt_mit_D &lt;- grep(pattern=\"^D\", x=varnamen, value=TRUE)\nendet_mit_a   &lt;- grep(pattern=\"a$\", x=varnamen, value=TRUE)\nbeides        &lt;- intersect(beginnt_mit_D, endet_mit_a)\nbeides\n\n[1] \"D10101a\" \"D10102a\" \"D10103a\" \"D10201a\"\n\n\n\n\nDie Funktionen gsub(), substr(), substring(), nchar() und strsplit()\n\ngsub() erlaubt es, Teile eines character-Vektors zu ersetzen. Sollen bspw. in der Variablenliste alle Namen, die mit “D101” beginnen, durch “D201” ersetzt werden, geht das mit gsub(pattern = \"D101\", replacement = \"D201\", x = varnamen). Hier ist es wichtig, die Stelligkeit zu beachten; gsub(pattern = \"D1\", replacement = \"D2\", x = varnamen) würde auch z.B. “D102” durch “D202” ersetzen. Möglich, aber nicht notwendig ist hier auch, die Ersetzung nur durchzuführen, wenn “D101” am Anfang des strings steht: gsub(pattern = \"^D101\", replacement = \"D201\", x = varnamen).\nsubstr() erlaubt es, bestimmte Teile eines character-Vektors “auszuschneiden”: wenn man bspw. nur die ersten 4 Zeichen ausschneiden will, geht das mit substr(x = varnamen, start = 1, stop = 4). Zeichenketten mit weniger als 4 Zeichen (hier etwa der Variablenname “sex”) werden dabei so beibehalten, wie sie waren.\nMöchte man von dem character-Vektor nur am Anfang bspw. das erste Zeichen entfernen und alle anderen beibehalten (egal, wie viele es sind), bietet sich die Funktion substring() an: substring(text = varnamen, first = 2)\nnchar() einem für jedes Element die Anzahl von Zeichen (Buchstaben und Ziffern): nchar(varnamen)\nstrsplit() teilt einen character-Vektor an einem definierten Zeichen\n\n\n\nDie Funktion paste()\nDie Funktion erlaubt es, character-Vektoren aus einzelnen Elementen “zusammenzubauen”. Soll beispielsweise an den Variablennamens-Vektor varnamen das Jahr der Erhebung mit angefügt werden, geht das mit folgendem Ausdruck: paste(varnamen, \"2012\", sep=\"_\"). An jeden Variablennamen wurde nun die Jahreszahl 2012 angefügt. Der Argument sep gibt dabei das Zeichen an, das als “Trenner” zweischen dem ursprünglichen Ausdruck und dem “Suffix” 2012 verwendet werden soll. paste() ist eine recht mächtige Funktion, so kann man bspw. auch an jeden Variablennamen die laufende Nummer anhängen, die er im character-Vektor einnimmt: paste(varnamen, 1:length(varnamen), sep=\"_\"). Es ist auch möglich, alle Elemente des Vektor zu einem einzigen großen String zusammenzubinden: paste(varnamen, collapse=\"_\"). Die wichtige, aber häufig Verwirrung stiftende Unterscheidung liegt hierbei zwischen den Separationsargumenten sep und collapse. sep definiert das Trennzeichen für die einzelnen Terme; collapse (ggf.) das Trennzeichen, mit dem die Ergebnisse zusammengefügt werden (sofern sie zusammengefügt werden sollen). Die Hilfeseite der paste-Funktion liefert einige anschauliche Beispiele, die die Unterscheidung zwischen beiden verdeutlichen.\n\n\nFunktionen aus eatTools\nIm Laufe der Datenaufbereitungsprozeduren am IQB wurden die obenstehenden Funktionen teils erweitert. Ohne Anspruch auf Vollständigkeit sollen weitere Möglichkeiten der Zeichenkettenmanipulation kurz genannt werden:\n\neatTools::crop() entfernt führende oder abschließende Leerzeichen (bzw. ein frei definiertes Zeichen) aus einem character-Vektor. Das ist bspw. dann sinnvoll, wenn in inakkurat aufbereiteten Datensätzen z.B. anstatt einer 1 der Wert 1 (also mit einem unbeabsichtrigten leerzeichen eingetragen wurde. Hier werden (nur der Anschaulichkeit zuliebe) alle führenden und abschließenden “D”s aus den Variablennamen entfernt: eatTools::crop(varnamen, char = \"D\")\neatTools::removeNumeric() entfernt alle Ziffern aus einem character-Vektor: eatTools::removeNumeric(varnamen)\neatTools::removeNonNumeric() entfernt alle Buchstaben aus einem character-Vektor und lässt nur die Ziffern übrig. Manche Elemente von varnamen sind hinterher leer. eatTools::removeNonNumeric(varnamen)\neatTools::removePattern() entfernt ein bestimmtes Muster aus einem character-Vektor: eatTools::removePattern(string = varnamen, pattern = \"id\")",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Einführung"
    ]
  },
  {
    "objectID": "docs/R/ws1.html#logische-operatoren",
    "href": "docs/R/ws1.html#logische-operatoren",
    "title": "R Workshop Einführung",
    "section": "4. Logische Operatoren",
    "text": "4. Logische Operatoren\nAllgemeines zu logischen Operatoren kann man auf der gleichnamigen Wikipediaseite finden: https://de.wikipedia.org/wiki/Logischer_Operator\nFür sämtliche Operatoren gibt es eine Entsprechung in R. Die Syntax ist dabei (weitgehend) äquivalent zu den angegeben Beispielen für C, C++, Java und PHP auf der Wikipediaseite. Der Wahrheitswert, der in R zurückgegeben wird, hat die Klasse logical und kann 2 Werte annehmen: TRUE oder FALSE. Der Wahrheitswert kann wiederum einem Objekt zugewiesen werden:\n\nistWahr &lt;- 4 == 5 \nclass(istWahr)\n\n[1] \"logical\"\n\nistWahr\n\n[1] FALSE\n\n\n\nLogische Operatoren ohne Verknüpfung\n\nist größer als: 4 &gt; 3\nist kleiner als: 4 &lt; 3\nist größer oder gleich: 4 &gt;= 3\nist kleiner oder gleich: 4 &lt;= 3\nist gleich: 4 == 3\nist ungleich: 4 != 3\n\n\n\nLogische Operatoren mit Verknüpfungen\n\nBedingung a UND Bedingung b sind erfüllt: 4 &gt; 3 & is.numeric(5)\nBedingung a ODER Bedingung b ist erfüllt: 4 &gt; 3 | is.numeric(5)\nENTWEDER Bedingung a ODER Bedingung b ist erfüllt: xor(4 &gt; 3, is.numeric(5)). Hier wird FALSE zurückgegeben, da beide Bedingungen erfüllt sind, und eben nicht nur entweder a oder b.\nBedingung b ist nicht erfüllt: !is.numeric(\"a\"). Hier wird TRUE zurückgegeben, denn es ist ja wahr, dass “a” nicht numerisch ist.\n\n\n\nArbeiten mit vektorwertigen logischen Verknüpfungen\nIn den oberen Beispielen wurden logische Abfragen immer nur für ein Objekt der Länge 1 durchgeführt. Man kann diese Funktionen aber auch auf Vektoren anwenden. Dazu folgendes hypothetisches Beispiel: ein großer Datensatz mit vielen Variablen soll in Mplus ausgewertet werden. In Mplus dürfen Variablennamen jedoch nur maximal 6 Zeichen haben. Gibt es also in dem Variablennamens-Vektor varnamen Variablennamen mit unerlaubter Länge? Um das zu prüfen, geht man in mehreren Schritten vor:\n\nZeige für jedes Element im Variablennamens-Vektor die Anzahl von Buchstaben an.\n\n\nanzahl &lt;- nchar(varnamen)\n\n\nPrüfe, für welche Variablennamen die zulässige Zeichenanzahl überschritten ist. Dazu wird ein logischer Vektor erzeugt, der den Wert TRUE annimmt, wenn die Zeichenanzahl maximal 6 beträgt, andernfalls FALSE.\n\n\nerlaubt &lt;- anzahl &lt;= 6\nerlaubt\n\n [1]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE\n[13] FALSE FALSE  TRUE  TRUE\n\n\n\nNun wird geprüft, ob diese Bedingung für alle Variablennamen erfüllt ist. Dazu können die Funktionen all() oder any() benutzt werden. all() fragt: Haben alle Elemente des Vektors erlaubt den Wahrheitswert TRUE? any() fragt: Gibt es irgendein Element in dem Vektors erlaubt, das den Wahrheitswert FALSE hat?\n\n\nall(erlaubt)\n\n[1] FALSE\n\nany(erlaubt == FALSE)\n\n[1] TRUE\n\n\n\nJa, einige Variablennamen haben eine größere Zeichenanzahl als 6. Man kann die Variablennamen auf die ersten 6 Zeichen reduzieren:\n\n\nvarnamen_neu &lt;- substr(varnamen, 1, 6)\n\n\nVariablennamen müssen jedoch stets einzigartig (unique) sein. Ist das jetzt noch der Fall? Dazu verwendet man die oben beschriebene Funktion duplicated() in Verbindung mit any:\n\n\nany(duplicated(varnamen_neu))\n\n[1] TRUE\n\n\nDer Wahrheitswert ist TRUE, es gibt also mindestens zwei Variablennamen, die jetzt identisch sind. An dieser Stelle könnte es passieren, dass man erstmal nicht weiter weiß. Eine Möglichkeit wäre, zu googlen: “r make unique”. So findet man eine Funktion namens make.unique, die es erlaubt, duplizierte Werte in character-Vektoren zu ersetzen, so dass sie einzigartig werden. Unglücklicherweise werden dadurch die Variablennamen wieder länger, als sie sein dürfen:\n\nvarnamen_neu2 &lt;- make.unique(varnamen_neu)\nany(nchar(varnamen_neu2)&gt;6)\n\n[1] TRUE\n\n\nTatsächlich gibt es für dieses Problem also keine einfache, “triviale” Lösung. Man könnte entweder vollständig willkürliche Namen vergeben, die dann aber keine Rückschlüsse auf die ursprüngliche Variablenbedeutung mehr zulassen, oder man experimentiert, beruhend auf folgenden Überlegungen: make.unique fügt an nicht-unique Variablennamen einen Punkt und eine laufende Nummer an, also zwei zusätzliche Zeichen. Also dürfte man nur die ersten 4 Zeichen der Variablennamen beibehalten:\n\nvarnamen_neu3 &lt;- make.unique(substr(varnamen, 1, 4))\nany(nchar(varnamen_neu3)&gt;6)\n\n[1] FALSE\n\nany(duplicated(varnamen_neu3))\n\n[1] FALSE\n\nvarnamen_neu3\n\n [1] \"idst\"   \"idcl\"   \"D101\"   \"D101.1\" \"D101.2\" \"D101.3\" \"D102\"   \"D103\"  \n [9] \"sex\"    \"M155\"   \"M156\"   \"M157\"   \"M157.1\" \"M157.2\" \"hisc\"   \"pari\"  \n\n\nHundertprotentig schön ist auch diese Variante nicht, weil nun auch von bereits einzigartigen Variablennamen nur die ersten vier Zeichen übrig behalten worden sind, obwohl es hier ja hätten sechs sein dürfen. Sofern eine solche Operation im Arbeitsalltag also häufiger gebraucht wird, wäre es günstig, sich dafür eine eigene Funktion zu schreiben, um diese Prozesse weniger umständlich zu gestalten. Dazu aber an anderer Stelle mehr.",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Einführung"
    ]
  },
  {
    "objectID": "docs/R/ws1.html#fehlende-werte-missing-values",
    "href": "docs/R/ws1.html#fehlende-werte-missing-values",
    "title": "R Workshop Einführung",
    "section": "5. Fehlende Werte (missing values)",
    "text": "5. Fehlende Werte (missing values)\nFehlende Werte werden in R mit NA (not available) gekennzeichnet. Im Folgenden geht es nicht darum, wie in statistischen Analysen mit fehlenden Werten umgegangen werden kann, sondern wie man sie in R technisch behandelt. Dazu soll beispielhaft ein numerischer Vektor betrachtet werden, der fehlende Werte enthält:\n\nnumvek &lt;- rnorm(20, 0, 1)\nnumvek[c(3,6,9,19)] &lt;- NA\n\n\nDie häufigsten im Zusammenhang mit fehlenden Werten gebräuchlichen Funktionen sind:\n\nis.na() gibt einen Vektor der Klasse logical zurück, dessen Wert TRUE ist, wenn es sich um einen fehlenden Wert handelt: is.na(numvek). Wenn man lediglich wissen, ob es überhaupt irgendwelche fehlenden Werte gibt, kann man das mit any() verbinden: any(is.na(numvek)). Wenn man wissen will, an welcher Stelle die fehlenden Werte stehen, geht which(is.na(numvek))\nAchtung! Anders als man vielleicht vermuten würde, funktioniert which(numvek == NA) nicht!\nWenn ich nur die beobachteten Werte aus numvek extrahieren möchte, also alles ausschließen, was NA ist, geht das mit na.omit(numvek). Dieser Vektor ist mit nur noch 16 Elementen folglich kürzer als der ursprüngliche mit 20 Elementen: length(na.omit(numvek))\nMöchte man sich beispielsweise den Mittelwert eines Vektors anzeigen lassen, der fehlende Werte enthält, ist das Ergebnis ebenfalls NA: mean(numvek). Meist will man jedoch einfach das arithmetisches Mittel aller beobachteten Werte. Dazu könnte man einfach den Mittelwert unter Ausschluss der fehlenden Werte bestimmen: mean(na.omit(numvek)). Das ist dasselbe, wie wenn man in der Funktion mean() mit einem zusätzlichen Argument definiert, dass fehlende Werte vor der Berechnung ausgeschlossen werden sollen: mean(numvek, na.rm = TRUE). Man sieht wieder, dass verschiedene syntaktische Umsetzungen zu dem gewünschten Ergebnis führen können. Das logische Argument na.rm ist für viele Funktionen definiert, so etwa var(), sd(), lm(), glm(), etc.\n\n\n\nFehlende Werte in character-Vektoren\nHier gilt im Grunde dasselbe wie für numerische Vektoren. Auf ein paar Fallstricke soll hingewiesen werden:\n\ncharvek &lt;- c(\"France\", \"Belgium\", \"Poland\", NA, \"Denmark\", \"NA\", \"Austria\", \"\")\nwhich(is.na(charvek))\n\n[1] 4\n\n\nAuch in character-Vektoren müssen fehlende Werte ohne hochgestellte Anführungszeichen eingetragen werden; der sechste Wert \"NA\" wird nicht als fehlender Wert verstanden. Ebensowenig der achte Wert, der einfach ein leerer String ist. Letzteres ist insofern relevant, dass, wenn man etwa csv-Dateien mit R einliest, leere Zellen manchmal als leere Strings eingelesen werden, obwohl man sie eigentlich wie fehlende Werte behandelt wissen will. Um das \"NA\" und den leeren String in einen wirklichen fehlenden Wert umzuwandeln, kann beispielsweise die recode()-Funktion aus dem Paket car verwendet werden:\n\ncharvek_neu &lt;- car::recode(charvek, \"'NA'=NA; ''=NA\")\ncharvek_neu\n\n[1] \"France\"  \"Belgium\" \"Poland\"  NA        \"Denmark\" NA        \"Austria\"\n[8] NA",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Einführung"
    ]
  },
  {
    "objectID": "docs/R/ws1.html#gut-zu-wissen",
    "href": "docs/R/ws1.html#gut-zu-wissen",
    "title": "R Workshop Einführung",
    "section": "6. Gut zu wissen",
    "text": "6. Gut zu wissen\nDen Überblick über die vorhandenen Funktionen und Pakete zu behalten, ist nahezu unmöglich; allein auf CRAN gibt es tausende von R-Paketen. Aus unserer subjektiven Sicht sollen daher die wichtigsten Funktionen, die sich im Laufe des IQB-Lebens als unverzichtbar herausgestellt haben, hier kurz ohne Anspruch auf Vollständigkeit aufgelistet werden. Wo nötig, werden Links für weiterführende Literatur angegeben:",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Einführung"
    ]
  },
  {
    "objectID": "docs/R/ws2.html",
    "href": "docs/R/ws2.html",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "",
    "text": "Ein data.frame kann als eine spaltenweise Aneinanderreihung verschiedener Vektoren verstanden werden. Jeder einzelne Vektor kann dabei, wie gehabt, nur Elemente derselben Klasse enthalten; der data.frame selbst kann jedoch Vektoren unterschiedlicher Klasse enthalten. Im folgenden Beispiel wird ein data.frame aus zwei character- und drei numerischen Vektoren erzeugt:\n\nID &lt;- c(89045, 43678, 88475, 69781, 88766, 67743)\nname &lt;- c(\"Onno\", \"Stefan\", \"Sylvain\", \"Annette\", \"Marina\", \"Eike\")\ngeschlecht &lt;- c(\"m\",\"m\",\"m\",\"w\",\"w\",\"m\")\ntreatment  &lt;- c(0,1,1,1,0,1)\nbdi.wert   &lt;- c(12.5,13,11.75,9.85,10.15,9.95)\ndaten      &lt;- data.frame(ID, name, geschlecht, treatment, bdi.wert, stringsAsFactors=FALSE)\n\nUm sich einen Überblick über den soeben angelegten data.frame zu verschaffen, sind folgende Befehle nützlich:\n\nDie ersten Zeilen des Datensatzes werden ausgegeben:\n\n\nhead(daten)\n\n     ID    name geschlecht treatment bdi.wert\n1 89045    Onno          m         0    12.50\n2 43678  Stefan          m         1    13.00\n3 88475 Sylvain          m         1    11.75\n4 69781 Annette          w         1     9.85\n5 88766  Marina          w         0    10.15\n6 67743    Eike          m         1     9.95\n\n\n\nDie Struktur des Datensatzes wird ausgegeben:\n\n\nstr(daten)\n\n'data.frame':   6 obs. of  5 variables:\n $ ID        : num  89045 43678 88475 69781 88766 ...\n $ name      : chr  \"Onno\" \"Stefan\" \"Sylvain\" \"Annette\" ...\n $ geschlecht: chr  \"m\" \"m\" \"m\" \"w\" ...\n $ treatment : num  0 1 1 1 0 1\n $ bdi.wert  : num  12.5 13 11.75 9.85 10.15 ...\n\n\n\nEine Zusammenfassung der Daten wird ausgegeben:\n\n\nsummary(daten)\n\n       ID            name            geschlecht          treatment     \n Min.   :43678   Length:6           Length:6           Min.   :0.0000  \n 1st Qu.:68252   Class :character   Class :character   1st Qu.:0.2500  \n Median :79128   Mode  :character   Mode  :character   Median :1.0000  \n Mean   :74581                                         Mean   :0.6667  \n 3rd Qu.:88693                                         3rd Qu.:1.0000  \n Max.   :89045                                         Max.   :1.0000  \n    bdi.wert    \n Min.   : 9.85  \n 1st Qu.:10.00  \n Median :10.95  \n Mean   :11.20  \n 3rd Qu.:12.31  \n Max.   :13.00  \n\n\n\nWelche Eigenschaften hat ein Objekt “data.frame”?\n\n\nclass(daten)\n\n[1] \"data.frame\"\n\nmode(daten)\n\n[1] \"list\"\n\n\nAuf zwei Besonderheiten soll hier kurz eingegangen werden:\n\nWarum hat das Objekt daten zwar die Klasse data.frame, aber den Modus list? Der Grund ist, dass in R data.frames “Spezialfälle” von Listen sind, genauso wie man einen Skalar als “Spezialfall” eines Vektors verstehen kann. In R dürfen Listen beliebig viele Elemente beliebigen Typs enthalten. data.frames dürfen mehrere Vektoren gleicher Länge, aber unterschiedlichen Typs (bzw. unterschiedlicher Klasse) enthalten. Ein data.frame ist also eine “eingeschränkte” Liste.\nWas bedeutet “stringsAsFactors”? Wird ein data.frame konstruiert, der sich (teilweise) aus character-Variablen zusammensetzt, werden diese in R standardmäßig wie Faktoren behandelt. Das ist dann sinnvoll, wenn diese character-Variablen (wie hier) im Grunde nur Gruppierungsvariablen sind (hier: male, female). In SPSS gibt es für Gruppierungsvariablen die Skalendefinition “nominal”. Typischerweise werden solche Variablen als unabhängige Variablen in Varianzanalysen eingesetzt. Unter “echten” character-Variablen könnte man sich etwa die Freitextantworten in Fragebögen vorstellen. “stringsAsFactors” besagt also: “Soll R diese Variablen wie Faktoren behandeln oder wie echte character-Variablen?”\n\nDie Variablen Treatment und Geschlecht könnten auch Faktoren werden (was in der Regel aber eigentlich nicht nötig ist):\n\ndaten$geschlecht &lt;- as.factor(daten$geschlecht)\ndaten$treatment &lt;- as.factor(daten$treatment)\nstr(daten)\n\n'data.frame':   6 obs. of  5 variables:\n $ ID        : num  89045 43678 88475 69781 88766 ...\n $ name      : chr  \"Onno\" \"Stefan\" \"Sylvain\" \"Annette\" ...\n $ geschlecht: Factor w/ 2 levels \"m\",\"w\": 1 1 1 2 2 1\n $ treatment : Factor w/ 2 levels \"0\",\"1\": 1 2 2 2 1 2\n $ bdi.wert  : num  12.5 13 11.75 9.85 10.15 ...\n\n\n\n\nNehmen wir an, wir hätten nun einen weiteren data.frame, der die Nachnamen einiger Studienteilnehmer*innen enthält:\n\ndaten2 &lt;- data.frame(\n    ID = c(43678, 88475, 88766, 89045),\n    nachname = c(\"Tegemann\", \"Laffont\", \"Brandner\",\n                 \"Schreiner\"), stringsAsFactors = FALSE)\ndaten2\n\n     ID  nachname\n1 43678  Tegemann\n2 88475   Laffont\n3 88766  Brandner\n4 89045 Schreiner\n\n\n…und möchten diesen nun mit unseren Daten zusammenführen, dann geht das sehr flexibel mit der Funktion merge(). merge() verknüpft die Datensätze automatisch über Spalten in den beiden Datensätzen, die gleich benannt sind, in unserem Beispiel die Spalte ID:\n\ndat &lt;- merge(daten, daten2, all=TRUE)\ndat\n\n     ID    name geschlecht treatment bdi.wert  nachname\n1 43678  Stefan          m         1    13.00  Tegemann\n2 67743    Eike          m         1     9.95      &lt;NA&gt;\n3 69781 Annette          w         1     9.85      &lt;NA&gt;\n4 88475 Sylvain          m         1    11.75   Laffont\n5 88766  Marina          w         0    10.15  Brandner\n6 89045    Onno          m         0    12.50 Schreiner\n\n\nSind die Spalten mit den Schlüsselvariablen nicht gleich benannt kann man im by.x-Argument spezifizieren, wie die Variable im ersten Datensatz heißt und im by.y-Argument, wie sie im zweiten Datensatz heißt. Heißen mehrere Variablen in beiden Datensätzen gleich und man möchte nur eine dieser gleichnamigen Variablen zur Verknüpfung verwenden, spezifiziert man diese im by-Argument:\n\ndat &lt;- merge(daten, daten2, by=\"ID\", all=TRUE)\ndat\n\n     ID    name geschlecht treatment bdi.wert  nachname\n1 43678  Stefan          m         1    13.00  Tegemann\n2 67743    Eike          m         1     9.95      &lt;NA&gt;\n3 69781 Annette          w         1     9.85      &lt;NA&gt;\n4 88475 Sylvain          m         1    11.75   Laffont\n5 88766  Marina          w         0    10.15  Brandner\n6 89045    Onno          m         0    12.50 Schreiner\n\n\nWenn man zwei Datensätze untereinander schreiben möchte, müssen sie dieselbe Spaltenausdehnung haben:\n\nrbind(daten2, daten2)\n\n     ID  nachname\n1 43678  Tegemann\n2 88475   Laffont\n3 88766  Brandner\n4 89045 Schreiner\n5 43678  Tegemann\n6 88475   Laffont\n7 88766  Brandner\n8 89045 Schreiner\n\n\n…und wenn man zwei Datensätze nebeneinander schreiben möchte, müssen sie dieselbe Zeilenausdehnung haben:\n\ncbind(daten2, daten2)\n\n     ID  nachname    ID  nachname\n1 43678  Tegemann 43678  Tegemann\n2 88475   Laffont 88475   Laffont\n3 88766  Brandner 88766  Brandner\n4 89045 Schreiner 89045 Schreiner\n\n\nMöchte man viele Datensätze derselben Ausdehnung nebeneinander oder untereinander in einen data.frameschreiben, kann man die Funktion do.call() benutzen, die analog zu hier im Beispiel mit cbind() auch mit rbind() funktioniert:\n\ndo.call(\"cbind\", list(daten2, daten2, daten2, daten2))\n\n     ID  nachname    ID  nachname    ID  nachname    ID  nachname\n1 43678  Tegemann 43678  Tegemann 43678  Tegemann 43678  Tegemann\n2 88475   Laffont 88475   Laffont 88475   Laffont 88475   Laffont\n3 88766  Brandner 88766  Brandner 88766  Brandner 88766  Brandner\n4 89045 Schreiner 89045 Schreiner 89045 Schreiner 89045 Schreiner\n\n\nZum weiteren Umgang mit dem Listenformat list siehe Kapitel 2, weiter unten.\n\n\n\nÄhnlich wie in Vektoren kann man in data.frames über eckige Klammern einzelne Elemente anzeigen lassen oder verändern. Da data.frames zwei Dimensionen haben (Vektoren haben nur eine), muss man hier das Element mit [Zeile, Spalte] auswählen, also beispielsweise\n\ndat[4,2]\n\n[1] \"Sylvain\"\n\n\nAlternativ kann man mit dem Dollar-Zeichen eine Variable ansteuern:\n\ndat[4,]$name\n\n[1] \"Sylvain\"\n\n\nOder man kann den Variablennamen (mit hochgestellten Anführungszeichen) verwenden:\n\ndat[4,\"name\"]\n\n[1] \"Sylvain\"\n\n\nDie komplette “name”-Spalte gibt man aus, indem man die Zeilenbezeichnung weglässt oder alle Zeilen explizit auswählt:\n\ndat$name\n\n[1] \"Stefan\"  \"Eike\"    \"Annette\" \"Sylvain\" \"Marina\"  \"Onno\"   \n\ndat[,\"name\"]\n\n[1] \"Stefan\"  \"Eike\"    \"Annette\" \"Sylvain\" \"Marina\"  \"Onno\"   \n\ndat[1:6,\"name\"]\n\n[1] \"Stefan\"  \"Eike\"    \"Annette\" \"Sylvain\" \"Marina\"  \"Onno\"   \n\n\nAuch die Reihenfolge zu variieren, ist möglich:\n\ndat[6:1,\"name\"]\n\n[1] \"Onno\"    \"Marina\"  \"Sylvain\" \"Annette\" \"Eike\"    \"Stefan\" \n\n\nUm sich nur ausgewählte Spalten in selbst definierter Reihenfolge des Datensatzes anzusehen bzw. in einem neuen Objekt zu speichern:\n\ndat2 &lt;- dat[,c(\"name\", \"nachname\", \"bdi.wert\", \"treatment\")]\ndat2\n\n     name  nachname bdi.wert treatment\n1  Stefan  Tegemann    13.00         1\n2    Eike      &lt;NA&gt;     9.95         1\n3 Annette      &lt;NA&gt;     9.85         1\n4 Sylvain   Laffont    11.75         1\n5  Marina  Brandner    10.15         0\n6    Onno Schreiner    12.50         0\n\n\nWenn man sich nur bestimmte Subgruppen anschauen möchte:\n\nAlle Mitglieder der Kontrollgruppe:\n\n\ndat2[dat2$treatment == 0,]\n\n    name  nachname bdi.wert treatment\n5 Marina  Brandner    10.15         0\n6   Onno Schreiner    12.50         0\n\n\n\nAlle mit einem BDI-Wert größer als 10:\n\n\ndat2[dat2$bdi.wert &gt; 10,]\n\n     name  nachname bdi.wert treatment\n1  Stefan  Tegemann    13.00         1\n4 Sylvain   Laffont    11.75         1\n5  Marina  Brandner    10.15         0\n6    Onno Schreiner    12.50         0\n\n\n\nAlle in der Treatment-Gruppe und einem BDI-Wert größer als 10:\n\n\ndat2[dat2$treatment == 1 & dat2$bdi.wert &gt; 10,]\n\n     name nachname bdi.wert treatment\n1  Stefan Tegemann    13.00         1\n4 Sylvain  Laffont    11.75         1\n\n\n\nAlle in der Treatment-Gruppe oder einem BDI-Wert größer als 10:\n\n\ndat2[dat2$treatment == 1 | dat2$bdi.wert &gt; 10,]\n\n     name  nachname bdi.wert treatment\n1  Stefan  Tegemann    13.00         1\n2    Eike      &lt;NA&gt;     9.95         1\n3 Annette      &lt;NA&gt;     9.85         1\n4 Sylvain   Laffont    11.75         1\n5  Marina  Brandner    10.15         0\n6    Onno Schreiner    12.50         0\n\n\n\nAlle, deren Vorname mit “S” beginnt:\n\n\ndat2[grep(\"^S\", dat2$name),]\n\n     name nachname bdi.wert treatment\n1  Stefan Tegemann    13.00         1\n4 Sylvain  Laffont    11.75         1\n\n\n\nAlle, für die kein Nachname hinterlegt ist:\n\n\ndat2[is.na(dat2$nachname),]\n\n     name nachname bdi.wert treatment\n2    Eike     &lt;NA&gt;     9.95         1\n3 Annette     &lt;NA&gt;     9.85         1\n\n\n\nDer Datensatz ohne Personen, für die kein Nachname hinterlegt ist:\n\n\ndat2[!is.na(dat2$nachname),]\n\n     name  nachname bdi.wert treatment\n1  Stefan  Tegemann    13.00         1\n4 Sylvain   Laffont    11.75         1\n5  Marina  Brandner    10.15         0\n6    Onno Schreiner    12.50         0\n\n\noder\n\ndat2[-which(is.na(dat2$nachname)),]\n\n     name  nachname bdi.wert treatment\n1  Stefan  Tegemann    13.00         1\n4 Sylvain   Laffont    11.75         1\n5  Marina  Brandner    10.15         0\n6    Onno Schreiner    12.50         0\n\n\n\n\n\nWenn man bestimmte Werte im data.frame ersetzen möchte oder Variablen in andere Variablen umkodieren möchte, hat man verschiedene Möglichkeiten.\n\nAlle Werte im Datensatz ersetzen:\n\n\n\n\nz.B. alle fehlenden Werte durch einen bestimmten Missingcode ersetzen:\n\n\ndat2[is.na(dat2)] &lt;- \"-97\"\ndat2\n\n     name  nachname bdi.wert treatment\n1  Stefan  Tegemann    13.00         1\n2    Eike       -97     9.95         1\n3 Annette       -97     9.85         1\n4 Sylvain   Laffont    11.75         1\n5  Marina  Brandner    10.15         0\n6    Onno Schreiner    12.50         0\n\n\n\noder einen bestimmen Wert durch andere Werte oder Missings ersetzen:\n\n\ndat2[dat2==\"-97\"] &lt;- NA\ndat2\n\n     name  nachname bdi.wert treatment\n1  Stefan  Tegemann    13.00         1\n2    Eike      &lt;NA&gt;     9.95         1\n3 Annette      &lt;NA&gt;     9.85         1\n4 Sylvain   Laffont    11.75         1\n5  Marina  Brandner    10.15         0\n6    Onno Schreiner    12.50         0\n\n\n\nNeue Variablen in Abhängigkeit von anderen Variablen bilden\n\nMit der Funktion ifelse formuliert man zunächst eine Bedingung (hier alle, die einen BDI kleiner als 10 haben und gleichzeitig in der Treatment-Gruppe sind), danach gibt man durch ein Komma abgetrennt an, welche Werte in der neuen Variable stehen sollen (hier \"Treatment war wirksam\"). Durch ein weiteres Komma abgetrennt kann dann angegeben werden, was passieren soll, wenn die Bedingung nicht zutrifft. Dabei kann dort sogar ein weiteres ifelse-Statement eingefügt werden, wie hier im Beispiel, das nach genau denselben Regeln aufgebaut ist.\n\ndat2$neueVar &lt;- ifelse(test=dat2$bdi.wert &lt; 10 & dat2$treatment==1,\n                       yes=\"Treatment war wirksam\",  \n                       no = ifelse(test=dat2$bdi.wert &gt;= 10 & dat2$treatment==1,   \n                                   yes=\"Treatment nicht wirksam\",\n                                   no=\"kein Treatment\"))\ndat2\n\n     name  nachname bdi.wert treatment                 neueVar\n1  Stefan  Tegemann    13.00         1 Treatment nicht wirksam\n2    Eike      &lt;NA&gt;     9.95         1   Treatment war wirksam\n3 Annette      &lt;NA&gt;     9.85         1   Treatment war wirksam\n4 Sylvain   Laffont    11.75         1 Treatment nicht wirksam\n5  Marina  Brandner    10.15         0          kein Treatment\n6    Onno Schreiner    12.50         0          kein Treatment\n\n\nAuch kann die Funktion recode aus dem Paket car verwendet werden. Hier werden die Werte oder Wertebereiche einer Variablen umkodiert. Der Wertebereich des niedrigsten aufgetretenen Wertes bis zum Wert 10 entspricht dem hier benutzten Statement lo:10. Wie man mit allen nicht explizit erwähnten Werten verfahren möchte, kann mit dem else-Argument festlegen.\n\nlibrary(car)\n\n\ndat2$neueVar &lt;- car::recode(dat2$bdi.wert, \"lo:10='leichte Depression'; else='schwere Depression'\")\ndat2\n\n     name  nachname bdi.wert treatment            neueVar\n1  Stefan  Tegemann    13.00         1 schwere Depression\n2    Eike      &lt;NA&gt;     9.95         1 leichte Depression\n3 Annette      &lt;NA&gt;     9.85         1 leichte Depression\n4 Sylvain   Laffont    11.75         1 schwere Depression\n5  Marina  Brandner    10.15         0 schwere Depression\n6    Onno Schreiner    12.50         0 schwere Depression\n\n\n\n\n\nUnser Datensatz befindet sich im sogenannten Wide-Format. Für manche Anwendungen kann es sinnvoll sein, den Datensatz in das sogenannte Long-Format zu bringen, in dem alle Werte der Personen in einer einzigen Variablen untereinander stehen. Früher benutzte man das Paket reshape2, um einen Datensatz ins Long-Format zu bringen, was auch jetzt noch immer unkompliziert möglich ist:\n\nlibrary(reshape2)\n\n\ndatl &lt;- reshape2::melt(dat, id.vars=\"ID\")\ndatl\n\n      ID   variable     value\n1  43678       name    Stefan\n2  67743       name      Eike\n3  69781       name   Annette\n4  88475       name   Sylvain\n5  88766       name    Marina\n6  89045       name      Onno\n7  43678 geschlecht         m\n8  67743 geschlecht         m\n9  69781 geschlecht         w\n10 88475 geschlecht         m\n11 88766 geschlecht         w\n12 89045 geschlecht         m\n13 43678  treatment         1\n14 67743  treatment         1\n15 69781  treatment         1\n16 88475  treatment         1\n17 88766  treatment         0\n18 89045  treatment         0\n19 43678   bdi.wert        13\n20 67743   bdi.wert      9.95\n21 69781   bdi.wert      9.85\n22 88475   bdi.wert     11.75\n23 88766   bdi.wert     10.15\n24 89045   bdi.wert      12.5\n25 43678   nachname  Tegemann\n26 67743   nachname      &lt;NA&gt;\n27 69781   nachname      &lt;NA&gt;\n28 88475   nachname   Laffont\n29 88766   nachname  Brandner\n30 89045   nachname Schreiner\n\n\nund mit dcast() formte man den Datensatz wieder zurück:\n\nreshape2::dcast(datl, ID ~ variable)\n\n     ID    name geschlecht treatment bdi.wert  nachname\n1 43678  Stefan          m         1       13  Tegemann\n2 67743    Eike          m         1     9.95      &lt;NA&gt;\n3 69781 Annette          w         1     9.85      &lt;NA&gt;\n4 88475 Sylvain          m         1    11.75   Laffont\n5 88766  Marina          w         0    10.15  Brandner\n6 89045    Onno          m         0     12.5 Schreiner\n\n\nIn jüngerer Zeit wurden dazu recht effiziente Funktionen entwickelt, die im Paket tidyr zu finden sind. Hier wird nur rudimentär in die Benutzung dieser Funktionen eingeführt – der/die interessierte Leser/in mag sich in folgende Seite vertiefen: http://tidyr.tidyverse.org/articles/pivot.html Hierbei ist zu beachten, dass bei Benutzung des Pakets tidyr die data.frames zu anderen Objekten werden, nämlich tibbles (die aber problemlos mit der Funktion as.data.frame() wieder in data.frames zurücktransformiert werden können. Darüber hinaus weicht die zu verwendende Syntax hier deutlich von der bisher gezeigten basalen R-Syntax ab. Eine besondere Rolle spielt hier der sogenannte Pipe-Operator %&gt;%, über den hier http://www.rdocumentation.org/packages/magrittr/versions/1.0.1/topics/%25%3E%25 oder an anderer Stelle weitergelesen werden kann.\n\nlibrary(tidyr)\n\nUmstrukturierung unserer Daten ins Long-Format:\n\ndat %&gt;% pivot_longer(\n  cols=name:nachname,\n  names_to = \"variable\",\n  values_to = \"value\"\n)\n\noder, äquivalent dazu, mit:\n\npivot_longer(dat, cols=name:nachname, names_to = \"variable\", values_to = \"value\")\n\n# A tibble: 30 × 3\n      ID variable   value   \n   &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;   \n 1 43678 name       Stefan  \n 2 43678 geschlecht m       \n 3 43678 treatment  1       \n 4 43678 bdi.wert   13      \n 5 43678 nachname   Tegemann\n 6 67743 name       Eike    \n 7 67743 geschlecht m       \n 8 67743 treatment  1       \n 9 67743 bdi.wert   9.95    \n10 67743 nachname   &lt;NA&gt;    \n# ℹ 20 more rows\n\n\nund mit pivot_wider() kann man den Datensatz wieder zurück formen:\n\ndatl  %&gt;% pivot_wider(\n  names_from = variable, values_from = value\n)\n\noder genauso:\n\npivot_wider(datl, names_from = variable, values_from = value)\n\n# A tibble: 6 × 6\n     ID name    geschlecht treatment bdi.wert nachname \n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;    \n1 43678 Stefan  m          1         13       Tegemann \n2 67743 Eike    m          1         9.95     &lt;NA&gt;     \n3 69781 Annette w          1         9.85     &lt;NA&gt;     \n4 88475 Sylvain m          1         11.75    Laffont  \n5 88766 Marina  w          0         10.15    Brandner \n6 89045 Onno    m          0         12.5     Schreiner",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Data.frames, Listen & Plots"
    ]
  },
  {
    "objectID": "docs/R/ws2.html#zusammenführen-von-data.frames-merging",
    "href": "docs/R/ws2.html#zusammenführen-von-data.frames-merging",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "",
    "text": "Nehmen wir an, wir hätten nun einen weiteren data.frame, der die Nachnamen einiger Studienteilnehmer*innen enthält:\n\ndaten2 &lt;- data.frame(\n    ID = c(43678, 88475, 88766, 89045),\n    nachname = c(\"Tegemann\", \"Laffont\", \"Brandner\",\n                 \"Schreiner\"), stringsAsFactors = FALSE)\ndaten2\n\n     ID  nachname\n1 43678  Tegemann\n2 88475   Laffont\n3 88766  Brandner\n4 89045 Schreiner\n\n\n…und möchten diesen nun mit unseren Daten zusammenführen, dann geht das sehr flexibel mit der Funktion merge(). merge() verknüpft die Datensätze automatisch über Spalten in den beiden Datensätzen, die gleich benannt sind, in unserem Beispiel die Spalte ID:\n\ndat &lt;- merge(daten, daten2, all=TRUE)\ndat\n\n     ID    name geschlecht treatment bdi.wert  nachname\n1 43678  Stefan          m         1    13.00  Tegemann\n2 67743    Eike          m         1     9.95      &lt;NA&gt;\n3 69781 Annette          w         1     9.85      &lt;NA&gt;\n4 88475 Sylvain          m         1    11.75   Laffont\n5 88766  Marina          w         0    10.15  Brandner\n6 89045    Onno          m         0    12.50 Schreiner\n\n\nSind die Spalten mit den Schlüsselvariablen nicht gleich benannt kann man im by.x-Argument spezifizieren, wie die Variable im ersten Datensatz heißt und im by.y-Argument, wie sie im zweiten Datensatz heißt. Heißen mehrere Variablen in beiden Datensätzen gleich und man möchte nur eine dieser gleichnamigen Variablen zur Verknüpfung verwenden, spezifiziert man diese im by-Argument:\n\ndat &lt;- merge(daten, daten2, by=\"ID\", all=TRUE)\ndat\n\n     ID    name geschlecht treatment bdi.wert  nachname\n1 43678  Stefan          m         1    13.00  Tegemann\n2 67743    Eike          m         1     9.95      &lt;NA&gt;\n3 69781 Annette          w         1     9.85      &lt;NA&gt;\n4 88475 Sylvain          m         1    11.75   Laffont\n5 88766  Marina          w         0    10.15  Brandner\n6 89045    Onno          m         0    12.50 Schreiner\n\n\nWenn man zwei Datensätze untereinander schreiben möchte, müssen sie dieselbe Spaltenausdehnung haben:\n\nrbind(daten2, daten2)\n\n     ID  nachname\n1 43678  Tegemann\n2 88475   Laffont\n3 88766  Brandner\n4 89045 Schreiner\n5 43678  Tegemann\n6 88475   Laffont\n7 88766  Brandner\n8 89045 Schreiner\n\n\n…und wenn man zwei Datensätze nebeneinander schreiben möchte, müssen sie dieselbe Zeilenausdehnung haben:\n\ncbind(daten2, daten2)\n\n     ID  nachname    ID  nachname\n1 43678  Tegemann 43678  Tegemann\n2 88475   Laffont 88475   Laffont\n3 88766  Brandner 88766  Brandner\n4 89045 Schreiner 89045 Schreiner\n\n\nMöchte man viele Datensätze derselben Ausdehnung nebeneinander oder untereinander in einen data.frameschreiben, kann man die Funktion do.call() benutzen, die analog zu hier im Beispiel mit cbind() auch mit rbind() funktioniert:\n\ndo.call(\"cbind\", list(daten2, daten2, daten2, daten2))\n\n     ID  nachname    ID  nachname    ID  nachname    ID  nachname\n1 43678  Tegemann 43678  Tegemann 43678  Tegemann 43678  Tegemann\n2 88475   Laffont 88475   Laffont 88475   Laffont 88475   Laffont\n3 88766  Brandner 88766  Brandner 88766  Brandner 88766  Brandner\n4 89045 Schreiner 89045 Schreiner 89045 Schreiner 89045 Schreiner\n\n\nZum weiteren Umgang mit dem Listenformat list siehe Kapitel 2, weiter unten.",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Data.frames, Listen & Plots"
    ]
  },
  {
    "objectID": "docs/R/ws2.html#navigation-in-data.frames-subsetting",
    "href": "docs/R/ws2.html#navigation-in-data.frames-subsetting",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "",
    "text": "Ähnlich wie in Vektoren kann man in data.frames über eckige Klammern einzelne Elemente anzeigen lassen oder verändern. Da data.frames zwei Dimensionen haben (Vektoren haben nur eine), muss man hier das Element mit [Zeile, Spalte] auswählen, also beispielsweise\n\ndat[4,2]\n\n[1] \"Sylvain\"\n\n\nAlternativ kann man mit dem Dollar-Zeichen eine Variable ansteuern:\n\ndat[4,]$name\n\n[1] \"Sylvain\"\n\n\nOder man kann den Variablennamen (mit hochgestellten Anführungszeichen) verwenden:\n\ndat[4,\"name\"]\n\n[1] \"Sylvain\"\n\n\nDie komplette “name”-Spalte gibt man aus, indem man die Zeilenbezeichnung weglässt oder alle Zeilen explizit auswählt:\n\ndat$name\n\n[1] \"Stefan\"  \"Eike\"    \"Annette\" \"Sylvain\" \"Marina\"  \"Onno\"   \n\ndat[,\"name\"]\n\n[1] \"Stefan\"  \"Eike\"    \"Annette\" \"Sylvain\" \"Marina\"  \"Onno\"   \n\ndat[1:6,\"name\"]\n\n[1] \"Stefan\"  \"Eike\"    \"Annette\" \"Sylvain\" \"Marina\"  \"Onno\"   \n\n\nAuch die Reihenfolge zu variieren, ist möglich:\n\ndat[6:1,\"name\"]\n\n[1] \"Onno\"    \"Marina\"  \"Sylvain\" \"Annette\" \"Eike\"    \"Stefan\" \n\n\nUm sich nur ausgewählte Spalten in selbst definierter Reihenfolge des Datensatzes anzusehen bzw. in einem neuen Objekt zu speichern:\n\ndat2 &lt;- dat[,c(\"name\", \"nachname\", \"bdi.wert\", \"treatment\")]\ndat2\n\n     name  nachname bdi.wert treatment\n1  Stefan  Tegemann    13.00         1\n2    Eike      &lt;NA&gt;     9.95         1\n3 Annette      &lt;NA&gt;     9.85         1\n4 Sylvain   Laffont    11.75         1\n5  Marina  Brandner    10.15         0\n6    Onno Schreiner    12.50         0\n\n\nWenn man sich nur bestimmte Subgruppen anschauen möchte:\n\nAlle Mitglieder der Kontrollgruppe:\n\n\ndat2[dat2$treatment == 0,]\n\n    name  nachname bdi.wert treatment\n5 Marina  Brandner    10.15         0\n6   Onno Schreiner    12.50         0\n\n\n\nAlle mit einem BDI-Wert größer als 10:\n\n\ndat2[dat2$bdi.wert &gt; 10,]\n\n     name  nachname bdi.wert treatment\n1  Stefan  Tegemann    13.00         1\n4 Sylvain   Laffont    11.75         1\n5  Marina  Brandner    10.15         0\n6    Onno Schreiner    12.50         0\n\n\n\nAlle in der Treatment-Gruppe und einem BDI-Wert größer als 10:\n\n\ndat2[dat2$treatment == 1 & dat2$bdi.wert &gt; 10,]\n\n     name nachname bdi.wert treatment\n1  Stefan Tegemann    13.00         1\n4 Sylvain  Laffont    11.75         1\n\n\n\nAlle in der Treatment-Gruppe oder einem BDI-Wert größer als 10:\n\n\ndat2[dat2$treatment == 1 | dat2$bdi.wert &gt; 10,]\n\n     name  nachname bdi.wert treatment\n1  Stefan  Tegemann    13.00         1\n2    Eike      &lt;NA&gt;     9.95         1\n3 Annette      &lt;NA&gt;     9.85         1\n4 Sylvain   Laffont    11.75         1\n5  Marina  Brandner    10.15         0\n6    Onno Schreiner    12.50         0\n\n\n\nAlle, deren Vorname mit “S” beginnt:\n\n\ndat2[grep(\"^S\", dat2$name),]\n\n     name nachname bdi.wert treatment\n1  Stefan Tegemann    13.00         1\n4 Sylvain  Laffont    11.75         1\n\n\n\nAlle, für die kein Nachname hinterlegt ist:\n\n\ndat2[is.na(dat2$nachname),]\n\n     name nachname bdi.wert treatment\n2    Eike     &lt;NA&gt;     9.95         1\n3 Annette     &lt;NA&gt;     9.85         1\n\n\n\nDer Datensatz ohne Personen, für die kein Nachname hinterlegt ist:\n\n\ndat2[!is.na(dat2$nachname),]\n\n     name  nachname bdi.wert treatment\n1  Stefan  Tegemann    13.00         1\n4 Sylvain   Laffont    11.75         1\n5  Marina  Brandner    10.15         0\n6    Onno Schreiner    12.50         0\n\n\noder\n\ndat2[-which(is.na(dat2$nachname)),]\n\n     name  nachname bdi.wert treatment\n1  Stefan  Tegemann    13.00         1\n4 Sylvain   Laffont    11.75         1\n5  Marina  Brandner    10.15         0\n6    Onno Schreiner    12.50         0",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Data.frames, Listen & Plots"
    ]
  },
  {
    "objectID": "docs/R/ws2.html#rekodieren-von-variablen-in-data.frames",
    "href": "docs/R/ws2.html#rekodieren-von-variablen-in-data.frames",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "",
    "text": "Wenn man bestimmte Werte im data.frame ersetzen möchte oder Variablen in andere Variablen umkodieren möchte, hat man verschiedene Möglichkeiten.\n\nAlle Werte im Datensatz ersetzen:\n\n\n\n\nz.B. alle fehlenden Werte durch einen bestimmten Missingcode ersetzen:\n\n\ndat2[is.na(dat2)] &lt;- \"-97\"\ndat2\n\n     name  nachname bdi.wert treatment\n1  Stefan  Tegemann    13.00         1\n2    Eike       -97     9.95         1\n3 Annette       -97     9.85         1\n4 Sylvain   Laffont    11.75         1\n5  Marina  Brandner    10.15         0\n6    Onno Schreiner    12.50         0\n\n\n\noder einen bestimmen Wert durch andere Werte oder Missings ersetzen:\n\n\ndat2[dat2==\"-97\"] &lt;- NA\ndat2\n\n     name  nachname bdi.wert treatment\n1  Stefan  Tegemann    13.00         1\n2    Eike      &lt;NA&gt;     9.95         1\n3 Annette      &lt;NA&gt;     9.85         1\n4 Sylvain   Laffont    11.75         1\n5  Marina  Brandner    10.15         0\n6    Onno Schreiner    12.50         0\n\n\n\nNeue Variablen in Abhängigkeit von anderen Variablen bilden\n\nMit der Funktion ifelse formuliert man zunächst eine Bedingung (hier alle, die einen BDI kleiner als 10 haben und gleichzeitig in der Treatment-Gruppe sind), danach gibt man durch ein Komma abgetrennt an, welche Werte in der neuen Variable stehen sollen (hier \"Treatment war wirksam\"). Durch ein weiteres Komma abgetrennt kann dann angegeben werden, was passieren soll, wenn die Bedingung nicht zutrifft. Dabei kann dort sogar ein weiteres ifelse-Statement eingefügt werden, wie hier im Beispiel, das nach genau denselben Regeln aufgebaut ist.\n\ndat2$neueVar &lt;- ifelse(test=dat2$bdi.wert &lt; 10 & dat2$treatment==1,\n                       yes=\"Treatment war wirksam\",  \n                       no = ifelse(test=dat2$bdi.wert &gt;= 10 & dat2$treatment==1,   \n                                   yes=\"Treatment nicht wirksam\",\n                                   no=\"kein Treatment\"))\ndat2\n\n     name  nachname bdi.wert treatment                 neueVar\n1  Stefan  Tegemann    13.00         1 Treatment nicht wirksam\n2    Eike      &lt;NA&gt;     9.95         1   Treatment war wirksam\n3 Annette      &lt;NA&gt;     9.85         1   Treatment war wirksam\n4 Sylvain   Laffont    11.75         1 Treatment nicht wirksam\n5  Marina  Brandner    10.15         0          kein Treatment\n6    Onno Schreiner    12.50         0          kein Treatment\n\n\nAuch kann die Funktion recode aus dem Paket car verwendet werden. Hier werden die Werte oder Wertebereiche einer Variablen umkodiert. Der Wertebereich des niedrigsten aufgetretenen Wertes bis zum Wert 10 entspricht dem hier benutzten Statement lo:10. Wie man mit allen nicht explizit erwähnten Werten verfahren möchte, kann mit dem else-Argument festlegen.\n\nlibrary(car)\n\n\ndat2$neueVar &lt;- car::recode(dat2$bdi.wert, \"lo:10='leichte Depression'; else='schwere Depression'\")\ndat2\n\n     name  nachname bdi.wert treatment            neueVar\n1  Stefan  Tegemann    13.00         1 schwere Depression\n2    Eike      &lt;NA&gt;     9.95         1 leichte Depression\n3 Annette      &lt;NA&gt;     9.85         1 leichte Depression\n4 Sylvain   Laffont    11.75         1 schwere Depression\n5  Marina  Brandner    10.15         0 schwere Depression\n6    Onno Schreiner    12.50         0 schwere Depression",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Data.frames, Listen & Plots"
    ]
  },
  {
    "objectID": "docs/R/ws2.html#umstrukturieren-von-data.frames",
    "href": "docs/R/ws2.html#umstrukturieren-von-data.frames",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "",
    "text": "Unser Datensatz befindet sich im sogenannten Wide-Format. Für manche Anwendungen kann es sinnvoll sein, den Datensatz in das sogenannte Long-Format zu bringen, in dem alle Werte der Personen in einer einzigen Variablen untereinander stehen. Früher benutzte man das Paket reshape2, um einen Datensatz ins Long-Format zu bringen, was auch jetzt noch immer unkompliziert möglich ist:\n\nlibrary(reshape2)\n\n\ndatl &lt;- reshape2::melt(dat, id.vars=\"ID\")\ndatl\n\n      ID   variable     value\n1  43678       name    Stefan\n2  67743       name      Eike\n3  69781       name   Annette\n4  88475       name   Sylvain\n5  88766       name    Marina\n6  89045       name      Onno\n7  43678 geschlecht         m\n8  67743 geschlecht         m\n9  69781 geschlecht         w\n10 88475 geschlecht         m\n11 88766 geschlecht         w\n12 89045 geschlecht         m\n13 43678  treatment         1\n14 67743  treatment         1\n15 69781  treatment         1\n16 88475  treatment         1\n17 88766  treatment         0\n18 89045  treatment         0\n19 43678   bdi.wert        13\n20 67743   bdi.wert      9.95\n21 69781   bdi.wert      9.85\n22 88475   bdi.wert     11.75\n23 88766   bdi.wert     10.15\n24 89045   bdi.wert      12.5\n25 43678   nachname  Tegemann\n26 67743   nachname      &lt;NA&gt;\n27 69781   nachname      &lt;NA&gt;\n28 88475   nachname   Laffont\n29 88766   nachname  Brandner\n30 89045   nachname Schreiner\n\n\nund mit dcast() formte man den Datensatz wieder zurück:\n\nreshape2::dcast(datl, ID ~ variable)\n\n     ID    name geschlecht treatment bdi.wert  nachname\n1 43678  Stefan          m         1       13  Tegemann\n2 67743    Eike          m         1     9.95      &lt;NA&gt;\n3 69781 Annette          w         1     9.85      &lt;NA&gt;\n4 88475 Sylvain          m         1    11.75   Laffont\n5 88766  Marina          w         0    10.15  Brandner\n6 89045    Onno          m         0     12.5 Schreiner\n\n\nIn jüngerer Zeit wurden dazu recht effiziente Funktionen entwickelt, die im Paket tidyr zu finden sind. Hier wird nur rudimentär in die Benutzung dieser Funktionen eingeführt – der/die interessierte Leser/in mag sich in folgende Seite vertiefen: http://tidyr.tidyverse.org/articles/pivot.html Hierbei ist zu beachten, dass bei Benutzung des Pakets tidyr die data.frames zu anderen Objekten werden, nämlich tibbles (die aber problemlos mit der Funktion as.data.frame() wieder in data.frames zurücktransformiert werden können. Darüber hinaus weicht die zu verwendende Syntax hier deutlich von der bisher gezeigten basalen R-Syntax ab. Eine besondere Rolle spielt hier der sogenannte Pipe-Operator %&gt;%, über den hier http://www.rdocumentation.org/packages/magrittr/versions/1.0.1/topics/%25%3E%25 oder an anderer Stelle weitergelesen werden kann.\n\nlibrary(tidyr)\n\nUmstrukturierung unserer Daten ins Long-Format:\n\ndat %&gt;% pivot_longer(\n  cols=name:nachname,\n  names_to = \"variable\",\n  values_to = \"value\"\n)\n\noder, äquivalent dazu, mit:\n\npivot_longer(dat, cols=name:nachname, names_to = \"variable\", values_to = \"value\")\n\n# A tibble: 30 × 3\n      ID variable   value   \n   &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;   \n 1 43678 name       Stefan  \n 2 43678 geschlecht m       \n 3 43678 treatment  1       \n 4 43678 bdi.wert   13      \n 5 43678 nachname   Tegemann\n 6 67743 name       Eike    \n 7 67743 geschlecht m       \n 8 67743 treatment  1       \n 9 67743 bdi.wert   9.95    \n10 67743 nachname   &lt;NA&gt;    \n# ℹ 20 more rows\n\n\nund mit pivot_wider() kann man den Datensatz wieder zurück formen:\n\ndatl  %&gt;% pivot_wider(\n  names_from = variable, values_from = value\n)\n\noder genauso:\n\npivot_wider(datl, names_from = variable, values_from = value)\n\n# A tibble: 6 × 6\n     ID name    geschlecht treatment bdi.wert nachname \n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;    \n1 43678 Stefan  m          1         13       Tegemann \n2 67743 Eike    m          1         9.95     &lt;NA&gt;     \n3 69781 Annette w          1         9.85     &lt;NA&gt;     \n4 88475 Sylvain m          1         11.75    Laffont  \n5 88766 Marina  w          0         10.15    Brandner \n6 89045 Onno    m          0         12.5     Schreiner",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Data.frames, Listen & Plots"
    ]
  },
  {
    "objectID": "docs/R/ws2.html#subsetting-in-listen",
    "href": "docs/R/ws2.html#subsetting-in-listen",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "2.1 Subsetting in Listen",
    "text": "2.1 Subsetting in Listen\nAuch bei Listen gibt es wieder zwei Möglichkeiten, wie man auf die Elemente zugreifen kann:\n\nÜber den Index, z.B. wenn man im dritten Listenelement weitere Unterelemente ansteuern möchte, wie hier die zweite Spalte und die fünfte Zeile:\n\n\nL1[[3]][5,2]\n\n[1] \"Brandner\"\n\n\n\nÜber den Namen in Anführungszeichen oder mit vorangestelltem Dollar-Zeichen:\n\n\nL1[[\"Gesamt\"]][5,2]\n\n[1] \"Brandner\"\n\nL1[[\"Gesamt\"]][5,\"nachname\"]\n\n[1] \"Brandner\"\n\nL1$Gesamt$nachname[5]\n\n[1] \"Brandner\"\n\n\nEine Teilliste der Liste kann aufgerufen werden, indem die einzelnen Komponenten indiziert werden:\n\nL1[c(1,2)]\n\n$Werte\n[1] 12.50 13.00 11.75  9.85 10.15  9.95\n\n$Nachnamen\n[1] \"Tegemann\"  \"Laffont\"   \"Brandner\"  \"Schreiner\"",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Data.frames, Listen & Plots"
    ]
  },
  {
    "objectID": "docs/R/ws2.html#merging-von-listen",
    "href": "docs/R/ws2.html#merging-von-listen",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "2.2 Merging von Listen",
    "text": "2.2 Merging von Listen\nListen können kombiniert werden, indem sie mit c() verbunden werden:\n\nL2 &lt;- c(L1[2], L1[1])\nL2\n\n$Nachnamen\n[1] \"Tegemann\"  \"Laffont\"   \"Brandner\"  \"Schreiner\"\n\n$Werte\n[1] 12.50 13.00 11.75  9.85 10.15  9.95\n\n\nWeitere Komponenten können über Neuindizierung oder Namen hinzugefügt werden:\n\nL2[[3]] &lt;- TRUE\nL2$nochwas &lt;- FALSE\nL2[[\"undnochwas\"]] &lt;- data.frame(wahr=c(FALSE,TRUE,TRUE),falsch=c(TRUE,TRUE,FALSE))\nL2\n\n$Nachnamen\n[1] \"Tegemann\"  \"Laffont\"   \"Brandner\"  \"Schreiner\"\n\n$Werte\n[1] 12.50 13.00 11.75  9.85 10.15  9.95\n\n[[3]]\n[1] TRUE\n\n$nochwas\n[1] FALSE\n\n$undnochwas\n   wahr falsch\n1 FALSE   TRUE\n2  TRUE   TRUE\n3  TRUE  FALSE\n\n\nSollen Komponenten entfernt werden, kann man wieder den Minus-Operator benutzen:\n\nL2 &lt;- L2[-c(3,4)]\nL2\n\n$Nachnamen\n[1] \"Tegemann\"  \"Laffont\"   \"Brandner\"  \"Schreiner\"\n\n$Werte\n[1] 12.50 13.00 11.75  9.85 10.15  9.95\n\n$undnochwas\n   wahr falsch\n1 FALSE   TRUE\n2  TRUE   TRUE\n3  TRUE  FALSE",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Data.frames, Listen & Plots"
    ]
  },
  {
    "objectID": "docs/R/ws2.html#aufheben-der-listenstruktur",
    "href": "docs/R/ws2.html#aufheben-der-listenstruktur",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "2.3 Aufheben der Listenstruktur",
    "text": "2.3 Aufheben der Listenstruktur\nMöchte man keine Liste mehr haben, hilft die Funktion unlist() weiter, die alle Elemente der Liste nacheinander in einen benannten Vektor schreibt, dessen Namen man aber auch entfernen kann:\n\n(L3 &lt;- unlist(L2))\n\n        Nachnamen1         Nachnamen2         Nachnamen3         Nachnamen4 \n        \"Tegemann\"          \"Laffont\"         \"Brandner\"        \"Schreiner\" \n            Werte1             Werte2             Werte3             Werte4 \n            \"12.5\"               \"13\"            \"11.75\"             \"9.85\" \n            Werte5             Werte6   undnochwas.wahr1   undnochwas.wahr2 \n           \"10.15\"             \"9.95\"            \"FALSE\"             \"TRUE\" \n  undnochwas.wahr3 undnochwas.falsch1 undnochwas.falsch2 undnochwas.falsch3 \n            \"TRUE\"             \"TRUE\"             \"TRUE\"            \"FALSE\" \n\nunname(unlist(L2))\n\n [1] \"Tegemann\"  \"Laffont\"   \"Brandner\"  \"Schreiner\" \"12.5\"      \"13\"       \n [7] \"11.75\"     \"9.85\"      \"10.15\"     \"9.95\"      \"FALSE\"     \"TRUE\"     \n[13] \"TRUE\"      \"TRUE\"      \"TRUE\"      \"FALSE\"",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Data.frames, Listen & Plots"
    ]
  },
  {
    "objectID": "docs/R/ws2.html#balkendiagramme",
    "href": "docs/R/ws2.html#balkendiagramme",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "1.1 Balkendiagramme",
    "text": "1.1 Balkendiagramme\nZ.B. Verteilung des BDI-Werts:\n\nbarplot(bdi.wert ~ name, data=dat2)\n\n\n\n\n\n\n\n\nFür einfache Häufigkeitsverteilungen:\n\nhist(dat2$bdi.wert)\n\n\n\n\n\n\n\n\nBoxplots:\n\nboxplot(bdi.wert ~ treatment, data=dat2)",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Data.frames, Listen & Plots"
    ]
  },
  {
    "objectID": "docs/R/ws2.html#die-plot-funktion-und-mehrere-grafiken-neben--oder-untereinander",
    "href": "docs/R/ws2.html#die-plot-funktion-und-mehrere-grafiken-neben--oder-untereinander",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "1.2 Die plot()-Funktion und mehrere Grafiken neben- oder untereinander",
    "text": "1.2 Die plot()-Funktion und mehrere Grafiken neben- oder untereinander\nMöchte man in einem Fenster mehrere Grafiken unter- oder nebeneinander darstellen, kann man sich des Parameters mfrow der par()-Funktion bedienen. Die erste Zahl gibt an, in wie vielen Grafiken die Zeilen untereinander dargestellt werden sollen und die zweite Zahl, in wie vielen Spalten nebeneinander. Sollen die Daten zunächst geplottet werden und daneben deren Verteilung (im Beispiel nur bedingt sinnvoll), sieht das so aus:\n\npar(mfrow=c(1,2))\nplot(dat2$bdi.wert)\nplot(density(dat2$bdi.wert),main=\"Eine Verteilung\")",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Data.frames, Listen & Plots"
    ]
  },
  {
    "objectID": "docs/R/ws2.html#das-paket-ggplot2",
    "href": "docs/R/ws2.html#das-paket-ggplot2",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "1.3 Das Paket ggplot2",
    "text": "1.3 Das Paket ggplot2\nEin mächtiges Paket zur Erstellung von Grafiken ist ggplot2, zu dem z.B. unter diesem Link eine gute Einführung gegeben wird: http://methodenlehre.github.io/einfuehrung-in-R/grafiken-mit-ggplot2.html",
    "crumbs": [
      "R-Sig",
      "R Tutorials",
      "Introduction",
      "Data.frames, Listen & Plots"
    ]
  },
  {
    "objectID": "docs/reproduce/renv.html",
    "href": "docs/reproduce/renv.html",
    "title": "The renv-Package",
    "section": "",
    "text": "Reproducibility\nProject repo for reproducibility research. Currently, we are working on making the BT21 reproducible by using the renv-Package in R.\n\n\nrenv\nThe renv-package is intended for simple project-local R dependency management. Here you’ll find a more thorough introduction.\n\n\nSetup\n\nCreate an RStudio Project in the working directory that should be made reproducible.\nIf another R-version should be used, switch to that version. On Windows, you can simply install multiple versions of R and switch between them in RStudio by going to Tools - Global Options - General. Maybe you will have to install renv for this version again.\nInitialise the project using renv::init(). This creates the basic infrastructure for the usage of renv.\n\n\nDependencies should be discovered automatically. It can take a while, if you’re doing this for the first time.\nIf you want to install specific package versions, you can use renv::intit(bare = TRUE).\n\nThis sets up the renv project without trying to find the used dependencies. Thus, you can install the specific versions manually afterwards.\n\nThe dependencies in the working directory can be obtained by renv::dependencies().\n\n\n\nIf you want specific package versions, you can use renv::install(packagename/@version-number). Local packages or packages from GitHub can be installed as well (see here).\nIn the end, packages should be installed in ./renv/library. A lockfile ./renv.lock is created, where the R version and the package versions are noted.\nNow you can work with the project. If you update dependencies, for example when you install and/or load new packages, you can save the state of the project library to the lockfile using renv::snapshot().\nIf you want to restore the state of the project library as noted in the lockfile, use renv::restore().\n\n\n\nProject usage\n\nFor maximal reproducibility, check the lockfile for the R-version before working with renv. If another R-version is documented in the lockfile, you can change the R-version before reproducing an analysis, see 2).\nAs the packages are directly installed into the project working directory, you should be able to simply work with the renv-project as saved by the last user without doing anything.\n\n\n\nNote on Package Versions\nMRAN can be used to get snapshots of R on any day back to 17.09.2014. Here, package versions on specific dates can be found, for example, when a script was finished on 06.05.22, the packages probably used can be obtained from here. Sometimes an error similar to this can occur:\nError: install of package 'tidyselect' failed [error code 1]\nIn this case it is possible to look up the package version on the respective date on MRAN and install this version manually. On 06.05.22, CRAN hosted Version 1.1.2 of tidyselect, so you install the version like so: renv::install(\"tidyselect@1.1.2\").",
    "crumbs": [
      "R-Sig",
      "Reproducibility",
      "The renv-Package"
    ]
  },
  {
    "objectID": "docs/FAQ/FAQ.html",
    "href": "docs/FAQ/FAQ.html",
    "title": "FAQ",
    "section": "",
    "text": "Die Quadratwurzel aus \\(R^2\\) ziehen; eine Fisher z-Transformation durchführen, damit der Wertebereich auf alle reellen Zahlen ausgeweitet wird; Rubins Regeln für metrische Variablen anwenden; mit einer inversen z-Transformation den Wert wieder zurückrechnen und quadrieren\n\n\n\nDie Funktion wird momentan noch nicht auf den Namensraum (Namespace) des Pakets exportiert, was allerdings ab der nächsten Paketversion möglich sein wird. Angenommen, aus einer Analyse multipel imputierter Daten resultieren 5 verschiedene (hier fiktive) \\(R^2\\)-Werte, dann kann der gepoolte \\(R^2\\)-Wert folgendermaßen bestimmt werden: r2 &lt;- c(0.12,0.18,0.17,0.21,0.23); eatRep:::pool.R2(r2)\nHarel, O. (2009). The estimation of R2 and adjusted R2 in incomplete data sets using multiple imputation. Journal of Applied Statistics, 36(10), 1109-1118."
  },
  {
    "objectID": "docs/FAQ/FAQ.html#wie-poole-ich-mein-r2-richtig-über-mehrere-bspw.-15-imputationen",
    "href": "docs/FAQ/FAQ.html#wie-poole-ich-mein-r2-richtig-über-mehrere-bspw.-15-imputationen",
    "title": "FAQ",
    "section": "",
    "text": "Die Quadratwurzel aus \\(R^2\\) ziehen; eine Fisher z-Transformation durchführen, damit der Wertebereich auf alle reellen Zahlen ausgeweitet wird; Rubins Regeln für metrische Variablen anwenden; mit einer inversen z-Transformation den Wert wieder zurückrechnen und quadrieren\n\n\n\nDie Funktion wird momentan noch nicht auf den Namensraum (Namespace) des Pakets exportiert, was allerdings ab der nächsten Paketversion möglich sein wird. Angenommen, aus einer Analyse multipel imputierter Daten resultieren 5 verschiedene (hier fiktive) \\(R^2\\)-Werte, dann kann der gepoolte \\(R^2\\)-Wert folgendermaßen bestimmt werden: r2 &lt;- c(0.12,0.18,0.17,0.21,0.23); eatRep:::pool.R2(r2)\nHarel, O. (2009). The estimation of R2 and adjusted R2 in incomplete data sets using multiple imputation. Journal of Applied Statistics, 36(10), 1109-1118."
  },
  {
    "objectID": "docs/FAQ/FAQ.html#dif-richtung-in-conquesteatmodel-was-bedeuten-negative-werte-in-der-estdif-spalte",
    "href": "docs/FAQ/FAQ.html#dif-richtung-in-conquesteatmodel-was-bedeuten-negative-werte-in-der-estdif-spalte",
    "title": "FAQ",
    "section": "2. DIF-Richtung in Conquest/eatModel: Was bedeuten negative Werte in der “estDif”-Spalte?",
    "text": "2. DIF-Richtung in Conquest/eatModel: Was bedeuten negative Werte in der “estDif”-Spalte?\nIn eatModel wird nur der erste Teil der zweiten Tabelle item*[DIFvariable] aus Conquest übertragen. Das bedeutet, dass negative Werte in der eatModel-estDif-Spalte dafür stehen, dass die jeweiligen Items in der ersten Gruppe der [DIFvariable] leichter sind. Die erste Gruppe ist die mit dem numerisch kleineren Gruppenindikatorwert."
  },
  {
    "objectID": "docs/FAQ/FAQ.html#zentrierung-um-den-gesamtmittelwert-grand-mean-centering-oder-um-den-gruppenmittelwert-group-mean-centering-und-bedeutung-für-interaktionen-in-mehrebenenmodellen",
    "href": "docs/FAQ/FAQ.html#zentrierung-um-den-gesamtmittelwert-grand-mean-centering-oder-um-den-gruppenmittelwert-group-mean-centering-und-bedeutung-für-interaktionen-in-mehrebenenmodellen",
    "title": "FAQ",
    "section": "3. Zentrierung um den Gesamtmittelwert (Grand-Mean-Centering) oder um den Gruppenmittelwert (Group-Mean-Centering) und Bedeutung für Interaktionen in Mehrebenenmodellen",
    "text": "3. Zentrierung um den Gesamtmittelwert (Grand-Mean-Centering) oder um den Gruppenmittelwert (Group-Mean-Centering) und Bedeutung für Interaktionen in Mehrebenenmodellen\nWenn in Mehrebenenmodellen Interaktionen geschätzt werden, hängt die Schätzung des Intercepts wie auch die der Haupteffekte von der gewählten Skala der Prädiktoren ab. Die Haupteffekte repräsentieren den Effekt eines Prädiktors an der Stelle, an der die anderen Prädiktoren null sind. Da die Null oftmals kein natürlicher Wert von Prädiktoren ist (z. B. ist die Interpretation eines Effekts an der Stelle Klassengröße = 0 i. d. R. nicht sehr sinnvoll), wird das Zentrieren der Prädiktoren empfohlen. Hier kommen zwei Varianten in Frage: Zentrierung am Gruppenmittelwert und Zentrierung am Gesamtmittelwert. Für einen Prädiktor \\(X\\), der an Individuum \\(i\\) (\\(\\forall i \\in \\{1,…,i,…,n\\}\\)) in Gruppe \\(j\\) (\\(\\forall j \\in \\{1,…,j,…,J\\}\\)) erhoben wird, bedeutet eine Zentrierung am Gesamtmittelwert, dass man von diesem individuellen Wert \\(x_{ij}\\) den Gesamtmittelwert \\(M_X\\) abzieht, gemäß: \\(X_{ij}-M_X\\). Eine Zentrierung am Gruppenmittelwert bedeutet, dass man vom individuellen Wert \\(x_{ij}\\) den Mittelwert der jeweiligen Gruppe abzieht, gemäß: \\(X_{ij}-M_{X_j}\\) Hier eine grafische Darstellung dieser Zentrierungsmöglichkeiten eines Prädiktors:\n\n\n\nZentrierungsmöglichkeiten\n\n\nHier ist derselbe Prädiktor in seinen drei Zentrierungsformen in Relation zu einem Outcome abgebildet:\n\n\n\ndrei Zentrierungsformen in Relation zu einem Outcome\n\n\nWenn man nun eine einfache lineare Regression eines Outcomes auf den Prädiktor rechnet, kann man die Haupteffekte (Slopes) des unzentrierten Prädiktors und des Grand-Mean-zentrierten Prädiktors genau gleich interpretieren: Der Regressionskoeffizient beschreibt die Veränderung des Outcomes, wenn der Prädiktor um eine Einheit ansteigt. Dies gilt nicht für den Group-Mean-zentrierten Prädiktor: Dieser repräsentiert die erwartete Veränderung des Outcomes bei Zunahme des Prädiktors um eine durchschnittliche Einheit innerhalb der Gruppen.\n\na. Zentrierung um den Gruppenmittelwert: Schätzung von Individual- und Aggregateffekten unabhängig voneinander.\nDie Zentrierung um den Gruppenmittelwert ermöglicht die Trennung der individuellen Variation innerhalb der Gruppen von der Variation zwischen den Gruppen. Dadurch können sowohl die Effekte auf der Individualebene als auch die Effekte auf der Gruppenebene unabhängig voneinander geschätzt werden.\n\nInterpretation von Level-1-Variablen-Interaktionen: Zeigt an, wie sich die lineare Beziehung zwischen Variablen innerhalb der Gruppen gestaltet.\nInterpretation von Level-2-Variablen-Interaktionen: Zeigt an, wie sich die lineare Beziehung der Variablen zwischen den Gruppen gestaltet – allerdings wird hier nicht voll kontrolliert für Level-1-Prädiktoren, sofern nicht zusätzlich noch die Gruppenmittelwerte der zu kontrollierenden Level-1-Variablen aufgenommen werden, sodass die Zentrierung um den Gruppenmittelwert für diesen Zweck von manchen Autor:innen als weniger sinnvoll erachtet wird (Algina & Swaminathan, 2011).\nInterpretation von Cross-Level-Interaktionen: Bei der Untersuchung von Interaktionen zeigt ein Interaktionseffekt zwischen einer um den Gruppenmittelwert zentrierten individuellen Variablen (Level-1) und einer gruppenbezogenen Variablen (Level-2), inwiefern der Effekt der individuellen Variablen von der gruppenbezogenen Variablen abhängt: Hat eine höhere Ausprägung auf einer Level-1-Variablen relativ zum Gruppenmittelwert auf dieser Variablen einen anderen Effekt auf das Kriterium, wenn die Ausprägung einer Level-2-Variablen für die Gruppe höher ist? Der Koeffizient sollte sich gemäß Algina und Swaminathan (2011) nicht bedeutsam unterscheiden von dem, der durch Zentrierung um den Gesamtmittelwert geschätzt wird, aber falls doch, empfehlen die Autoren, diese Cross-Level-Interaktion aus dem Modell zu entfernen. Andere Autor:innen empfehlen nur Group-Mean-Centering der Level-1- und Grand-Mean-Centering der Level-2-Prädiktoren bei Untersuchung von Cross-Level-Interaktionen, da so die Interpretation der Haupteffekte erleichtert wird (z.B. Bauer & Curran, 2005). Mehrere Autor:innen (z. B. Yaremych et al., 2023) plädieren bei Cross-Level-Interaktionen im Allgemeinen für diese Art der Zentrierung, da sie meistens den formulierten Cross-Level-Interaktions-Hypothesen entspricht.\n\n\n\nb. Zentrierung um den Gesamtmittelwert: Führt zu einfacher Interpretation des Intercepts, aber auch zu “Overall-Regression”.\nDie Zentrierung um den Gesamtmittelwert ermöglicht die Untersuchung der Effekte in Bezug auf den Mittelwert der gesamten Stichprobe. Das Intercept entspricht dem erwarteten Wert auf der Kriteriumsvariablen bei durchschnittlicher Ausprägung der Prädiktorvariablen. Die Effekte zwischen und innerhalb der Untersuchungseinheiten lassen sich nicht mehr getrennt interpretieren („Overall-Regression“).\n\nInterpretation von Level-1-Variablen-Interaktionen: Zeigt an, wie sich die lineare Beziehung der Variablen über alle Gruppen hinweg gestaltet.\nInterpretation von Level-2-Variablen-Interaktionen: Zeigt an, wie sich die lineare Beziehung der Variablen zwischen den Gruppen gestaltet (ggf. vollständig kontrolliert für Level-1-Prädiktoren). Diese Form der Zentrierung wird zu solchem Zweck meist empfohlen (Algina & Swaminathan, 2011).\nInterpretation von Cross-Level-Interaktionen: Bei der Untersuchung von Interaktionen zeigt ein Interaktionseffekt zwischen einer um den Gesamtmittelwert zentrierten individuellen Variablen (Level-1) und einer gruppenbezogenen Variablen (Level-2), wie der Effekt der individuellen Variablen über alle Gruppen hinweg von der gruppenbezogenen Variablen abhängt: Hat eine höhere absolute Ausprägung auf einer Level-1-Variablen einen anderen Effekt auf das Kriterium, wenn die Ausprägung einer Level-2-Variablen für die Gruppe höher ist? Algina und Swaminathan (2011) plädieren dafür, diese Cross-Level-Interaktion aus dem Modell zu entfernen, sollte sich der Effekt deutlich unterscheiden von der alternativen Schätzung nach Zentrierung um den Gruppenmittelwert.\n\n\n\nc. Keine Zentrierung: Ist selten sinnvoll bei Interaktionen im Modell. Vor allem dann nicht, wenn die Null für die Prädiktorvariablen kein sinnvoller Wert ist.\nAlle Empfehlungen gelten ebenso für kategoriale Prädiktoren, siehe z. B. Yaremych et al. (2023): “… we have demonstrated that centering guidelines for continuous predictors should be applied analogously to categorical predictors” (p. 8). Hierbei wird ein \\(k-\\)stufiger Prädiktor stets durch \\(k-1\\) “Coding-Variablen” repräsentiert. Ob diese durch Dummy-Kodierung, Effekt-Kodierung oder Kontrast-Kodierung gebildet werden, hängt von der intendierten Interpretation ab und liegt außerhalb des Fokus’ dieses Artikels.\n\n\nLiteratur\nAlgina, J., & Swaminathan, H. (2011). Centering in two-level nested designs. In J. Hox & K. Roberts (Eds.), The handbook of advanced multilevel data analysis (pp. 285–312). Routledge.\nBauer, D.J., & Curran, P.J. (2005). Probing interactions in fixed and multilevel regression: Inferential and graphical techniques. Multivariate Behavioral Research, 40, 373–400. https://doi.org/10.1207/s15327906mbr4003_5\nYaremych, H. E., Preacher, K. J., & Hedeker, D. (2023). Centering categorical predictors in multilevel models: Best practices and interpretation. Psychological Methods, 28(3), 613–630. https://doi.org/10.1037/met0000434"
  },
  {
    "objectID": "docs/FAQ/FAQ.html#section",
    "href": "docs/FAQ/FAQ.html#section",
    "title": "FAQ",
    "section": "",
    "text": "Weitere Fragen und/oder deren Antworten können abgelegt und eingesehen werden unter: t:/SIG/SIG Methoden/Liste methodischer Fragen.docx"
  }
]