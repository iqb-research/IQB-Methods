[
  {
    "objectID": "posts_newsletter.html",
    "href": "posts_newsletter.html",
    "title": "Newsletter",
    "section": "",
    "text": "26-08-2024\n\n\n\n\n\n\neatPrepTBA\n\n\neatAutoCode\n\n\neatPrerp\n\n\neatTools\n\n\nWorkshop\n\n\nR-SIG\n\n\nSIG Methoden\n\n\n\nNewsletter\n\n\n\n\n\nAug 26, 2024\n\n\nKaroline Sachse\n\n\n\n\n\n\n\n\n\n\n\n\n12-01-2024\n\n\n\n\n\n\nMethoden-Webseite\n\n\neatTools\n\n\n\nNewsletter\n\n\n\n\n\nJan 12, 2024\n\n\nNicklas Hafiz\n\n\n\n\n\n\n\n\n\n\n\n\n09-08-2023\n\n\n\n\n\n\neatGADS\n\n\n\nNewsletter\n\n\n\n\n\nAug 9, 2023\n\n\nBenjamin Becker\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "docs/workflow.html",
    "href": "docs/workflow.html",
    "title": "Workflow",
    "section": "",
    "text": "1\nWelcome to our workflow learn page. Here you can find articles explaining how to work with Git/Github and Quarto, or some info about our code conventions."
  },
  {
    "objectID": "docs/workflow.html#articles-and-workshops",
    "href": "docs/workflow.html#articles-and-workshops",
    "title": "Workflow",
    "section": "Articles and Workshops",
    "text": "Articles and Workshops"
  },
  {
    "objectID": "docs/workflow.html#footnotes",
    "href": "docs/workflow.html#footnotes",
    "title": "Workflow",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFoto von Simon Berger auf Unsplash↩︎"
  },
  {
    "objectID": "docs/r_sig/23_10_09_cleaner/index.html",
    "href": "docs/r_sig/23_10_09_cleaner/index.html",
    "title": "Cleaner Scripts",
    "section": "",
    "text": "1"
  },
  {
    "objectID": "docs/r_sig/23_10_09_cleaner/index.html#code-conventionsstyle-guides",
    "href": "docs/r_sig/23_10_09_cleaner/index.html#code-conventionsstyle-guides",
    "title": "Cleaner Scripts",
    "section": "Code conventions/Style Guides",
    "text": "Code conventions/Style Guides\nFor general code styling, multiple style guides exist:\n\nTidyverse Style Guide\nGoogle R Style Guide\nCode Konventionen Methodenteam IQB"
  },
  {
    "objectID": "docs/r_sig/23_10_09_cleaner/index.html#some-general-things-we-can-look-at-when-refactoring-code",
    "href": "docs/r_sig/23_10_09_cleaner/index.html#some-general-things-we-can-look-at-when-refactoring-code",
    "title": "Cleaner Scripts",
    "section": "Some general things we can look at when refactoring code",
    "text": "Some general things we can look at when refactoring code\n\n\n\n\n\n\nNote\n\n\n\nRefactoring is the process of making many small improvements to code without altering the code’s output/result.\n\n\n\nMarkdown vs. Quarto vs. R-Skripte\nMarkdown has more dependencies, so I would now use .R files if I don’t need the markdown features. In general however, I would highly recommend to work with Quarto, some use cases can be found in our Quarto-Tutorial.\nQuarto is just the newer R-Markdown, with more features and bringing the R-Markdown magic to new programming languages.\n\n\nLoad data\nIt should always be clear which data is loaded and why. Paths should work, so keep that in mind when dependent folders are moved.\n\n\nWrite packages on top of the script.\nAt the very minimum, write down version number (use sessionInfo()).\nThis way, it is kind of reproducable which packages you used for the script.\nMuch much better and definitily recommended: using renv or repro for your R-project.\n\n\nDuplications\nDuplication should be avoided.\nThey make the code less readable and more error-prone. The most important tools to avoid duplication in R are:\n\nFunctions\nEvery time we do something more than once/twice, we should write that into a function This has several advantages:\n\nWe can give the function a name that conveys to the user what happens in the function. This makes the code more readable.\n\nWe can easily make changes to the function once and don’t have to update it every time the action is performed.\n\nWhen the cursor is in the function name, we can press F2 to quickly jump to the function definition.\nWe can put our functions into another file\n\n\nLoops\nLoops and apply-functions help us to repeat actions multiple times.\n\n\n\nCompartmentalization\nIt makes sense to split big scripts into multiple smaller ones.\nThis also increases readability and makes it easier to get an overview of what happens in a project. For example, we could put our self-defined functions into a functions.R script and load it into our main script with source(\"functions.R\")\n\n\nVersion Control\nUse Version Control for your code. A great option is Git and in addition GitHub."
  },
  {
    "objectID": "docs/r_sig/23_10_09_cleaner/index.html#footnotes",
    "href": "docs/r_sig/23_10_09_cleaner/index.html#footnotes",
    "title": "Cleaner Scripts",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Markus Spiske on Unsplash.↩︎"
  },
  {
    "objectID": "docs/r_sig/24_03_25_tidyverse_wrangling/index.html",
    "href": "docs/r_sig/24_03_25_tidyverse_wrangling/index.html",
    "title": "Data wrangling in the tidyverse",
    "section": "",
    "text": "1\nlibrary(tidyverse)\nThe tidyverse provides many tools for wrangling data, from selecting, sorting or renaming columns over filtering specific rows according to complex conditions to building new columns according to values in other columns. Let’s take a look at the most important ones. We will use the (athletes)[] dataset in the examples:"
  },
  {
    "objectID": "docs/r_sig/24_03_25_tidyverse_wrangling/index.html#select-columns",
    "href": "docs/r_sig/24_03_25_tidyverse_wrangling/index.html#select-columns",
    "title": "Data wrangling in the tidyverse",
    "section": "1 select() columns",
    "text": "1 select() columns\nSelecting columns from a data.frame is pretty straight forward:\n\nathletes %&gt;%\n  select(Year, Sport)\n\n      Year                     Sport\n1     1956                    Hockey\n2     1948                    Hockey\n3     1980                 Wrestling\n...\n\n\nNote how we don’t have to put the columns in \"\", and how we can simply seperate them by ,.\nselect() becomes especially useful when combined with selection helpers:\n\n## Select all columns starting with a Se\nathletes %&gt;%\n  select(starts_with(\"Se\"))\n\n      Sex Season\n1       M Summer\n2       M Summer\n3       M Summer\n...\n\n## Select all columns containing the letters \"ea\"\nathletes %&gt;%\n  select(contains(\"ea\"))\n\n                                         Team Year Season\n1                                 Afghanistan 1956 Summer\n2                                 Afghanistan 1948 Summer\n3                                 Afghanistan 1980 Summer\n...\n\n## Or, we can combine them:\nathletes %&gt;% \n  select(ends_with(\"t\") & contains(\"igh\"))\n\n      Height Weight\n1         NA     NA\n2         NA     NA\n3        163   57.0\n..."
  },
  {
    "objectID": "docs/r_sig/24_03_25_tidyverse_wrangling/index.html#filter-rows",
    "href": "docs/r_sig/24_03_25_tidyverse_wrangling/index.html#filter-rows",
    "title": "Data wrangling in the tidyverse",
    "section": "2 filter() rows",
    "text": "2 filter() rows\nWe can use filter to subset rows according to their values in specific columns:\n\n## All Volleyballers\nathletes %&gt;%\n  filter(Sport == \"Volleyball\") %&gt;%\n  str\n\n'data.frame':   3404 obs. of  16 variables:\n $ NOC   : chr  \"ALG\" \"ALG\" \"ALG\" \"ALG\" ...\n $ ID    : int  122168 73155 47642 74593 74593 117675 249 249 90117 90100 ...\n $ Name  : chr  \"Faza Tsabet\" \"Narimne Madani\" \"Sehryne Hennaoui\" \"Nawal Mansouri\" ...\n...\n\n## All Judoka between 50 and 100 kg\nathletes %&gt;%\n  filter(Sport == \"Judo\", between(Weight, 50, 100)) %&gt;%\n  str()\n\n'data.frame':   2916 obs. of  16 variables:\n $ NOC   : chr  \"AFG\" \"AFG\" \"AFG\" \"ALB\" ...\n $ ID    : int  99303 33817 7050 58601 121096 9593 78883 5689 78882 9593 ...\n $ Name  : chr  \"Friba Razayee\" \"Ajmal Faizzada\" \"Mohammad Tawfiq Bakhshi\" \"Majlinda Kelmendi\" ...\n...\n\n## All athletes with missing height\nathletes %&gt;%\n  filter(is.na(Height)) %&gt;%\n  str()\n\n'data.frame':   60083 obs. of  16 variables:\n $ NOC   : chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ ID    : int  132181 87371 502 109153 1076 121376 80210 87374 6323 59344 ...\n $ Name  : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Ahmad Shah Abouwi\" \"Shakar Khan Shakar\" ...\n...\n\n\nNote how we can just write our conditions without connecting them with & (filter() does that automatically for us). Also, we don’t have to put the column names into ““, because filter() knows that this are column names of the athletes data frame, which makes coding a bit more pleasant. Also, missing rows are automatically removed, which makes sense in many cases!"
  },
  {
    "objectID": "docs/r_sig/24_03_25_tidyverse_wrangling/index.html#pivot_...-longwide-format",
    "href": "docs/r_sig/24_03_25_tidyverse_wrangling/index.html#pivot_...-longwide-format",
    "title": "Data wrangling in the tidyverse",
    "section": "3 pivot_...() long/wide format",
    "text": "3 pivot_...() long/wide format\nTo reshape data.frames from long to wide or wide to long format we can use pivot_wider() and pivot_longer():\nLet’s define a simpler data.frame first:\n\ninhabitants_wide &lt;- data.frame(\n  country = c(\"China\", \"India\", \"USA\"),\n  inhabitants_2021 = c(1425893465, 1407563842, NA),\n  inhabitants_2022 = c(1425857720, 1420939232, 338903174)\n)\ninhabitants_wide\n\n  country inhabitants_2021 inhabitants_2022\n1   China       1425893465       1425857720\n2   India       1407563842       1420939232\n3     USA               NA        338903174\n\n\n\ninhabitants_long &lt;- inhabitants_wide %&gt;%\n  pivot_longer(\n    ## Select the columns we want to reshape:\n    cols = starts_with(\"inhabitants\"),\n    names_prefix = \"inhabitants_\",\n    ## Define a new column where the column names will go to:\n    names_to = \"year\",\n    ## Define a new column where the values will go to:\n    values_to = \"inhabitants\"\n  )\n\nhead(inhabitants_long)\n\n# A tibble: 6 × 3\n  country year  inhabitants\n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt;\n1 China   2021   1425893465\n2 China   2022   1425857720\n3 India   2021   1407563842\n4 India   2022   1420939232\n5 USA     2021           NA\n6 USA     2022    338903174\n\n\nIn other cases, it might happen that multiple variables are put into the same column, together with an identifier column:\n\ninhabitants_long_2\n\n  country         variable      value\n1   China             area    9597000\n2   China inhabitants_2022 1425857720\n3   India             area    3287000\n4   India inhabitants_2022 1420939232\n5     USA             area    9834000\n6     USA inhabitants_2022  338903174\n\n\nIn that case it can make sense to spread the the distinct variables into two columns:\n\ninhabitants_wide_2 &lt;- inhabitants_long_2 %&gt;%\n  pivot_wider(\n    id_cols = \"country\",\n    names_from = \"variable\",\n    values_from = \"value\"\n  )\n\ninhabitants_wide_2\n\n# A tibble: 3 × 3\n  country    area inhabitants_2022\n  &lt;chr&gt;     &lt;dbl&gt;            &lt;dbl&gt;\n1 China   9597000       1425857720\n2 India   3287000       1420939232\n3 USA     9834000        338903174"
  },
  {
    "objectID": "docs/r_sig/24_03_25_tidyverse_wrangling/index.html#mutate",
    "href": "docs/r_sig/24_03_25_tidyverse_wrangling/index.html#mutate",
    "title": "Data wrangling in the tidyverse",
    "section": "4 mutate()",
    "text": "4 mutate()\nWith mutate() we can add new columns to a data.frame or edit existing ones:\n\nathletes %&gt;%\n  mutate(new_column = NA) %&gt;%\n  mutate(ID = as.character(ID)) %&gt;%\n  str()\n\n'data.frame':   270767 obs. of  17 variables:\n $ NOC       : chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ ID        : chr  \"132181\" \"87371\" \"44977\" \"502\" ...\n $ Name      : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Mohammad Halilula\" \"Ahmad Shah Abouwi\" ...\n...\n\n\n\n4.1 Useful helpers\nLike select(), mutate() really starts to shine when helper functions are added. For example we can fill a new column according to values in other columns:\n\n## Build a new column indicating if this is a contact sport athlete\nathletes %&gt;%\n  mutate(contact_sport = ifelse(Sport %in% c(\"Wrestling\", \"Boxing\", \"Judo\", \"Rugby\", \"Taekwondo\", \"Rugby Sevens\"), \n                                yes = TRUE, \n                                no = FALSE)\n         ) %&gt;%\n  select(Name, Sport, contact_sport) %&gt;%\n  str\n\n'data.frame':   270767 obs. of  3 variables:\n $ Name         : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Mohammad Halilula\" \"Ahmad Shah Abouwi\" ...\n $ Sport        : chr  \"Hockey\" \"Hockey\" \"Wrestling\" \"Hockey\" ...\n $ contact_sport: logi  FALSE FALSE TRUE FALSE TRUE TRUE ...\n\n\nIf we have to connect multiple ifelse() functions, it’s better to use dplyrs case_when():\n\n## This gets complicated pretty quickly:\nathletes %&gt;%\n  mutate(judo_weightclass = if_else(str_detect(Event, \"Middleweight\"), \n                                  true = \"Middleweight\", \n                                  false = if_else(str_detect(Event, \"Half-Lightweight\"), \n                                        true = \"Half-Lightweight\", \n                                        false = if_else(str_detect(Event, \"Lightweight\"), \n                                                    true = \"Lightweight\", \n                                                    false = NA)\n                                        ) \n                                        )\n                                  ) %&gt;% \n  filter(Sport == \"Judo\") %&gt;%\n  select(Name, Sport, Event, judo_weightclass) %&gt;%\n  str\n\n'data.frame':   3799 obs. of  4 variables:\n $ Name            : chr  \"Friba Razayee\" \"Ajmal Faizzada\" \"Mohammad Tawfiq Bakhshi\" \"Sergio Murray\" ...\n $ Sport           : chr  \"Judo\" \"Judo\" \"Judo\" \"Judo\" ...\n $ Event           : chr  \"Judo Women's Middleweight\" \"Judo Men's Half-Lightweight\" \"Judo Men's Half-Heavyweight\" \"Judo Men's Middleweight\" ...\n $ judo_weightclass: chr  \"Middleweight\" \"Half-Lightweight\" NA \"Middleweight\" ...\n\n## so do this instead:\nathletes %&gt;%\n  mutate(judo_weightclass = case_when(str_detect(Event, \"Middleweight\") ~ \"Middleweight\", \n                                      str_detect(Event, \"Half-Lightweight\") ~ \"Half-Lightweight\", \n                                      str_detect(Event, \"Lightweight\") ~ \"Lightweight\",\n                                      TRUE ~ \"other Weightclass\" )\n         ) %&gt;%\n  filter(Sport == \"Judo\") %&gt;%\n  select(Name, Sport, Event, judo_weightclass) %&gt;%\n  str()\n\n'data.frame':   3799 obs. of  4 variables:\n $ Name            : chr  \"Friba Razayee\" \"Ajmal Faizzada\" \"Mohammad Tawfiq Bakhshi\" \"Sergio Murray\" ...\n $ Sport           : chr  \"Judo\" \"Judo\" \"Judo\" \"Judo\" ...\n $ Event           : chr  \"Judo Women's Middleweight\" \"Judo Men's Half-Lightweight\" \"Judo Men's Half-Heavyweight\" \"Judo Men's Middleweight\" ...\n $ judo_weightclass: chr  \"Middleweight\" \"Half-Lightweight\" \"other Weightclass\" \"Middleweight\" ...\n\n\n\n\n4.2 Programmatically using mutate()\nIf you want to use mutate() programmatically within a loop or a function, take a look at Column-wise operations in the tidyverse"
  },
  {
    "objectID": "docs/r_sig/24_03_25_tidyverse_wrangling/index.html#replace_...",
    "href": "docs/r_sig/24_03_25_tidyverse_wrangling/index.html#replace_...",
    "title": "Data wrangling in the tidyverse",
    "section": "5 ..._replace_...()",
    "text": "5 ..._replace_...()\nWe can easily replace values in a column using str_replace() or replace_na():\n\nathletes %&gt;%\n  mutate(Sex = str_replace(Sex, \"M\", \"Male\")) %&gt;%\n  mutate(Sex = str_replace(Sex, \"F\", \"Female\")) %&gt;%\n  mutate(Height = replace_na(Height, 0)) %&gt;%\n  select(Sex, Height) %&gt;%\n  str()\n\n'data.frame':   270767 obs. of  2 variables:\n $ Sex   : chr  \"Male\" \"Male\" \"Male\" \"Male\" ...\n $ Height: int  0 0 163 0 0 168 0 0 0 0 ..."
  },
  {
    "objectID": "docs/r_sig/24_03_25_tidyverse_wrangling/index.html#group_by",
    "href": "docs/r_sig/24_03_25_tidyverse_wrangling/index.html#group_by",
    "title": "Data wrangling in the tidyverse",
    "section": "6 group_by()",
    "text": "6 group_by()\nWe can group our data by values in specific columns and perform some sort of operation on the groups. If we wanted to know the number of medals each region has won, we can for example group by region and medal type, and then count() (another tidyverse function) the number of cases in each group:\n\nmedal_counts &lt;- athletes %&gt;%\n  group_by(Region, Medal) %&gt;%\n  count(Medal) \n\nmedal_counts\n\n# A tibble: 533 × 3\n# Groups:   Region, Medal [533]\n   Region         Medal      n\n   &lt;chr&gt;          &lt;chr&gt;  &lt;int&gt;\n 1 Afghanistan    Bronze     2\n 2 Afghanistan    &lt;NA&gt;     124\n 3 Albania        &lt;NA&gt;      70\n 4 Algeria        Bronze     8\n 5 Algeria        Gold       5\n 6 Algeria        Silver     4\n...\n\n\nWe can also summarize() data:\n\n## Let's see what the mean, min and max age of athletes was in each Region:\nathletes %&gt;%\n  group_by(Region) %&gt;%\n      summarize(mean_age = mean(Age, na.rm = TRUE), \n                min_age = min(Age, na.rm = TRUE), \n                max_age = max(Age, na.rm = TRUE)\n                )\n\n# A tibble: 206 × 4\n   Region         mean_age min_age max_age\n   &lt;chr&gt;             &lt;dbl&gt;   &lt;int&gt;   &lt;int&gt;\n 1 Afghanistan        23.5      17      35\n 2 Albania            25.3      16      46\n 3 Algeria            24.4      14      38\n 4 American Samoa     27.2      16      43\n 5 Andorra            23.1      15      61\n 6 Angola             24.9      13      51\n 7 Antigua            23.2      14      38\n..."
  },
  {
    "objectID": "docs/r_sig/24_03_25_tidyverse_wrangling/index.html#join_..-data.frames",
    "href": "docs/r_sig/24_03_25_tidyverse_wrangling/index.html#join_..-data.frames",
    "title": "Data wrangling in the tidyverse",
    "section": "7 ..._join_..() data.frames",
    "text": "7 ..._join_..() data.frames\nWe have multiple options for merging data.frames in the tidyverse. left_join() can be used if we want to keep all rows of the first data.frame and only adds the rows of the second data.frame that have an identifier in the first data.frame, right_join() keeps all rows of the second data frame, and full_join() keeps all rows of both data frames.\nLet’s merge a world coordinate data set onto our medal counts. This can be helpful if we want to plot the number of won medals in each country later on:\n\nworld_coordinates &lt;- readRDS(here::here(\"raw_data\", \"world_coordinates.rds\"))\n\nOnly take gold medals into account:\n\nmedal_counts &lt;- medal_counts %&gt;% filter(Medal == \"Gold\")\n\nTo merge two data frames that include information that belongs together, we need a common column, on which we can combine them. In our case, this is the column containing the country. They are both named region, but one with an upper case R. This doesn’t pose a problem, as we can define which columns should be taken from which data frame for merging with join_by(). Let’s take a quick look before merging to check if there are any countries named differently in both data sets:\n\nmedal_counts$Region[!(medal_counts$Region %in% world_coordinates$region)]\n\n[1] \"Individual Olympic Athletes\"\n\n\nLooks like all of the countries in our medal_countries data frame can also be found in our world_coordinates frame. Only athletes without a country will be lost when merging, but that’s ok for now, as we are interested in the country specific gold medal counts. So let’s merge:\n\nmedal_countries &lt;- world_coordinates %&gt;%\n  left_join(medal_counts, join_by(region == Region))\n\nhead(medal_countries)\n\n       long      lat group order region subregion Medal  n\n1 -69.89912 12.45200     1     1  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n2 -69.89571 12.42300     1     2  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n3 -69.94219 12.43853     1     3  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n4 -70.00415 12.50049     1     4  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n5 -70.06612 12.54697     1     5  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n6 -70.05088 12.59707     1     6  Aruba      &lt;NA&gt;  &lt;NA&gt; NA"
  },
  {
    "objectID": "docs/r_sig/24_03_25_tidyverse_wrangling/index.html#exercise",
    "href": "docs/r_sig/24_03_25_tidyverse_wrangling/index.html#exercise",
    "title": "Data wrangling in the tidyverse",
    "section": "8 Exercise",
    "text": "8 Exercise\n\nRead the characters.rds and the psych_stats.csv into R (download here).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ncharacters &lt;- readRDS(here::here(  \"raw_data\", \"characters.rds\"))\npsych_stats &lt;- read.csv(here::here(  \"raw_data\", \"psych_stats.csv\"), sep = \";\")\n\n\n\n\n\nReshape the psych_stats data frame so there are only three columns in the data set: char_id, question and rating.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can select multiple columns like this: column_1:column_10.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npsych_stats_long &lt;- psych_stats %&gt;%\n  pivot_longer(cols = messy_neat:innocent_jaded, \n               names_to = \"question\", \n               values_to = \"rating\")\n\nhead(psych_stats_long)\n\n# A tibble: 6 × 3\n  char_id question                      rating\n  &lt;chr&gt;   &lt;chr&gt;                          &lt;dbl&gt;\n1 F2      messy_neat                     95.7 \n2 F2      disorganized_self.disciplined  95.2 \n3 F2      diligent_lazy                   6.10\n4 F2      on.time_tardy                   6.2 \n5 F2      competitive_cooperative         6.40\n6 F2      scheduled_spontaneous           6.60\n\n\nNow we have multiple rows for every character, but all question ratings are nicely aligned in one column.\n\n\n\n\nMerge the characters data frame and the psych_stats_long data frame on a common column.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nIdentify the common columns. Are they named the same in both data frames? Look at the documentation of ?join_by() to see, how you can merge data frames that don’t have identically named columns.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFirst, let’s take a look at both data sets again:\n\nstr(characters)\n\n'data.frame':   889 obs. of  7 variables:\n $ id        : chr  \"F2\" \"F1\" \"F5\" \"F4\" ...\n $ name      : chr  \"Monica Geller\" \"Rachel Green\" \"Chandler Bing\" \"Joey Tribbiani\" ...\n $ uni_id    : chr  \"F\" \"F\" \"F\" \"F\" ...\n $ uni_name  : chr  \"Friends\" \"Friends\" \"Friends\" \"Friends\" ...\n $ notability: num  79.7 76.7 74.4 74.3 72.6 51.6 86.5 84.2 82.6 65.6 ...\n $ link      : chr  \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/1\" \"https://openpsychometrics.org/tests/characters/stats/F/5\" \"https://openpsychometrics.org/tests/characters/stats/F/4\" ...\n $ image_link: chr  \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/5.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/4.jpg\" ...\n\nstr(psych_stats)\n\n'data.frame':   889 obs. of  365 variables:\n $ char_id                                     : chr  \"F2\" \"F1\" \"F5\" \"F4\" ...\n $ messy_neat                                  : num  95.7 30.2 45.3 13 20.9 ...\n $ disorganized_self.disciplined               : num  95.2 25.9 42.4 11 20.9 75.6 10.4 31.9 39.6 31.1 ...\n $ diligent_lazy                               : num  6.1 51.8 52.2 78.1 45.2 ...\n $ on.time_tardy                               : num  6.2 77.9 57.1 84.1 74 20.6 85.7 68.3 73.6 58.2 ...\n $ competitive_cooperative                     : num  6.4 28.9 42.8 44.2 55.3 ...\n $ scheduled_spontaneous                       : num  6.6 72.3 54.9 91.3 94.9 ...\n $ ADHD_OCD                                    : num  92.9 31.8 26.7 10.4 12.8 70.1 35.5 30.1 51.8 39.2 ...\n $ chaotic_orderly                             : num  92.2 27 38.2 12.6 11.2 68.8 6.8 20.6 23.4 28.8 ...\n $ motivated_unmotivated                       : num  7.8 31.8 52.3 45.6 24.7 31.5 80.9 30.5 40.8 50.7 ...\n $ bossy_meek                                  : num  7.9 30.6 64.8 60.8 40.1 ...\n $ persistent_quitter                          : num  7.9 35.8 43.9 33.8 21.3 ...\n $ overachiever_underachiever                  : num  8.2 43.8 55.8 68.8 51.3 23.2 67.7 36.7 44.1 44.4 ...\n $ muddy_washed                                : num  91 80.2 58.7 42.7 48.1 64.6 27.6 62.4 70.1 69.2 ...\n $ beautiful_ugly                              : num  9.2 5.3 26.2 11 11.4 ...\n $ slacker_workaholic                          : num  90.8 45.9 53.4 17.6 32 81.5 23.8 30.1 33.2 34.6 ...\n $ driven_unambitious                          : num  9.5 30.3 49.8 49.4 43.4 22.7 58.5 34.1 32 47.4 ...\n $ outlaw_sheriff                              : num  90.3 39.3 46.7 23.8 16.1 85.4 21.4 22.7 27.3 30.1 ...\n $ precise_vague                               : num  9.9 64.7 53.2 78 78.1 25.4 68.4 60.1 47.3 61.7 ...\n $ bad.cook_good.cook                          : num  90 11.1 28.2 31.2 29.4 35.9 27.3 46.2 43.8 52.8 ...\n $ manicured_scruffy                           : num  10.6 7.7 45.6 47.6 62.5 20.5 81.3 37.3 20.3 20.9 ...\n $ lenient_strict                              : num  89.3 34.2 28.8 11 15.4 76.7 15.2 24.2 38.9 21.5 ...\n $ relaxed_tense                               : num  89 58.8 66.4 10.4 16.9 88.9 69.9 64.2 54.5 64.8 ...\n $ demanding_unchallenging                     : num  11 23.9 58.3 66.3 57.1 28.5 35.9 37.8 16.8 60.3 ...\n $ drop.out_valedictorian                      : num  88.9 32.5 47 14.9 22.1 87.7 12.5 29.6 36.5 51.2 ...\n $ go.getter_slugabed                          : num  11.7 31.3 52.6 48.1 27.6 41.8 62.6 33.9 27.3 51.1 ...\n $ competent_incompetent                       : num  11.9 47.1 37.1 77.2 53.6 37.8 51.9 41.1 35.2 56.1 ...\n $ aloof_obsessed                              : num  88.1 62.3 52.3 35.1 33.2 80.8 75.1 54.9 70.7 61.9 ...\n $ flexible_rigid                              : num  87.8 41.8 45.9 17.3 13.9 83.7 45.9 27.4 55 32.1 ...\n $ active_slothful                             : num  12.2 33.1 61.1 56.7 31.4 48.8 73.9 19.8 29.2 35.5 ...\n $ loose_tight                                 : num  87.4 43.2 44.3 14 15.3 82.5 28.1 26 44.8 43.6 ...\n $ pointed_random                              : num  12.8 49.9 67.1 86.2 87.4 36.7 65.4 53.1 36.9 56.2 ...\n $ fresh_stinky                                : num  12.9 14.6 31.9 44.3 39.2 44.3 64.4 30.2 18.2 24.6 ...\n $ dominant_submissive                         : num  13.6 41.6 73.7 40.2 30.9 69.5 43.5 52.6 36.9 77.9 ...\n $ anxious_calm                                : num  13.7 28.8 20 66.1 58 11.9 12 32.1 37.1 29.8 ...\n $ clean_perverted                             : num  13.7 42.5 56.8 77.5 59.4 44 53.1 51.2 61.9 50.6 ...\n $ neutral_opinionated                         : num  86.3 74.6 67.2 43.4 76.6 84.2 67.3 77.9 82.5 43.9 ...\n $ always.down_picky                           : num  85.9 72.6 49.8 27.1 35.2 71.9 23.6 36.2 71.8 36.2 ...\n $ hurried_leisurely                           : num  14.6 55.1 55.9 85.9 81 22.1 48.6 45.6 49 39.3 ...\n $ attractive_repulsive                        : num  14.7 9.4 28.5 15.7 18.2 ...\n $ devoted_unfaithful                          : num  14.8 29.1 22.6 41.5 19.6 47.5 34.1 55.7 42.7 48.2 ...\n $ helpless_resourceful                        : num  85 41.4 56.6 37.9 70.6 52.4 41.4 51.5 36.2 29.8 ...\n $ deliberate_spontaneous                      : num  15.1 71.7 56.5 89.1 92.9 20.9 78.6 88.3 64 60.9 ...\n $ plays.hard_works.hard                       : num  84.7 41.3 46.5 13.7 26 81.2 28.2 30 19.9 26.4 ...\n $ imaginative_practical                       : num  84.7 37.9 54.6 17 5.4 ...\n $ frenzied_sleepy                             : num  15.5 29.9 34.7 55.6 30 31.1 59.4 25.2 19 46 ...\n $ queer_straight                              : num  84.3 84.1 65.4 84.3 45.4 77.9 10.2 4.8 73.4 64.1 ...\n $ assertive_passive                           : num  15.8 40.4 66.3 44.3 39.3 60.9 45.1 45.8 23.4 63.3 ...\n $ fast.talking_slow.talking                   : num  15.9 20.8 18.3 42.2 21.7 49.6 69.5 34.3 32.5 44.5 ...\n $ astonishing_methodical                      : num  83.8 28 49.9 19.2 17.4 83 31.2 27.4 36 32.7 ...\n $ hoarder_unprepared                          : num  16.2 70 63.5 82 54.9 35.5 60.3 64.5 48.3 67.8 ...\n $ consistent_variable                         : num  16.6 60.2 46.3 63.1 79.3 39.5 72 65.3 69.7 62.3 ...\n $ involved_remote                             : num  16.7 26.3 42.7 30.2 36.7 36.6 62.2 39.3 26.4 38.7 ...\n $ backdoor_official                           : num  83.3 51.9 47.4 24.4 20.4 76.4 29.1 29.3 53.5 36.7 ...\n $ captain_first.mate                          : num  16.7 52.7 73.5 74.2 57.9 68.4 55.9 51 19 73.6 ...\n $ refined_rugged                              : num  17.3 18.9 48.4 74.4 69.9 24.4 81.6 48 31.4 40.7 ...\n $ accommodating_stubborn                      : num  82.7 77.2 48.2 43.9 48.3 78.5 78.1 69 85.9 41.5 ...\n $ barbaric_civilized                          : num  82.6 76.5 66.6 32.9 39.9 77 33.4 44.4 36.7 55.5 ...\n $ alpha_beta                                  : num  17.7 37.9 73.9 33.6 41.9 78.2 44.3 37.4 17.5 66.6 ...\n $ loyal_traitorous                            : num  17.8 32.3 20 15.3 14.5 40.3 29.2 43.1 47.2 33.2 ...\n $ trash_treasure                              : num  82 80.1 82.2 78.4 83.2 47.8 64.5 62.2 68.2 78.4 ...\n $ fast_slow                                   : num  18.1 43.7 38.1 69 55.3 60.4 57.8 29.4 30 54.5 ...\n $ perceptive_unobservant                      : num  18.3 59.5 41.5 80 41.1 48.6 21.6 33.3 28 49 ...\n $ goof.off_studious                           : num  81.4 33.2 20.7 7.4 16.6 ...\n $ feminist_sexist                             : num  18.6 23.3 43.9 62 10.5 ...\n $ desperate_high.standards                    : num  81.1 69.2 30.7 36.8 56.7 29.2 33.7 32.5 61.7 25.8 ...\n $ impatient_patient                           : num  18.9 21.9 34 25.7 39.1 25.8 23.8 35.1 18 57.2 ...\n $ preppy_punk.rock                            : num  18.9 16.4 41.5 49.5 73.2 14.4 87.7 74.4 26.4 18.2 ...\n $ naive_paranoid                              : num  80.7 35.5 66.6 22 39.7 71.6 69.6 45.6 50.7 32.1 ...\n $ important_irrelevant                        : num  19.3 22.3 24.6 24.7 26.4 47.4 12.5 14.8 16.4 33.4 ...\n $ apprentice_master                           : num  80.6 42.3 44.9 36.3 61.5 60.8 48 48 73 31.5 ...\n $ healthy_sickly                              : num  19.6 17.8 39.1 26.9 22.6 37 88.9 65.7 56.7 45.5 ...\n $ morning.lark_night.owl                      : num  19.6 69.9 58.3 80.4 61.9 23.2 90.6 81.9 90.1 78.3 ...\n $ alert_oblivious                             : num  19.6 70.7 55.5 87.6 78.9 57.1 54.7 48.9 38.3 67.4 ...\n $ f....the.police_tattle.tale                 : num  80 57.5 56.7 34.4 13.7 ...\n $ experimental_reliable                       : num  79.7 37.8 62 35 22.2 61.7 28 26.5 30.4 39.8 ...\n $ loud_quiet                                  : num  20.4 20.8 25 10.6 15.3 39.5 71.9 42.7 13.2 55.2 ...\n $ high.IQ_low.IQ                              : num  20.5 56.7 28.8 82.6 50.6 19.3 30.9 26.1 47.7 55.6 ...\n $ oppressed_privileged                        : num  79.2 85.4 67.2 66.5 42.1 84.3 22.4 19.6 59.9 63.4 ...\n $ animalistic_human                           : num  79.2 75.6 73.7 43.8 42.1 69.3 70.4 55.9 64.4 73.2 ...\n $ still_twitchy                               : num  79.2 68.6 79.9 76.9 83.6 81.9 77.9 67.4 60.1 58.4 ...\n $ thick_thin                                  : num  78.8 79.6 52.8 35.2 69.2 60.6 73.3 81.4 66.1 48.8 ...\n $ repetitive_varied                           : num  21.3 44.5 40.9 43.4 74.1 18.4 40.1 68.4 47.3 42.1 ...\n $ rational_whimsical                          : num  21.7 72.3 54.4 86.8 93 27.4 67 78.7 69.6 70.9 ...\n $ egalitarian_racist                          : num  21.7 27.8 24.7 24.3 10.7 ...\n $ disreputable_prestigious                    : num  78.2 66.2 47 32.5 36.7 68.2 21.2 42.5 65.2 45.8 ...\n $ ignorant_knowledgeable                      : num  78.2 37.7 66.9 22.2 59.9 68.5 60.8 68.1 44.2 42.6 ...\n $ hard.work_natural.talent                    : num  21.9 47.5 41.8 69.8 71.2 29.2 55.8 67.5 65.8 57.3 ...\n $ androgynous_gendered                        : num  78.1 89.4 68.5 82.5 60.1 78.1 32.6 43.4 88.3 87.9 ...\n $ dispassionate_romantic                      : num  77.9 80.5 64.7 69.6 74.9 67.2 61.5 64.8 59.1 82.3 ...\n $ eloquent_unpolished                         : num  22.1 32.1 56.1 79.8 69 33.7 76.3 45.2 35 42.9 ...\n $ permanent_transient                         : num  22.2 56.1 39 59.6 71.1 31.9 68.5 79.7 57.2 70.6 ...\n $ intense_lighthearted                        : num  22.2 50.8 73.8 79.8 64.2 28.2 22.4 34.7 18.2 44.3 ...\n $ mischievous_well.behaved                    : num  77.8 34.2 30.6 15.8 20.3 71.4 13.3 19.4 17.6 38.2 ...\n $ adventurous_stick.in.the.mud                : num  77.7 37.4 59.7 14.4 8 ...\n $ obedient_rebellious                         : num  22.3 69.2 42.9 72.9 86.2 16.5 92.3 87.1 84.2 38.1 ...\n $ authoritarian_democratic                    : num  22.4 55.2 70 72.1 75.4 41.6 68 67.4 21.8 68.9 ...\n $ city.slicker_country.bumpkin                : num  22.7 9 22.4 18.4 42.6 18.8 26.5 20.2 16.8 24 ...\n $ traditional_unorthodox                      : num  22.8 52.8 54.9 67.2 90 23.1 85.7 90.2 74.5 62.6 ...\n  [list output truncated]\n\n\nIt seems like both data frames have a column containing an ID for the character. We can use that column for merging:\n\ncharacters_stats &lt;- characters %&gt;%\n  right_join(psych_stats_long, join_by(id == char_id))\n\nstr(characters_stats)\n\n'data.frame':   323596 obs. of  9 variables:\n $ id        : chr  \"F2\" \"F2\" \"F2\" \"F2\" ...\n $ name      : chr  \"Monica Geller\" \"Monica Geller\" \"Monica Geller\" \"Monica Geller\" ...\n $ uni_id    : chr  \"F\" \"F\" \"F\" \"F\" ...\n $ uni_name  : chr  \"Friends\" \"Friends\" \"Friends\" \"Friends\" ...\n $ notability: num  79.7 79.7 79.7 79.7 79.7 79.7 79.7 79.7 79.7 79.7 ...\n $ link      : chr  \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/2\" ...\n $ image_link: chr  \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" ...\n $ question  : chr  \"messy_neat\" \"disorganized_self.disciplined\" \"diligent_lazy\" \"on.time_tardy\" ...\n $ rating    : num  95.7 95.2 6.1 6.2 6.4 ...\n\n\n\n\n\n\nRemove all columns from your merged data frame that start with \"uni\". Don’t overwrite your old data, this is just for exercise and won’t be worked with further on.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nTake a look at the examples in ?select to see how you can select all columns but those fulfilling a certain condition.\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\ncharacters_stats %&gt;%\n  select(!starts_with(\"uni\")) %&gt;%\n  str()\n\n'data.frame':   323596 obs. of  7 variables:\n $ id        : chr  \"F2\" \"F2\" \"F2\" \"F2\" ...\n $ name      : chr  \"Monica Geller\" \"Monica Geller\" \"Monica Geller\" \"Monica Geller\" ...\n $ notability: num  79.7 79.7 79.7 79.7 79.7 79.7 79.7 79.7 79.7 79.7 ...\n $ link      : chr  \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/2\" ...\n $ image_link: chr  \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" ...\n $ question  : chr  \"messy_neat\" \"disorganized_self.disciplined\" \"diligent_lazy\" \"on.time_tardy\" ...\n $ rating    : num  95.7 95.2 6.1 6.2 6.4 ...\n\n\n\n\n\n\nCalculate the mean rating of all characters by show and question, so you get the mean rating of all characters in a show on each item.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse group_by() and summarise().\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\ncharacters_summary &lt;- characters_stats %&gt;%\n  group_by(uni_name, question) %&gt;%\n  summarise(mean_rating = mean(rating, na.rm = TRUE))\n\n`summarise()` has grouped output by 'uni_name'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\nChoose two of your favorite shows. Build a data frame that has two mean_rating columns, one for each show.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can get an overview of the used shows with unique(characters_stats$uni_name) First, filter your two shows from the characters_stats data.frame.\nSecond, reshape this data.frame into long format.\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\ncompare_shows &lt;- characters_summary %&gt;%\n  filter(str_detect(uni_name, c(\"Friends|How I Met Your Mother\" ))) %&gt;%\n  pivot_wider(\n    names_from = \"uni_name\",\n    values_from = \"mean_rating\")\n\ncompare_shows\n\n# A tibble: 364 × 3\n   question               Friends `How I Met Your Mother`\n   &lt;chr&gt;                    &lt;dbl&gt;                   &lt;dbl&gt;\n 1 ADHD_OCD                  40.8                    46.6\n 2 Coke_Pepsi                49.2                    48.1\n 3 English_German            26.6                    31.3\n 4 French_Russian            30.7                    38.7\n 5 Greek_Roman               44.0                    47.9\n 6 Italian_Swedish           39.2                    44.5\n 7 abstract_concrete         46.0                    43.6\n 8 accepting_judgemental     52.0                    53.4\n 9 accommodating_stubborn    63.1                    63.6\n10 active_slothful           40.6                    37.0\n# ℹ 354 more rows\n\n\nNow we could look at specific questions. For example the How I Met Your Mother characters seem to be rated a bit more slothful than the Friends characters.\n\n\n\n\nNow, add a column containing the difference in rating between both shows for each question to your new comparison data.frame. Then, sort the rows by descending size of difference between the ratings. So the row with the highest difference in mean rating between your two shows should be on top.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo work with columns within mutate() you could for example use .$column_name.\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\ncompare_shows %&gt;%\n  mutate(diff_shows = .$Friends - .$\"How I Met Your Mother\") %&gt;%\n  arrange(desc(abs(diff_shows)))\n\n# A tibble: 364 × 4\n   question                            Friends How I Met Your Mothe…¹ diff_shows\n   &lt;chr&gt;                                 &lt;dbl&gt;                  &lt;dbl&gt;      &lt;dbl&gt;\n 1 cat.person_dog.person                  46.4                   65.1      -18.6\n 2 musical_off.key                        61.5                   44.8       16.7\n 3 nonpolitical_political                 40.2                   54.7      -14.5\n 4 gamer_non.gamer                        58.6                   44.8       13.8\n 5 focused.on.the.future_focused.on.t…    55.0                   41.8       13.2\n 6 gatherer_hunter                        38.8                   51.2      -12.5\n 7 captain_first.mate                     57.2                   44.9       12.3\n 8 flower.child_goth                      21.5                   33.6      -12.1\n 9 perceptive_unobservant                 48.2                   36.4       11.7\n10 dunce_genius                           46.4                   57.9      -11.4\n# ℹ 354 more rows\n# ℹ abbreviated name: ¹​`How I Met Your Mother`\n\n\ndesc() means descending, so we go from the largest value to the smallest.\nabs() means absolute, so we get the absolute value instead of negative values in some cases."
  },
  {
    "objectID": "docs/r_sig/24_03_25_tidyverse_wrangling/index.html#footnotes",
    "href": "docs/r_sig/24_03_25_tidyverse_wrangling/index.html#footnotes",
    "title": "Data wrangling in the tidyverse",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Bing Copilot↩︎"
  },
  {
    "objectID": "docs/r_sig/24_01_26_tidyverse_intro/index.html",
    "href": "docs/r_sig/24_01_26_tidyverse_intro/index.html",
    "title": "Introduction to the tidyverse",
    "section": "",
    "text": "1\nlibrary(tidyverse)"
  },
  {
    "objectID": "docs/r_sig/24_01_26_tidyverse_intro/index.html#introduction",
    "href": "docs/r_sig/24_01_26_tidyverse_intro/index.html#introduction",
    "title": "Introduction to the tidyverse",
    "section": "1 Introduction",
    "text": "1 Introduction\nTidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. (Wickham, 2014).\nThe tidyverse is composed of multiple packages, all following a common philosophy, and facilitating many aspects of coding in R, for example data wrangling and plotting. It is not really necessary to learn the tidyverse syntax in order to be proficient in R. However, I find it easier to understand and write Code in, at least in most cases. In the end, it is a question of preference what you want to learn and use. Most code will probably be composed from base R functions and tidyverse functions.\nYou can find an overview of the included packages at the offical tidyverse documentation.\nA more thorough introduction into the tidyverse can be found here."
  },
  {
    "objectID": "docs/r_sig/24_01_26_tidyverse_intro/index.html#some-tidyverse-features",
    "href": "docs/r_sig/24_01_26_tidyverse_intro/index.html#some-tidyverse-features",
    "title": "Introduction to the tidyverse",
    "section": "2 Some tidyverse features",
    "text": "2 Some tidyverse features\n\n2.1 Tibbles\nA special type of data frame are the so called tibbles. Tibbles are a modern version of data frames and the standard data frame type of the tidyverse, as they have some advantageous characteristics (e.g., note the more informative printing of the data frame). So don’t be confused if you run into them, in general they behave like data frames. Take a look at the Exercises, or at a more thorough Example if you want to learn more.\n\n\n2.2 The Pipe Operator\ntidyverse code is often written using the pipe operator %&gt;% (read as ‘then do’), which makes it easy to connect multiple function calls.\nSome notes on the pipe syntax, also see Exercises:\n\nIf we don’t have any additional arguments we want to put into the function, we can just write the function name without any brackets.\nThe pipe operator will give the result of the last function as input into the next function.\nIf we want to clearly state which of the function arguments should receive the input, we can write a ., which can be read as output of the previous function call."
  },
  {
    "objectID": "docs/r_sig/24_01_26_tidyverse_intro/index.html#workstation-organization",
    "href": "docs/r_sig/24_01_26_tidyverse_intro/index.html#workstation-organization",
    "title": "Introduction to the tidyverse",
    "section": "3 Workstation organization",
    "text": "3 Workstation organization\n\n3.1 RStudio Projects\nOver time, it will become increasingly hard to organize all your files, working directories and workspaces in a sensible manner. A reasonable big project will consist of multiple script files, data, output and plots. To keep everything toghether, RStudio Projects can be used (highly recommended). Therefore, when starting a new project in R, the first thing you should do is to create a RStudio project.\nYou can create a new RStudio project by clicking on File - New Project in the RStudio window. You can either create a totally new directory, or choose an already existing folder for the project.\n\n\n3.2 Code organization\nWithin your project folder, I would suggest that you create subfolders to save your Scripts, data, outputs … in. For example, you could create a folder named R, where all your R Scripts will go. You can do the same for data, plots etc. This will help you to structure your working directory and make it easier to find specific files.\n\n\n3.3 Absolute paths vs. relative paths\nI can head to a specific file by using the full path (absolute path): \"C:/Users/hafiznij/Documents/GitHub/IQB-Methods/posts/r_sig/24_01_26_tidyverse_intro/raw_data/winners.rda\". This approach has some disadvantages: it will only work on my notebook. If I want to continue my project on another device, I will have to change the path. The same goes for other people who want to work with my project. So, to keep these paths more reproducable, we should always use relative paths: \"./raw_data/winners.rda\". This will always work independently of the device I am working on, as long as I am in the correct working directory.\n\n\n\n\n\n\nNetwork drives\n\n\n\nOne exception might be paths to files on the IQB network drives, like T: … Because these are always the same for every one, absolute paths will work just fine for everything lying on here.\n\n\nThe working directory is the path R is currently working in. I can obtain it by typing:\n\ngetwd()\n\n[1] \"/home/runner/work/IQB-Methods/IQB-Methods/docs/r_sig/24_01_26_tidyverse_intro\"\n\n\nLuckily, RStudio projects set the working directory automatically, so we don’t really have to deal with that.\nNow take a look at the working directory and the relative path I used for loading the winners.rda. Notice something? Correct, both paths combined equal the absolute path to the file. So by splitting it up, we obtain a more reproducible path, that works independently of where the current working directory is.\n\n\n\n\n\n\nThe here package\n\n\n\nAnother great way to deal with the path confusion is to use the here package. It can build the paths relative to the directory where your R Studio project is saved in. For example, \"./raw_data/winners.rda\" becomes here::here(\"raw_data\", \"winners.rda\"). This is not incredibly important right now, especially if you have all your files in the same folder. But it can become very valuable with increasing project complexity and file structure, so look into it if you want to get a head start! I also I have to use it sometimes during the tutorial because of the way I have organized my project, so don’t be confused! It is just another way to build file paths. Look here (:D) if you want to learn more about the package."
  },
  {
    "objectID": "docs/r_sig/24_01_26_tidyverse_intro/index.html#exercise",
    "href": "docs/r_sig/24_01_26_tidyverse_intro/index.html#exercise",
    "title": "Introduction to the tidyverse",
    "section": "4 Exercise",
    "text": "4 Exercise\n\nCreate a new RStudio project. Create the folders R, data and plots. Create a new R-Script which lies in your R folder.\nWrite the following code using the pipe-operator from the tidyverse:\n\n\nsum(seq(from = 1, to = mean(c(45:100), na.rm = TRUE), by = 0.1))\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(tidyverse)\n\nc(45:100) %&gt;%\n  mean(na.rm = TRUE) %&gt;%\n  seq(from = 1, to = ., by = 0.1) %&gt;%\n  sum\n\n[1] 26313\n\n\nMuch nicer to read, right?\n\nIf we don’t have any additional arguments we want to put into the function, we can just write the function name without any brackets, like we do at the end with sum.\nThe pipe operator will give the result of the last function as input into the next function. That’s why we don’t have to specify the vector within the mean() function.\nIf we want to clearly state which of the function arguments should receive the input, we can write a ., which can be read as output of the previous function call. That’s what we do in the seq() function. It calculates a sequence from 1 to the mean of c(45:100).\n\n\n\n\n\nInstall and load the palmerpenguins package.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# install.packages(\"palmerpenguins\")\nlibrary(palmerpenguins)\n\n\n\n\n\nTransform the penguins-tibble (available after loading the package) into a data.frame.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npenguins_frame &lt;- as.data.frame(penguins)\n\n\n\n\n\nCompare how both objects (tibble and data.frame) are printed into the console. Which differences can you see?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npenguins\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\npenguins_frame\n\n      species    island bill_length_mm bill_depth_mm flipper_length_mm\n1      Adelie Torgersen           39.1          18.7               181\n2      Adelie Torgersen           39.5          17.4               186\n3      Adelie Torgersen           40.3          18.0               195\n4      Adelie Torgersen             NA            NA                NA\n5      Adelie Torgersen           36.7          19.3               193\n6      Adelie Torgersen           39.3          20.6               190\n7      Adelie Torgersen           38.9          17.8               181\n8      Adelie Torgersen           39.2          19.6               195\n9      Adelie Torgersen           34.1          18.1               193\n10     Adelie Torgersen           42.0          20.2               190\n11     Adelie Torgersen           37.8          17.1               186\n12     Adelie Torgersen           37.8          17.3               180\n13     Adelie Torgersen           41.1          17.6               182\n14     Adelie Torgersen           38.6          21.2               191\n15     Adelie Torgersen           34.6          21.1               198\n16     Adelie Torgersen           36.6          17.8               185\n17     Adelie Torgersen           38.7          19.0               195\n18     Adelie Torgersen           42.5          20.7               197\n19     Adelie Torgersen           34.4          18.4               184\n20     Adelie Torgersen           46.0          21.5               194\n21     Adelie    Biscoe           37.8          18.3               174\n22     Adelie    Biscoe           37.7          18.7               180\n23     Adelie    Biscoe           35.9          19.2               189\n24     Adelie    Biscoe           38.2          18.1               185\n25     Adelie    Biscoe           38.8          17.2               180\n26     Adelie    Biscoe           35.3          18.9               187\n27     Adelie    Biscoe           40.6          18.6               183\n28     Adelie    Biscoe           40.5          17.9               187\n29     Adelie    Biscoe           37.9          18.6               172\n30     Adelie    Biscoe           40.5          18.9               180\n31     Adelie     Dream           39.5          16.7               178\n32     Adelie     Dream           37.2          18.1               178\n33     Adelie     Dream           39.5          17.8               188\n34     Adelie     Dream           40.9          18.9               184\n35     Adelie     Dream           36.4          17.0               195\n36     Adelie     Dream           39.2          21.1               196\n37     Adelie     Dream           38.8          20.0               190\n38     Adelie     Dream           42.2          18.5               180\n39     Adelie     Dream           37.6          19.3               181\n40     Adelie     Dream           39.8          19.1               184\n41     Adelie     Dream           36.5          18.0               182\n42     Adelie     Dream           40.8          18.4               195\n43     Adelie     Dream           36.0          18.5               186\n44     Adelie     Dream           44.1          19.7               196\n45     Adelie     Dream           37.0          16.9               185\n46     Adelie     Dream           39.6          18.8               190\n47     Adelie     Dream           41.1          19.0               182\n48     Adelie     Dream           37.5          18.9               179\n49     Adelie     Dream           36.0          17.9               190\n50     Adelie     Dream           42.3          21.2               191\n51     Adelie    Biscoe           39.6          17.7               186\n52     Adelie    Biscoe           40.1          18.9               188\n53     Adelie    Biscoe           35.0          17.9               190\n54     Adelie    Biscoe           42.0          19.5               200\n55     Adelie    Biscoe           34.5          18.1               187\n56     Adelie    Biscoe           41.4          18.6               191\n57     Adelie    Biscoe           39.0          17.5               186\n58     Adelie    Biscoe           40.6          18.8               193\n59     Adelie    Biscoe           36.5          16.6               181\n60     Adelie    Biscoe           37.6          19.1               194\n61     Adelie    Biscoe           35.7          16.9               185\n62     Adelie    Biscoe           41.3          21.1               195\n63     Adelie    Biscoe           37.6          17.0               185\n64     Adelie    Biscoe           41.1          18.2               192\n65     Adelie    Biscoe           36.4          17.1               184\n66     Adelie    Biscoe           41.6          18.0               192\n67     Adelie    Biscoe           35.5          16.2               195\n68     Adelie    Biscoe           41.1          19.1               188\n69     Adelie Torgersen           35.9          16.6               190\n70     Adelie Torgersen           41.8          19.4               198\n71     Adelie Torgersen           33.5          19.0               190\n72     Adelie Torgersen           39.7          18.4               190\n73     Adelie Torgersen           39.6          17.2               196\n74     Adelie Torgersen           45.8          18.9               197\n75     Adelie Torgersen           35.5          17.5               190\n76     Adelie Torgersen           42.8          18.5               195\n77     Adelie Torgersen           40.9          16.8               191\n78     Adelie Torgersen           37.2          19.4               184\n79     Adelie Torgersen           36.2          16.1               187\n80     Adelie Torgersen           42.1          19.1               195\n81     Adelie Torgersen           34.6          17.2               189\n82     Adelie Torgersen           42.9          17.6               196\n83     Adelie Torgersen           36.7          18.8               187\n84     Adelie Torgersen           35.1          19.4               193\n85     Adelie     Dream           37.3          17.8               191\n86     Adelie     Dream           41.3          20.3               194\n87     Adelie     Dream           36.3          19.5               190\n88     Adelie     Dream           36.9          18.6               189\n89     Adelie     Dream           38.3          19.2               189\n90     Adelie     Dream           38.9          18.8               190\n91     Adelie     Dream           35.7          18.0               202\n92     Adelie     Dream           41.1          18.1               205\n93     Adelie     Dream           34.0          17.1               185\n94     Adelie     Dream           39.6          18.1               186\n95     Adelie     Dream           36.2          17.3               187\n96     Adelie     Dream           40.8          18.9               208\n97     Adelie     Dream           38.1          18.6               190\n98     Adelie     Dream           40.3          18.5               196\n99     Adelie     Dream           33.1          16.1               178\n100    Adelie     Dream           43.2          18.5               192\n101    Adelie    Biscoe           35.0          17.9               192\n102    Adelie    Biscoe           41.0          20.0               203\n103    Adelie    Biscoe           37.7          16.0               183\n104    Adelie    Biscoe           37.8          20.0               190\n105    Adelie    Biscoe           37.9          18.6               193\n106    Adelie    Biscoe           39.7          18.9               184\n107    Adelie    Biscoe           38.6          17.2               199\n108    Adelie    Biscoe           38.2          20.0               190\n109    Adelie    Biscoe           38.1          17.0               181\n110    Adelie    Biscoe           43.2          19.0               197\n111    Adelie    Biscoe           38.1          16.5               198\n112    Adelie    Biscoe           45.6          20.3               191\n113    Adelie    Biscoe           39.7          17.7               193\n114    Adelie    Biscoe           42.2          19.5               197\n115    Adelie    Biscoe           39.6          20.7               191\n116    Adelie    Biscoe           42.7          18.3               196\n117    Adelie Torgersen           38.6          17.0               188\n118    Adelie Torgersen           37.3          20.5               199\n119    Adelie Torgersen           35.7          17.0               189\n120    Adelie Torgersen           41.1          18.6               189\n121    Adelie Torgersen           36.2          17.2               187\n122    Adelie Torgersen           37.7          19.8               198\n123    Adelie Torgersen           40.2          17.0               176\n124    Adelie Torgersen           41.4          18.5               202\n125    Adelie Torgersen           35.2          15.9               186\n126    Adelie Torgersen           40.6          19.0               199\n127    Adelie Torgersen           38.8          17.6               191\n128    Adelie Torgersen           41.5          18.3               195\n129    Adelie Torgersen           39.0          17.1               191\n130    Adelie Torgersen           44.1          18.0               210\n131    Adelie Torgersen           38.5          17.9               190\n132    Adelie Torgersen           43.1          19.2               197\n133    Adelie     Dream           36.8          18.5               193\n134    Adelie     Dream           37.5          18.5               199\n135    Adelie     Dream           38.1          17.6               187\n136    Adelie     Dream           41.1          17.5               190\n137    Adelie     Dream           35.6          17.5               191\n138    Adelie     Dream           40.2          20.1               200\n139    Adelie     Dream           37.0          16.5               185\n140    Adelie     Dream           39.7          17.9               193\n141    Adelie     Dream           40.2          17.1               193\n142    Adelie     Dream           40.6          17.2               187\n143    Adelie     Dream           32.1          15.5               188\n144    Adelie     Dream           40.7          17.0               190\n145    Adelie     Dream           37.3          16.8               192\n146    Adelie     Dream           39.0          18.7               185\n147    Adelie     Dream           39.2          18.6               190\n148    Adelie     Dream           36.6          18.4               184\n149    Adelie     Dream           36.0          17.8               195\n150    Adelie     Dream           37.8          18.1               193\n151    Adelie     Dream           36.0          17.1               187\n152    Adelie     Dream           41.5          18.5               201\n153    Gentoo    Biscoe           46.1          13.2               211\n154    Gentoo    Biscoe           50.0          16.3               230\n155    Gentoo    Biscoe           48.7          14.1               210\n156    Gentoo    Biscoe           50.0          15.2               218\n157    Gentoo    Biscoe           47.6          14.5               215\n158    Gentoo    Biscoe           46.5          13.5               210\n159    Gentoo    Biscoe           45.4          14.6               211\n160    Gentoo    Biscoe           46.7          15.3               219\n161    Gentoo    Biscoe           43.3          13.4               209\n162    Gentoo    Biscoe           46.8          15.4               215\n163    Gentoo    Biscoe           40.9          13.7               214\n164    Gentoo    Biscoe           49.0          16.1               216\n165    Gentoo    Biscoe           45.5          13.7               214\n166    Gentoo    Biscoe           48.4          14.6               213\n167    Gentoo    Biscoe           45.8          14.6               210\n168    Gentoo    Biscoe           49.3          15.7               217\n169    Gentoo    Biscoe           42.0          13.5               210\n170    Gentoo    Biscoe           49.2          15.2               221\n171    Gentoo    Biscoe           46.2          14.5               209\n172    Gentoo    Biscoe           48.7          15.1               222\n173    Gentoo    Biscoe           50.2          14.3               218\n174    Gentoo    Biscoe           45.1          14.5               215\n175    Gentoo    Biscoe           46.5          14.5               213\n176    Gentoo    Biscoe           46.3          15.8               215\n177    Gentoo    Biscoe           42.9          13.1               215\n178    Gentoo    Biscoe           46.1          15.1               215\n179    Gentoo    Biscoe           44.5          14.3               216\n180    Gentoo    Biscoe           47.8          15.0               215\n181    Gentoo    Biscoe           48.2          14.3               210\n182    Gentoo    Biscoe           50.0          15.3               220\n183    Gentoo    Biscoe           47.3          15.3               222\n184    Gentoo    Biscoe           42.8          14.2               209\n185    Gentoo    Biscoe           45.1          14.5               207\n186    Gentoo    Biscoe           59.6          17.0               230\n187    Gentoo    Biscoe           49.1          14.8               220\n188    Gentoo    Biscoe           48.4          16.3               220\n189    Gentoo    Biscoe           42.6          13.7               213\n190    Gentoo    Biscoe           44.4          17.3               219\n191    Gentoo    Biscoe           44.0          13.6               208\n192    Gentoo    Biscoe           48.7          15.7               208\n193    Gentoo    Biscoe           42.7          13.7               208\n194    Gentoo    Biscoe           49.6          16.0               225\n195    Gentoo    Biscoe           45.3          13.7               210\n196    Gentoo    Biscoe           49.6          15.0               216\n197    Gentoo    Biscoe           50.5          15.9               222\n198    Gentoo    Biscoe           43.6          13.9               217\n199    Gentoo    Biscoe           45.5          13.9               210\n200    Gentoo    Biscoe           50.5          15.9               225\n201    Gentoo    Biscoe           44.9          13.3               213\n202    Gentoo    Biscoe           45.2          15.8               215\n203    Gentoo    Biscoe           46.6          14.2               210\n204    Gentoo    Biscoe           48.5          14.1               220\n205    Gentoo    Biscoe           45.1          14.4               210\n206    Gentoo    Biscoe           50.1          15.0               225\n207    Gentoo    Biscoe           46.5          14.4               217\n208    Gentoo    Biscoe           45.0          15.4               220\n209    Gentoo    Biscoe           43.8          13.9               208\n210    Gentoo    Biscoe           45.5          15.0               220\n211    Gentoo    Biscoe           43.2          14.5               208\n212    Gentoo    Biscoe           50.4          15.3               224\n213    Gentoo    Biscoe           45.3          13.8               208\n214    Gentoo    Biscoe           46.2          14.9               221\n215    Gentoo    Biscoe           45.7          13.9               214\n216    Gentoo    Biscoe           54.3          15.7               231\n217    Gentoo    Biscoe           45.8          14.2               219\n218    Gentoo    Biscoe           49.8          16.8               230\n219    Gentoo    Biscoe           46.2          14.4               214\n220    Gentoo    Biscoe           49.5          16.2               229\n221    Gentoo    Biscoe           43.5          14.2               220\n222    Gentoo    Biscoe           50.7          15.0               223\n223    Gentoo    Biscoe           47.7          15.0               216\n224    Gentoo    Biscoe           46.4          15.6               221\n225    Gentoo    Biscoe           48.2          15.6               221\n226    Gentoo    Biscoe           46.5          14.8               217\n227    Gentoo    Biscoe           46.4          15.0               216\n228    Gentoo    Biscoe           48.6          16.0               230\n229    Gentoo    Biscoe           47.5          14.2               209\n230    Gentoo    Biscoe           51.1          16.3               220\n231    Gentoo    Biscoe           45.2          13.8               215\n232    Gentoo    Biscoe           45.2          16.4               223\n233    Gentoo    Biscoe           49.1          14.5               212\n234    Gentoo    Biscoe           52.5          15.6               221\n235    Gentoo    Biscoe           47.4          14.6               212\n236    Gentoo    Biscoe           50.0          15.9               224\n237    Gentoo    Biscoe           44.9          13.8               212\n238    Gentoo    Biscoe           50.8          17.3               228\n239    Gentoo    Biscoe           43.4          14.4               218\n240    Gentoo    Biscoe           51.3          14.2               218\n241    Gentoo    Biscoe           47.5          14.0               212\n242    Gentoo    Biscoe           52.1          17.0               230\n243    Gentoo    Biscoe           47.5          15.0               218\n244    Gentoo    Biscoe           52.2          17.1               228\n245    Gentoo    Biscoe           45.5          14.5               212\n246    Gentoo    Biscoe           49.5          16.1               224\n247    Gentoo    Biscoe           44.5          14.7               214\n248    Gentoo    Biscoe           50.8          15.7               226\n249    Gentoo    Biscoe           49.4          15.8               216\n250    Gentoo    Biscoe           46.9          14.6               222\n251    Gentoo    Biscoe           48.4          14.4               203\n252    Gentoo    Biscoe           51.1          16.5               225\n253    Gentoo    Biscoe           48.5          15.0               219\n254    Gentoo    Biscoe           55.9          17.0               228\n255    Gentoo    Biscoe           47.2          15.5               215\n256    Gentoo    Biscoe           49.1          15.0               228\n257    Gentoo    Biscoe           47.3          13.8               216\n258    Gentoo    Biscoe           46.8          16.1               215\n259    Gentoo    Biscoe           41.7          14.7               210\n260    Gentoo    Biscoe           53.4          15.8               219\n261    Gentoo    Biscoe           43.3          14.0               208\n262    Gentoo    Biscoe           48.1          15.1               209\n263    Gentoo    Biscoe           50.5          15.2               216\n264    Gentoo    Biscoe           49.8          15.9               229\n265    Gentoo    Biscoe           43.5          15.2               213\n266    Gentoo    Biscoe           51.5          16.3               230\n267    Gentoo    Biscoe           46.2          14.1               217\n268    Gentoo    Biscoe           55.1          16.0               230\n269    Gentoo    Biscoe           44.5          15.7               217\n270    Gentoo    Biscoe           48.8          16.2               222\n271    Gentoo    Biscoe           47.2          13.7               214\n272    Gentoo    Biscoe             NA            NA                NA\n273    Gentoo    Biscoe           46.8          14.3               215\n274    Gentoo    Biscoe           50.4          15.7               222\n275    Gentoo    Biscoe           45.2          14.8               212\n276    Gentoo    Biscoe           49.9          16.1               213\n277 Chinstrap     Dream           46.5          17.9               192\n278 Chinstrap     Dream           50.0          19.5               196\n279 Chinstrap     Dream           51.3          19.2               193\n280 Chinstrap     Dream           45.4          18.7               188\n281 Chinstrap     Dream           52.7          19.8               197\n282 Chinstrap     Dream           45.2          17.8               198\n283 Chinstrap     Dream           46.1          18.2               178\n284 Chinstrap     Dream           51.3          18.2               197\n285 Chinstrap     Dream           46.0          18.9               195\n286 Chinstrap     Dream           51.3          19.9               198\n287 Chinstrap     Dream           46.6          17.8               193\n288 Chinstrap     Dream           51.7          20.3               194\n289 Chinstrap     Dream           47.0          17.3               185\n290 Chinstrap     Dream           52.0          18.1               201\n291 Chinstrap     Dream           45.9          17.1               190\n292 Chinstrap     Dream           50.5          19.6               201\n293 Chinstrap     Dream           50.3          20.0               197\n294 Chinstrap     Dream           58.0          17.8               181\n295 Chinstrap     Dream           46.4          18.6               190\n296 Chinstrap     Dream           49.2          18.2               195\n297 Chinstrap     Dream           42.4          17.3               181\n298 Chinstrap     Dream           48.5          17.5               191\n299 Chinstrap     Dream           43.2          16.6               187\n300 Chinstrap     Dream           50.6          19.4               193\n301 Chinstrap     Dream           46.7          17.9               195\n302 Chinstrap     Dream           52.0          19.0               197\n303 Chinstrap     Dream           50.5          18.4               200\n304 Chinstrap     Dream           49.5          19.0               200\n305 Chinstrap     Dream           46.4          17.8               191\n306 Chinstrap     Dream           52.8          20.0               205\n307 Chinstrap     Dream           40.9          16.6               187\n308 Chinstrap     Dream           54.2          20.8               201\n309 Chinstrap     Dream           42.5          16.7               187\n310 Chinstrap     Dream           51.0          18.8               203\n311 Chinstrap     Dream           49.7          18.6               195\n312 Chinstrap     Dream           47.5          16.8               199\n313 Chinstrap     Dream           47.6          18.3               195\n314 Chinstrap     Dream           52.0          20.7               210\n315 Chinstrap     Dream           46.9          16.6               192\n316 Chinstrap     Dream           53.5          19.9               205\n317 Chinstrap     Dream           49.0          19.5               210\n318 Chinstrap     Dream           46.2          17.5               187\n319 Chinstrap     Dream           50.9          19.1               196\n320 Chinstrap     Dream           45.5          17.0               196\n321 Chinstrap     Dream           50.9          17.9               196\n322 Chinstrap     Dream           50.8          18.5               201\n323 Chinstrap     Dream           50.1          17.9               190\n324 Chinstrap     Dream           49.0          19.6               212\n325 Chinstrap     Dream           51.5          18.7               187\n326 Chinstrap     Dream           49.8          17.3               198\n327 Chinstrap     Dream           48.1          16.4               199\n328 Chinstrap     Dream           51.4          19.0               201\n329 Chinstrap     Dream           45.7          17.3               193\n330 Chinstrap     Dream           50.7          19.7               203\n331 Chinstrap     Dream           42.5          17.3               187\n332 Chinstrap     Dream           52.2          18.8               197\n333 Chinstrap     Dream           45.2          16.6               191\n334 Chinstrap     Dream           49.3          19.9               203\n335 Chinstrap     Dream           50.2          18.8               202\n336 Chinstrap     Dream           45.6          19.4               194\n337 Chinstrap     Dream           51.9          19.5               206\n338 Chinstrap     Dream           46.8          16.5               189\n339 Chinstrap     Dream           45.7          17.0               195\n340 Chinstrap     Dream           55.8          19.8               207\n341 Chinstrap     Dream           43.5          18.1               202\n342 Chinstrap     Dream           49.6          18.2               193\n343 Chinstrap     Dream           50.8          19.0               210\n344 Chinstrap     Dream           50.2          18.7               198\n    body_mass_g    sex year\n1          3750   male 2007\n2          3800 female 2007\n3          3250 female 2007\n4            NA   &lt;NA&gt; 2007\n5          3450 female 2007\n6          3650   male 2007\n7          3625 female 2007\n8          4675   male 2007\n9          3475   &lt;NA&gt; 2007\n10         4250   &lt;NA&gt; 2007\n11         3300   &lt;NA&gt; 2007\n12         3700   &lt;NA&gt; 2007\n13         3200 female 2007\n14         3800   male 2007\n15         4400   male 2007\n16         3700 female 2007\n17         3450 female 2007\n18         4500   male 2007\n19         3325 female 2007\n20         4200   male 2007\n21         3400 female 2007\n22         3600   male 2007\n23         3800 female 2007\n24         3950   male 2007\n25         3800   male 2007\n26         3800 female 2007\n27         3550   male 2007\n28         3200 female 2007\n29         3150 female 2007\n30         3950   male 2007\n31         3250 female 2007\n32         3900   male 2007\n33         3300 female 2007\n34         3900   male 2007\n35         3325 female 2007\n36         4150   male 2007\n37         3950   male 2007\n38         3550 female 2007\n39         3300 female 2007\n40         4650   male 2007\n41         3150 female 2007\n42         3900   male 2007\n43         3100 female 2007\n44         4400   male 2007\n45         3000 female 2007\n46         4600   male 2007\n47         3425   male 2007\n48         2975   &lt;NA&gt; 2007\n49         3450 female 2007\n50         4150   male 2007\n51         3500 female 2008\n52         4300   male 2008\n53         3450 female 2008\n54         4050   male 2008\n55         2900 female 2008\n56         3700   male 2008\n57         3550 female 2008\n58         3800   male 2008\n59         2850 female 2008\n60         3750   male 2008\n61         3150 female 2008\n62         4400   male 2008\n63         3600 female 2008\n64         4050   male 2008\n65         2850 female 2008\n66         3950   male 2008\n67         3350 female 2008\n68         4100   male 2008\n69         3050 female 2008\n70         4450   male 2008\n71         3600 female 2008\n72         3900   male 2008\n73         3550 female 2008\n74         4150   male 2008\n75         3700 female 2008\n76         4250   male 2008\n77         3700 female 2008\n78         3900   male 2008\n79         3550 female 2008\n80         4000   male 2008\n81         3200 female 2008\n82         4700   male 2008\n83         3800 female 2008\n84         4200   male 2008\n85         3350 female 2008\n86         3550   male 2008\n87         3800   male 2008\n88         3500 female 2008\n89         3950   male 2008\n90         3600 female 2008\n91         3550 female 2008\n92         4300   male 2008\n93         3400 female 2008\n94         4450   male 2008\n95         3300 female 2008\n96         4300   male 2008\n97         3700 female 2008\n98         4350   male 2008\n99         2900 female 2008\n100        4100   male 2008\n101        3725 female 2009\n102        4725   male 2009\n103        3075 female 2009\n104        4250   male 2009\n105        2925 female 2009\n106        3550   male 2009\n107        3750 female 2009\n108        3900   male 2009\n109        3175 female 2009\n110        4775   male 2009\n111        3825 female 2009\n112        4600   male 2009\n113        3200 female 2009\n114        4275   male 2009\n115        3900 female 2009\n116        4075   male 2009\n117        2900 female 2009\n118        3775   male 2009\n119        3350 female 2009\n120        3325   male 2009\n121        3150 female 2009\n122        3500   male 2009\n123        3450 female 2009\n124        3875   male 2009\n125        3050 female 2009\n126        4000   male 2009\n127        3275 female 2009\n128        4300   male 2009\n129        3050 female 2009\n130        4000   male 2009\n131        3325 female 2009\n132        3500   male 2009\n133        3500 female 2009\n134        4475   male 2009\n135        3425 female 2009\n136        3900   male 2009\n137        3175 female 2009\n138        3975   male 2009\n139        3400 female 2009\n140        4250   male 2009\n141        3400 female 2009\n142        3475   male 2009\n143        3050 female 2009\n144        3725   male 2009\n145        3000 female 2009\n146        3650   male 2009\n147        4250   male 2009\n148        3475 female 2009\n149        3450 female 2009\n150        3750   male 2009\n151        3700 female 2009\n152        4000   male 2009\n153        4500 female 2007\n154        5700   male 2007\n155        4450 female 2007\n156        5700   male 2007\n157        5400   male 2007\n158        4550 female 2007\n159        4800 female 2007\n160        5200   male 2007\n161        4400 female 2007\n162        5150   male 2007\n163        4650 female 2007\n164        5550   male 2007\n165        4650 female 2007\n166        5850   male 2007\n167        4200 female 2007\n168        5850   male 2007\n169        4150 female 2007\n170        6300   male 2007\n171        4800 female 2007\n172        5350   male 2007\n173        5700   male 2007\n174        5000 female 2007\n175        4400 female 2007\n176        5050   male 2007\n177        5000 female 2007\n178        5100   male 2007\n179        4100   &lt;NA&gt; 2007\n180        5650   male 2007\n181        4600 female 2007\n182        5550   male 2007\n183        5250   male 2007\n184        4700 female 2007\n185        5050 female 2007\n186        6050   male 2007\n187        5150 female 2008\n188        5400   male 2008\n189        4950 female 2008\n190        5250   male 2008\n191        4350 female 2008\n192        5350   male 2008\n193        3950 female 2008\n194        5700   male 2008\n195        4300 female 2008\n196        4750   male 2008\n197        5550   male 2008\n198        4900 female 2008\n199        4200 female 2008\n200        5400   male 2008\n201        5100 female 2008\n202        5300   male 2008\n203        4850 female 2008\n204        5300   male 2008\n205        4400 female 2008\n206        5000   male 2008\n207        4900 female 2008\n208        5050   male 2008\n209        4300 female 2008\n210        5000   male 2008\n211        4450 female 2008\n212        5550   male 2008\n213        4200 female 2008\n214        5300   male 2008\n215        4400 female 2008\n216        5650   male 2008\n217        4700 female 2008\n218        5700   male 2008\n219        4650   &lt;NA&gt; 2008\n220        5800   male 2008\n221        4700 female 2008\n222        5550   male 2008\n223        4750 female 2008\n224        5000   male 2008\n225        5100   male 2008\n226        5200 female 2008\n227        4700 female 2008\n228        5800   male 2008\n229        4600 female 2008\n230        6000   male 2008\n231        4750 female 2008\n232        5950   male 2008\n233        4625 female 2009\n234        5450   male 2009\n235        4725 female 2009\n236        5350   male 2009\n237        4750 female 2009\n238        5600   male 2009\n239        4600 female 2009\n240        5300   male 2009\n241        4875 female 2009\n242        5550   male 2009\n243        4950 female 2009\n244        5400   male 2009\n245        4750 female 2009\n246        5650   male 2009\n247        4850 female 2009\n248        5200   male 2009\n249        4925   male 2009\n250        4875 female 2009\n251        4625 female 2009\n252        5250   male 2009\n253        4850 female 2009\n254        5600   male 2009\n255        4975 female 2009\n256        5500   male 2009\n257        4725   &lt;NA&gt; 2009\n258        5500   male 2009\n259        4700 female 2009\n260        5500   male 2009\n261        4575 female 2009\n262        5500   male 2009\n263        5000 female 2009\n264        5950   male 2009\n265        4650 female 2009\n266        5500   male 2009\n267        4375 female 2009\n268        5850   male 2009\n269        4875   &lt;NA&gt; 2009\n270        6000   male 2009\n271        4925 female 2009\n272          NA   &lt;NA&gt; 2009\n273        4850 female 2009\n274        5750   male 2009\n275        5200 female 2009\n276        5400   male 2009\n277        3500 female 2007\n278        3900   male 2007\n279        3650   male 2007\n280        3525 female 2007\n281        3725   male 2007\n282        3950 female 2007\n283        3250 female 2007\n284        3750   male 2007\n285        4150 female 2007\n286        3700   male 2007\n287        3800 female 2007\n288        3775   male 2007\n289        3700 female 2007\n290        4050   male 2007\n291        3575 female 2007\n292        4050   male 2007\n293        3300   male 2007\n294        3700 female 2007\n295        3450 female 2007\n296        4400   male 2007\n297        3600 female 2007\n298        3400   male 2007\n299        2900 female 2007\n300        3800   male 2007\n301        3300 female 2007\n302        4150   male 2007\n303        3400 female 2008\n304        3800   male 2008\n305        3700 female 2008\n306        4550   male 2008\n307        3200 female 2008\n308        4300   male 2008\n309        3350 female 2008\n310        4100   male 2008\n311        3600   male 2008\n312        3900 female 2008\n313        3850 female 2008\n314        4800   male 2008\n315        2700 female 2008\n316        4500   male 2008\n317        3950   male 2008\n318        3650 female 2008\n319        3550   male 2008\n320        3500 female 2008\n321        3675 female 2009\n322        4450   male 2009\n323        3400 female 2009\n324        4300   male 2009\n325        3250   male 2009\n326        3675 female 2009\n327        3325 female 2009\n328        3950   male 2009\n329        3600 female 2009\n330        4050   male 2009\n331        3350 female 2009\n332        3450   male 2009\n333        3250 female 2009\n334        4050   male 2009\n335        3800   male 2009\n336        3525 female 2009\n337        3950   male 2009\n338        3650 female 2009\n339        3650 female 2009\n340        4000   male 2009\n341        3400 female 2009\n342        3775   male 2009\n343        4100   male 2009\n344        3775 female 2009\n\n\n\ntibbles only print 10 rows by default, data.frames a lot more.\ntibbles only print as many columns as possible in one row, which looks a lot cleaner.\nOn top, the tibble shows us how many rows and columns there are in our data.\nNAs are printed in red in tibbles (not in this output, but try it yourself).\nThe data-type of each column is printed on top of the column in tibbles.\n\n\n\n\n\nSave your penguins data.frame and your penguins tibble as .RDS files in a dedicated data folder in your R-project. Use relative paths!\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nsaveRDS(penguins, file = \"./data/penguins.RDS\")\nsaveRDS(penguins_frame, file = \"./data/penguins_frame.RDS\")\n\n\n\n\n\nLoad your penguins data.frame and your penguins tibble into R. Use the here package.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(here)\n\nreadRDS(here::here(\"data\", \"penguins.RDS\"))\nreadRDS(here::here(\"data\", \"penguins_frame.RDS\"))"
  },
  {
    "objectID": "docs/r_sig/24_01_26_tidyverse_intro/index.html#footnotes",
    "href": "docs/r_sig/24_01_26_tidyverse_intro/index.html#footnotes",
    "title": "Introduction to the tidyverse",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Barn Images on Unsplash.↩︎"
  },
  {
    "objectID": "docs/r_sig/23_03_20_forloops/index.html",
    "href": "docs/r_sig/23_03_20_forloops/index.html",
    "title": "for-loops",
    "section": "",
    "text": "1"
  },
  {
    "objectID": "docs/r_sig/23_03_20_forloops/index.html#for-loops",
    "href": "docs/r_sig/23_03_20_forloops/index.html#for-loops",
    "title": "for-loops",
    "section": "For-loops",
    "text": "For-loops\nIn this session we talked about for-loops. Take a look here for the corresponding chapter in a workshop I’ve designed."
  },
  {
    "objectID": "docs/r_sig/23_03_20_forloops/index.html#footnotes",
    "href": "docs/r_sig/23_03_20_forloops/index.html#footnotes",
    "title": "for-loops",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Tine Ivanic on Unsplash.↩︎"
  },
  {
    "objectID": "docs/r_sig/24_06_03_ggplot2/index.html",
    "href": "docs/r_sig/24_06_03_ggplot2/index.html",
    "title": "Plotting with ggplot2",
    "section": "",
    "text": "1\nA ggplot2-tutorial I’ve created can be found here."
  },
  {
    "objectID": "docs/r_sig/24_06_03_ggplot2/index.html#footnotes",
    "href": "docs/r_sig/24_06_03_ggplot2/index.html#footnotes",
    "title": "Plotting with ggplot2",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Bing Copilot.↩︎"
  },
  {
    "objectID": "docs/r_sig/24_09_09_quarto_git/index.html",
    "href": "docs/r_sig/24_09_09_quarto_git/index.html",
    "title": "Reproducible manuscripts with Git",
    "section": "",
    "text": "1"
  },
  {
    "objectID": "docs/r_sig/24_09_09_quarto_git/index.html#footnotes",
    "href": "docs/r_sig/24_09_09_quarto_git/index.html#footnotes",
    "title": "Reproducible manuscripts with Git",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Towfiqu barbhuiya on Unsplash.↩︎"
  },
  {
    "objectID": "docs/r_sig/24_03_22_datasets/index.html",
    "href": "docs/r_sig/24_03_22_datasets/index.html",
    "title": "Data sets",
    "section": "",
    "text": "We will use two data sets for some time in the R SIG now. One for the theory, and one for you to work on in the exercises."
  },
  {
    "objectID": "docs/r_sig/24_03_22_datasets/index.html#theory-olympic-athletes",
    "href": "docs/r_sig/24_03_22_datasets/index.html#theory-olympic-athletes",
    "title": "Data sets",
    "section": "1 Theory: Olympic athletes",
    "text": "1 Theory: Olympic athletes\n1\nFor the theory part of the workshop, we will mainly work with the athletes data set. It contains the Olympic athletes from 1896 to 2016, along with some basic stats, their sport and country, and the medals they won.\n\n\n\n\n\n\nGoal\n\n\n\nOur goal for the theory part of this workshop is to find the best country in each sport (operationalized by the number of gold medal winners from this country)."
  },
  {
    "objectID": "docs/r_sig/24_03_22_datasets/index.html#exercises-fictional-characters",
    "href": "docs/r_sig/24_03_22_datasets/index.html#exercises-fictional-characters",
    "title": "Data sets",
    "section": "2 Exercises: Fictional characters",
    "text": "2 Exercises: Fictional characters\n2\nOver the course of this workshop, you can work on exercises to put the theoretical knowledge you acquired in the chapters to use. Most of these exercises will use the characters data set, which contains psychometric ratings for different fictional characters, rated by a large number of people on a personality scale developed by the author of the questionnaire.\nYou will load the data, prepare it for analyses and also plot it in the end.\n\n\n\n\n\n\nGoal\n\n\n\nThe goal for the exercise part of this workshop is to build a character profile for a fictional universe of your choosing.\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe have looked at how to download these data sets in the this exercise."
  },
  {
    "objectID": "docs/r_sig/24_03_22_datasets/index.html#footnotes",
    "href": "docs/r_sig/24_03_22_datasets/index.html#footnotes",
    "title": "Data sets",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Florian Schmetz on Unsplash.↩︎\nImage by Ilse Orsen on Unsplash.↩︎"
  },
  {
    "objectID": "docs/FAQ/FAQ2_eatModel-Conquest.html",
    "href": "docs/FAQ/FAQ2_eatModel-Conquest.html",
    "title": "Frage 2: ‘estDif’ in Conquest/eatModel",
    "section": "",
    "text": "In eatModel wird nur der erste Teil der zweiten Tabelle \\(\\text{item}\\times\\text{[DIFvariable]}\\) aus Conquest übertragen. Das bedeutet, dass negative Werte in der eatModel-estDif-Spalte dafür stehen, dass die jeweiligen Items in der ersten Gruppe der \\(\\text{[DIFvariable]}\\) leichter sind. Die erste Gruppe ist die mit dem numerisch kleineren Gruppenindikatorwert. Zur Illustration ein Beispiel, das Daten aus dem TAM-Paket verwendet:\nlibrary(kableExtra)\nlibrary(eatTools)\nlibrary(eatModel)\ndata(data.ex08, package=\"TAM\")\n# Gesamtdatensatz bauen, der sowohl Personen-ID, DIF-Variable als auch responses enthaelt\ndat &lt;- data.frame(id = 1:nrow(data.ex08[[\"resp\"]]), female = unlist(data.ex08[[\"facets\"]])-1, \n       data.ex08[[\"resp\"]])\ndef &lt;- defineModel(dat, items= -c(1:2), id=\"id\", DIF.var = \"female\", software=\"tam\")\n\n14 subject(s) do not solve any item:\n   115 (10 false), 613 (10 false), 979 (10 false) ... \n7 subject(s) solved each item: 119 (10 correct), 514 (10 correct), 774 (10 correct) ... \nDataset is completely linked.\n'gauss' has been chosen for estimation method. Number of nodes was not explicitly specified. Set nodes to 20.\nQ matrix specifies 1 dimension(s).\n\nrun &lt;- runModel(def)\nres &lt;- getResults(run, verbose=FALSE)\nitem &lt;- itemFromRes(res)\nDas einzige Item mit B-DIF entsprechend der ETS-Kriterien ist Item Nummer 6:\nitem6 &lt;- subset(roundDF(item,digits = 3), item == \"I0006\")\ncols  &lt;- c(\"item\", \"itemP\", \"est\", \"estDif\", \"absDif\", \"difIndex\", \"ETS\")\n# ausgewaehlte Spalten fuer Items 6 anzeigen lassen \nkbl(item6[,cols], row.names=FALSE) %&gt;% \n    kable_styling(bootstrap_options = \"striped\", full_width = FALSE, position = \"center\")\n\n\n\n\nitem\nitemP\nest\nestDif\nabsDif\ndifIndex\nETS\n\n\n\n\nI0006\n0.454\n0.226\n0.31\n0.62\n1\nB\nDie allgemeine Lösungshäufigkeit des Items ist 45.4 Prozent. Der positive DIF-Wert von 0.31 bedeutet, dass das Item in der ersten Gruppe (also female = 0, die Gruppe der Jungen) schwerer ist. Die Lösungshäufigkeit sollte also für female = 0 geringer sein, als für female = 1:\ntapply(dat[,\"I0006\"], dat[,\"female\"], mean)\n\n    0     1 \n0.410 0.498\nDie beiden Spalten “estDif” und “absDif” im Output unterscheiden dabei insofern, als dass für zwei Gruppen (hier: “male” und “female”) “absDif” immer doppelt so groß wie “estDif” und im Betrag positiv ist. Im DIF-Modell hat jedes Item zwei Parameter, einen Schwierigkeitsparameter “est” und einen DIF-Parameter “estDif”. Bei dichotomen, näherungsweise gleichverteilten Gruppen wie Geschlecht entspricht der “est”-Parameter in etwa dem Wert, den man erhalten würde, wenn ein einfaches Raschmodell ohne separate Betrachtung der Geschlechtergruppen modelliert werden würde. “estDif” ist nun der Wert, den man (näherungsweise) für die Referenzgruppe addieren und für die Fokusgruppe subtrahieren muss, um die Werte zu erhalten, die bei separater Modellierung der Gruppen resultieren würden. Da der Wert einmal addiert, einmal subtrahiert wird, ist die Differenz des Itemparameters in Referenz- und Fokusgruppe im Betrag doppelt so groß wie der DIF-Parameter “estDif”. Für unser Beispiel (Referenzgruppe = “male”) bedeutet das: Bei separater Modellierung würde ich für die Jungen einen Itemparameter 0.226 + 0.31 = 0.536 erwarten, und für die Mädchen 0.226 - 0.31 = -0.084. Das soll hier kurz veranschaulicht werden:\nspl &lt;- splitModels(person.groups = dat[,c(\"id\", \"female\")], all.persons = FALSE, nCores = 1)\n\n--------------------------------\nsplitModels: generating 2 models\n..\nsee &lt;returned&gt;$models\nnumber of cores: 1\n--------------------------------\n\ndef &lt;- defineModel(dat, id = \"id\", items= -c(1:2), splittedModels = spl, software=\"tam\")\n\n\nSpecification of 'qMatrix' and 'person.groups' results in 2 model(s).\n\n\n==================================\nModel No. 1\n    Model name:           female.0\n    Number of items:      10\n    Number of persons:    500\n    Number of dimensions: 1\n==================================\n\n6 subject(s) do not solve any item:\n   115 (10 false), 270 (10 false), 9 (10 false) ... \n4 subject(s) solved each item: 119 (10 correct), 139 (10 correct), 62 (10 correct) ... \nDataset is completely linked.\n'gauss' has been chosen for estimation method. Number of nodes was not explicitly specified. Set nodes to 20.\nQ matrix specifies 1 dimension(s).\n\n\n==================================\nModel No. 2\n    Model name:           female.1\n    Number of items:      10\n    Number of persons:    500\n    Number of dimensions: 1\n==================================\n\n8 subject(s) do not solve any item:\n   543 (10 false), 752 (10 false), 979 (10 false) ... \n3 subject(s) solved each item: 514 (10 correct), 569 (10 correct), 774 (10 correct) ... \nDataset is completely linked.\n'gauss' has been chosen for estimation method. Number of nodes was not explicitly specified. Set nodes to 20.\nQ matrix specifies 1 dimension(s).\n\nrun &lt;- runModel(def)\nres &lt;- getResults(run, verbose=FALSE)\nitem&lt;- itemFromRes(res)\ncols&lt;- c(\"model\", \"item\", \"itemP\", \"est\")\nkbl(roundDF(subset(item, item == \"I0006\")[,cols],digits = 3), row.names=FALSE) %&gt;% \n    kable_styling(bootstrap_options = \"striped\", full_width = FALSE, position = \"center\")\n\n\n\n\nmodel\nitem\nitemP\nest\n\n\n\n\nfemale.0\nI0006\n0.410\n0.443\n\n\nfemale.1\nI0006\n0.498\n0.006\nLinkt man nun die beiden separat modellierten Gruppen “male” und “female” aneinander, entspricht der DIF für das Item “I0006” näherungsweise dem zuvor in einem gemeinsamen DIF-Modell geschätzten DIF-Parameter:\nitemFokus &lt;- subset(res, model == \"female.1\")\nreferenz  &lt;- subset(itemFromRes(res), model == \"female.0\")\nequating  &lt;- equat1pl(results = itemFokus, prmNorm = referenz[,c(\"item\", \"est\")],  \n             difBound = 0.6, iterativ = TRUE)\n\nFound 1 model(s).\n   Equating is executed for each dimension in each model separately.\n\n====================================================================================================\n \nModel No. 1\n    Model name:                female.1\n    Number of dimension(s):    1\n    Name(s) of dimension(s):   Dim1\n    Number of linking items:   10\n    Linking method:            Mean.Mean\n\nDimension 'Dim1': 1 of 10 items with linking |DIF| &gt; 0.6 identified.\n   Iteration 1: Exclude item 'I0006'.\n\n    method iter itemExcluded DIF.excluded linking.constant linkerror\n1 iterativ    0                                     -0.182     0.096\n2 iterativ    1        I0006       -0.603           -0.251     0.074"
  },
  {
    "objectID": "docs/FAQ/FAQ2_eatModel-Conquest.html#section",
    "href": "docs/FAQ/FAQ2_eatModel-Conquest.html#section",
    "title": "Frage 2: ‘estDif’ in Conquest/eatModel",
    "section": "",
    "text": "Weitere Fragen und/oder deren Antworten können abgelegt und eingesehen werden unter: t:/SIG/SIG Methoden/Liste methodischer Fragen.docx"
  },
  {
    "objectID": "docs/FAQ/FAQ4_NproItem.html",
    "href": "docs/FAQ/FAQ4_NproItem.html",
    "title": "Frage 4: N pro Item",
    "section": "",
    "text": "Grundsätzlich stellt sich die Frage des N pro Item in erster Linie bei Pilotierungsstudien, wo die Inferenz auf der Itemebene (anstatt der Personenebene) stattfindet. Einen festen Grenzwert gibt es hier nicht, wobei größer natürlich immer besser ist. Es gibt jedoch Daumenregeln und es hängt von den Analysen ab, die mit den gewonnenen Daten unternommen werden sollen. Als Minimalwert kann man sich an \\(N&gt;100\\) orientieren. Im Studiendesign versucht man dabei, auf ein \\(N=150\\) zuzusteuern, damit selbst trotz unvorhergesehener Ausfälle bspw. aufgrund von Krankheit Einzelner die 100 niemals unterschritten wird. Konkret können die praktisch notwendigen Stichprobenzahlen aber auch größer ausfallen, zum Beispiel:"
  },
  {
    "objectID": "docs/FAQ/FAQ4_NproItem.html#section",
    "href": "docs/FAQ/FAQ4_NproItem.html#section",
    "title": "Frage 4: N pro Item",
    "section": "",
    "text": "Weitere Fragen und/oder deren Antworten können abgelegt und eingesehen werden unter: t:/SIG/SIG Methoden/Liste methodischer Fragen.docx"
  },
  {
    "objectID": "docs/quarto/index.html",
    "href": "docs/quarto/index.html",
    "title": "Updating the website",
    "section": "",
    "text": "This website was created using Quarto. It is hosted on GitHub. In this chapter we will look at the underlying structure of this website, and how to update it."
  },
  {
    "objectID": "docs/quarto/index.html#setup",
    "href": "docs/quarto/index.html#setup",
    "title": "Updating the website",
    "section": "Setup",
    "text": "Setup\n\nAs the website is hosted on GitHub, you can just clone the repository.\nOpen the RStudio project with RStudio.\nThis website uses renv to keep the project specific package library up to date.\n\n\nrenv\n\n\n\n\n\n\nImportant\n\n\n\nMake sure you’re using the R version recorded in the LOCK-file when working with renv. This makes things a bit easier. Of course, if the R version in the LOCK file is an old one, you can update it with renv::snapshot().\n\n\nWandering what renv is? Check out the renv Intro for more information.\nThe needed packages are recorded in the .lock-file, but not uploaded to GitHub. So the first thing you need to do is to install the necessary packages into your local project library:\n\n# install.packages(\"renv\")\nrenv::restore()\n\nYou can do this every time you start working on the website. Only packages that are not already in your project specific package library will be downloaded.\nIf your files need their own packages, just install them like you would normally do with either:\n\ninstall.packages(\"eatGADS\")\nrenv::install(\"eatGADS\")\n\nYou need to do this even if you have them already installed on your PC locally, because renv uses a project specific library.\n\n\n\n\n\n\nImportant\n\n\n\nDon’t forget to update the .lock file with renv::snapshot() if you have added new packages in your code. Otherwise the GitHub-Action will fail. But be concious about what is updated. If you are using an old version in the project, or old package versions, you might downgrade the projects package versions. So run renv::restore() before, to make sure your project library is up to date. renv will show you in the console what is updated from which version to which version."
  },
  {
    "objectID": "docs/quarto/index.html#file-structure",
    "href": "docs/quarto/index.html#file-structure",
    "title": "Updating the website",
    "section": "File structure",
    "text": "File structure\nBasically you just need to know where to put your files. Everything else will be taken care of by pushing to GitHub. Files can go into one of two folders: docs or posts. docs contains most of the tutorial files: They are structured into sub folders, like eatPackages or R. Here the quarto-files can be found that contain the actual website content. Edit them or add new ones. Make sure they are quarto-files with the .qmd ending.\n\n_quarto.yml\nOn the highest directory level you can find the _quarto.yml file. It defines the structure of the website. If you want your new page to be displayed in the website navigation, you have to add it here. You can define different sections and give name the links to the websites:\n    contents:\n      - section: \"R Tutorials\"\n        contents:\n          - section: \"Introduction\"\n            contents:\n             - docs/R/index.qmd\n             - href: https://nickhaf.github.io/r_tutorial/\n               text: Selfpaced R Workshop\n             - href: docs/R/ws1.qmd\n               text: Einführung\nThis creates the section R Tutorials with the subsection Introduction. Introduction consists of three pages: the index.qmd page, which is like the main page of this section, the page Selfpaced R Workshop, which actually is only a link to another website, and the page Einführung, which links to the qmd-file ws1.qmd. Just add your pages where appropriate.\n\n\nquarto-files\nThe quarto-files contain the actual content of the website. Just edit them like you would edit .qmd-files (or .rmd-files, as the rmarkdown syntax is quite similar). An introduction to the basic quarto functions can be found in the R SIG. Here are some additional useful tips:\n\nLinking\nYou can easily link to other pages of this website, or to other websites:\n[displayed text](link.de)\nYou might need to use relative paths: [renv](../r_sig/23_11_06_renv/index.qmd). This will link to the renv page in the posts directory.\n\n\nPictures\nTo add a picture to your website, save the picture in the same folder as your .qmd-file. Then you can display it with:\n![](my_image.jpg)\n1\n\n\nFootnotes\nYou can add footnotes with:\nAdd a footnote[^2].\n\n[^2]: My Footnote.\nAdd a footnote2.\n\n\nCallouts\nYou can add little information boxes like this:\n::: callout-tip\nThe R-SIG meets each every two weeks on Monday from 13:00 - 14:00.\n:::\n\n\n\n\n\n\nTip\n\n\n\nThe R-SIG meets each every two weeks on Monday from 13:00 - 14:00.\n\n\nThere are multiple different options, take a look at the documentation for more.\n\n\nCSS styles\nYou can tweak the appearence even more by using you own CSS-styles.\n\n\n\nEditing on the web page\nYou can also find a small button called Edit this page next to the GitHub logo. This allows you to edit the page directly on GitHub."
  },
  {
    "objectID": "docs/quarto/index.html#building-the-website",
    "href": "docs/quarto/index.html#building-the-website",
    "title": "Updating the website",
    "section": "Building the website",
    "text": "Building the website\nTo get a preview of your website, click on the Render button in R Studio. Make sure you are not working locally and not on the network drive, because you might run into admin right problems otherwise. The rendering is not really necessary, because the website will only be built online when you push to GitHub. It will take a while (up to 20 min or more, depending on the size of the website) until the website is updated, as some checks are run first. The website will already get updated if you just open a pull request that wants to merge into main."
  },
  {
    "objectID": "docs/quarto/index.html#further-reading",
    "href": "docs/quarto/index.html#further-reading",
    "title": "Updating the website",
    "section": "Further reading",
    "text": "Further reading\nThe official documentation can be found here. A nice hands on tutorial on adding blog posts to an existing Quarto website can be found here, along with some additional tips on citations, footnotes etc."
  },
  {
    "objectID": "docs/quarto/index.html#footnotes",
    "href": "docs/quarto/index.html#footnotes",
    "title": "Updating the website",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Sinjin Thomas on Unsplash.↩︎\nMy Footnote.↩︎"
  },
  {
    "objectID": "docs/discussions/code_conventions.html",
    "href": "docs/discussions/code_conventions.html",
    "title": "Code-Konventionen",
    "section": "",
    "text": "Diese Seite dient als Zusammenfassung unserer Beschlüsse hinsichtlich bestimmter Code-Konventionen, die wir im Team verfolgen wollen. Zum Absprechen dieser Themen treffen wir uns regelmäßig einmal im Monat.\n1"
  },
  {
    "objectID": "docs/discussions/code_conventions.html#umfang-von-code-abschnitten",
    "href": "docs/discussions/code_conventions.html#umfang-von-code-abschnitten",
    "title": "Code-Konventionen",
    "section": "Umfang von Code-Abschnitten",
    "text": "Umfang von Code-Abschnitten\n\nGenerell sollte innerhalb einer Zeile möglichst wenig passieren. Als Orientierung: eine Zeile sollte nicht mehr als 100 Zeichen beinhalten.\nGleiches gilt für eine Funktion: sie sollte maximal 100 Zeilen lang sein, und eher in Sub-Funktionen aufgeteilt werden.\nIn R-Paketen sollte es pro exportierter Funktion ein eigenes Skript geben. Zu Hilsfunktionen haben wir noch nichts beschlossen.\n\nBei Funktionen mit vielen Funktionsargumenten soll eine Liste von Funktionsargumenten innerhalb der internen Funktionsköpfe übergeben werden.\nRigoroses Testen kann helfen bei Ergänzung oder Löschung von Funktionsargumenten den Überblick zu behalten."
  },
  {
    "objectID": "docs/discussions/code_conventions.html#benennungskonventionen",
    "href": "docs/discussions/code_conventions.html#benennungskonventionen",
    "title": "Code-Konventionen",
    "section": "Benennungskonventionen",
    "text": "Benennungskonventionen\n\nBei längeren Objektnamen sollten Punkte vermieden werden und entweder CamelCases oder snake_cases genutzt werden. Das aber jeweils konsistent innerhalb von Paketen.\nEs sollten eher sprechende Namen als möglichst kurse Namen verwendet werden.\nFunktionsnamen sollten aus Verben bestehen.\nObjektnamen (die keine Funktionen sind) sollten Substantive sein.\nDopplungen mit existierenden R-Objekten sollten vermieden werdeen.\nBei der Objekt-Modifikation sollten Objekte nicht überschreiben werden, wenn sie sich substanziell ändern.\nEinige häufige Argumentnamen: dat, path/file/filePath/filename, dir/folder, …\nBei der Argumentreihenfolge sollte die Pipebarkeit und Output-Steuerung beachtet werden."
  },
  {
    "objectID": "docs/discussions/code_conventions.html#dependencies",
    "href": "docs/discussions/code_conventions.html#dependencies",
    "title": "Code-Konventionen",
    "section": "Dependencies",
    "text": "Dependencies\npkgnet kann genutzt werden, um die Dependencies innerhalb eines Pakets zu visualisieren."
  },
  {
    "objectID": "docs/discussions/code_conventions.html#code-review",
    "href": "docs/discussions/code_conventions.html#code-review",
    "title": "Code-Konventionen",
    "section": "Code Review",
    "text": "Code Review\nEine übersicht zum GitHub-Workflow findet sich hier. Eine etwas ausführlicheres Tutorial zur Einführung in GitHub, aber auch zu Pull-Requests und Code-Reviews findet sich hier.\n\nVorgehen\n\nPerson, die das Review anfordert, schlägt Personen für das Review for, in dem diese zur Pull-Request assigned werden.\nSind mehrere Reviewer zum Review assigned, reicht es i.d.R. wenn eine:r das Review übernimmt (es sei denn, es wird explizit angefordert, dass alle das Review übernehmen)\nÜbernimmt man ein Review, assigned man sich selbst den Pull-Request, dann wissen alle potenziell angesprochenen Reviewer gleich Bescheid, dass man übernimmt, auch wenn man noch nicht angefangen hat (bzw. noch keine Kommentare in den Code gesetzt hat)\n\n\n\nWas muss bei der Anforderung eines Reviews beachtet werden?\n\nEher kleinschrittige, abgeschlossene Bestandteile reviewen lassen.\nPriorität festlegen:\n\nhigh: innerhalb eines Tages\nmedium: innerhalb einer Woche\nlow: keine Zeitbegrenzung\n\n\n\n\nWas sollen die Reviewer machen?\n\nSich zum Review assignen, wenn man anfängt.\nAchten ob Benennungskonventionen und Formatkonventionen eingehalten wurden.\nPrüfen, ob der code verständlich geschrieben ist und möglichst keine erklärenden Kommentare benötigt.\nTests auf Vollständigkeit überprüfen (sind mögliche Edge Cases (NA, negative Werte, hohe/niedrige Werte, anderer data type …) abgedeckt?).\n\n\nOptional:\n\n\nMit den Tests rumspielen, versuchen die Funktion failen zu lassen.\n\n\n\nPersonelle Aufteilung\n\neatPrepTBA: PF, NH, KAS, … (mal schauen)\neatPrep: KAS, PF, NH\neatPlot: NH, PF, KAS\neatModel: SW, KAS, BB\neatRep: SW, BB, KAS\neatTools: SW, KAS, BB, NH, PF\neatAnalysis: BB, SW, KAS\neatGADS: BB, KAS, NH\neatDB: BB, PF, NH\neatFDZ: BB, NH\neatCodebook: BB, SW, PF, NH\neatRecode: BB, NH\neatATA: BB, DD, ?\n\n\n\nKommunikation & Zeiterwartung\n\nPerson, die das Review anfordert, schreibt ein paar Sätze dazu, worauf besonders geachtete werden sollte als Kommentar in den Pull-Request. Das können grobe Erwartungen an das Review sein (macht das konzeptuell Sinn, decken die Tests alle möglichen Edge cases ab …), oder eine Prioritätenfestlegung.\nLabel sollen einheitlich über die Repositories erstell und genutzt werden (Bug/Enhancement …, Prio-Label)"
  },
  {
    "objectID": "docs/discussions/code_conventions.html#issues",
    "href": "docs/discussions/code_conventions.html#issues",
    "title": "Code-Konventionen",
    "section": "Issues",
    "text": "Issues\n\nWir nutzen GitHub-Projects um alle ToDos aus verschiedenen Repos an einem Ort zu sammeln.\n\nWichtige Issues aus jedem Repo sollten im Projekt hinzugefügt werden.\n\n\nIssues aus einem anderen Repository zum Projekt hinzufügen\n\nClick on Add item\n#beckerbenj/eatGADS\nFrom the suggested list you can choose the issue you want to add to the project, or create a new one.\n\nYou can filter for all open issues with is:issue is:open.\n\n\n\nIssue sorting\n\nColumn “Done” contains all finished issues. They will be discussed one last time at the jour fix, and than the issue will be closed together.\nEverything should be an issue, not a draft! Drafts without a project can fit into iqb-research/to-dos."
  },
  {
    "objectID": "docs/discussions/code_conventions.html#branch-benennung",
    "href": "docs/discussions/code_conventions.html#branch-benennung",
    "title": "Code-Konventionen",
    "section": "Branch-Benennung",
    "text": "Branch-Benennung\nSiehe hier.\n\nRegeln:\n\nerstes Element: Feature/Bugfix/Hotfix/Docu/Release\nzweites Element: Issue-Nummer\ndrittes Element: Kurz-Beschreibung\n\n\n\nBeispiele:\n\nfeature/33-asNumericIfPossible-for-logicals\nbugfix/45-dataframes-in-cleanifyStrings\ndocu/68-data-cleaning-vignette"
  },
  {
    "objectID": "docs/discussions/code_conventions.html#commit-benennung",
    "href": "docs/discussions/code_conventions.html#commit-benennung",
    "title": "Code-Konventionen",
    "section": "Commit-Benennung",
    "text": "Commit-Benennung\nSiehe hier.\n\nRegeln:\n\nerstes Element: worauf bezieht sich der Commit (zB Funktionsname)\nzweites Element: Kurz-Beschreibung\nin Kurzbeschreibung: Präsenz verwenden und sich kurz fassen\n\n\n\nBeispiele:\n\nasNumericIfPossible: Add methods for logical and factor\nmerge.GADSdat: Add by.x and by.y arguments\ncleanifyString: Add missing argument documentation\n\n\n\n\n\n\n\nWichtige Voraussetzung\n\n\n\nEin Commit muss eine in sich sinnvoll abgeschlossene Einheit darstellen!"
  },
  {
    "objectID": "docs/discussions/code_conventions.html#umfang-von-code-abschnitten-1",
    "href": "docs/discussions/code_conventions.html#umfang-von-code-abschnitten-1",
    "title": "Code-Konventionen",
    "section": "Umfang von Code-Abschnitten",
    "text": "Umfang von Code-Abschnitten\n\nGenerell sollte innerhalb einer Zeile möglichst wenig passieren. Als Orientierung gilt: Eine Zeile sollte maximal 100 Zeichen beinhalten. Dies gilt für Code, Dokumentation und Kommentare.\n\nZu empfehlende Lösungsoptionen sind “harte” Zeilenumbrüche, das Erstellen und Aufrufen zusätzlicher Objekte und Pipen.\n\nGleiches gilt für eine Funktion. Sie sollte maximal 100 Zeilen lang sein.\nAnzahl der Funktionsargumenten in einer Funktion\n\nEs gibt mehrere Möglichkeiten, mit sehr vielen Argumenten un Funktionskopf umzugehen:\n\nFunktion, die eine Liste mit Default-Werten erzeugt, die dann überschrieben werden können (z.B. eatPlot::plot_lineplot)\n„…“\n\nAusschlaggebend dafür, ob Handlungsbedarf besteht, ist nicht die schiere Menge der Argumente, sondern wenn\n\ndie Argumente sich stark in ihrer Hierarchie unterscheiden\ndie Argumente viele Defaults haben"
  },
  {
    "objectID": "docs/discussions/code_conventions.html#konventionen-zum-schreiben-von-funktionen",
    "href": "docs/discussions/code_conventions.html#konventionen-zum-schreiben-von-funktionen",
    "title": "Code-Konventionen",
    "section": "Konventionen zum Schreiben von Funktionen",
    "text": "Konventionen zum Schreiben von Funktionen\n\nIn R-Paketen sollte es pro exportierter Funktion ein eigenes Skript geben.\nEine Funktion sollte genau eine Sache tun, die aus dem Namen der Funktion hervorgeht, und davon Gebrauch machen, einzelne Aufgaben in andere (Hilfs-) Funktionen auszulagern (vgl. Umfang von Code-Abschnitten)\n\nEine Ausnahme sind wrapper-Funktionen, die jedoch nichts weiter tun sollten, als die anderen Funktionen aufzurufen.\nHilfsfunktionen werden im Skript der Funktion platziert, in dem sie verwendet werden.\nFalls Hilfsfunktionen von mehreren Haupt-/exportierten Funktionen verwendet werden, werden sie in utils.R verschoben. Diese Datei gibt es nur einmal pro Paket.\nFalls der Umfang von utils.R zu stark anwächst, können Hilfsfunktionen gruppiert in separate Dateien geschoben werden.\n\nFunktionen sollten entweder keine side effects haben, oder ausschließlich side effects bewirken.\nreturn() oder kein return() bleibt den Codenden überlassen\n\nEs gibt Argumente, die dafür sprechen, konsequent am Ende der Funktion return() zu setzen (Eindeutigkeit, Nachvollziehbarkeit, Suchbarkeit) - aber auch dagegen.\nKriterium: Es sollte aus der Funktion heraus klar werden, was ausgegeben wird.\n\nEinrückungen/Indentation: Die Wahl zwischen styleR oder dem RStudio Default ist den Codenden überlassen.\nKommentare sollten a) möglichst gar nicht notwendig sein (weil der Code verständlich geschrieben ist) und b) das Warum und nicht das Was von Zeilen erklären.\nif-statements, loops und Funktionsdefinitionen (z.B. in lapply()) sollten stets und auch dann umgebrochen werden, wenn sie nur einen Befehl enthalten, d.h. die Zeile endet mit {, gefolgt von einem Zeilenumbruch."
  },
  {
    "objectID": "docs/discussions/code_conventions.html#benennungskonventionen-1",
    "href": "docs/discussions/code_conventions.html#benennungskonventionen-1",
    "title": "Code-Konventionen",
    "section": "Benennungskonventionen",
    "text": "Benennungskonventionen\n\nBei längeren Objektnamen sollten Punkte vermieden werden und entweder CamelCases oder snake_cases genutzt werden. Das aber jeweils konsistent innerhalb von Paketen.\nEs sollten eher sprechende Namen als möglichst kurze Namen verwendet werden.\nFunktionsnamen sollten aus Verben bestehen.\nObjektnamen (die keine Funktionen sind) sollten Substantive sein.\nDopplungen mit existierenden R-Objekten sollten vermieden werden.\nBei der Objekt-Modifikation sollten Objekte nicht überschreiben werden, wenn sie sich substanziell ändern.\nEinige häufige Argumentnamen: dat, path/file/filePath/filename, dir/folder, … –&gt; nächstes Mal besprechen\nBei der Argumentreihenfolge sollte die Pipebarkeit und Output-Steuerung beachtet werden."
  },
  {
    "objectID": "docs/discussions/code_conventions.html#konventionen-für-pakete",
    "href": "docs/discussions/code_conventions.html#konventionen-für-pakete",
    "title": "Code-Konventionen",
    "section": "Konventionen für Pakete",
    "text": "Konventionen für Pakete\n\nRigoroses Testen\n\nRigoroses Testen kann helfen, bei Ergänzung oder Löschung von Funktionsargumenten den Überblick zu behalten.\nUmsetzung mit testthat\nEs wird eine Coverage &gt; 90% angestrebt\n\nDie Anzahl von Dependencies sollte gering gehalten werden.\n\npkgnet kann genutzt werden, um die Dependencies innerhalb eines Pakets zu visualisieren.\nInsbesondere sollten “teure” Dependencies, die ihrerseits viele Dependencies aufrufen, vermieden werden.\nGgf. sollten Funktionen selbst (nach-) gebaut werden."
  },
  {
    "objectID": "docs/discussions/code_conventions.html#offen-besprechung-am-6.12.-oder-13.12.",
    "href": "docs/discussions/code_conventions.html#offen-besprechung-am-6.12.-oder-13.12.",
    "title": "Code-Konventionen",
    "section": "Offen –> Besprechung am 6.12. oder 13.12.",
    "text": "Offen –&gt; Besprechung am 6.12. oder 13.12.\n\nKristophs Konventionen zur Benennung von Objekten („df_“, „pt_“, …)\nScope von Paketen\nCode Review (auf Basis von https://iqb-research.github.io/IQB-Methods/docs/discussions/code_conventions.html)\ncommit-messages\nBenennung von feature branches"
  },
  {
    "objectID": "docs/discussions/code_conventions.html#footnotes",
    "href": "docs/discussions/code_conventions.html#footnotes",
    "title": "Code-Konventionen",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Swipe on Unsplash.↩︎"
  },
  {
    "objectID": "docs/git/copilot/copilot.html",
    "href": "docs/git/copilot/copilot.html",
    "title": "GitHub Copilot in R-Studio",
    "section": "",
    "text": "GitHub Copilot is an AI pair programmer that offers autocomplete-style suggestions as you code. It is possible to integrate GitHub Copilot into R-Studio to speed up annoying coding tasks and get suggestions for code snippets.\n1"
  },
  {
    "objectID": "docs/git/copilot/copilot.html#setup",
    "href": "docs/git/copilot/copilot.html#setup",
    "title": "GitHub Copilot in R-Studio",
    "section": "Setup",
    "text": "Setup\nTo make the Copilot available in RStudio, you either need to have a subscription to GitHub Copilot, or (recommended) a GitHub Education account. It is free for students and faculty members. To get GitHub Education, you might need to upload a certificate showing that you are either a student, or affiliated with an university. For IQB-Members, it might be enough to upload a confirmation of your employment as researcher at the IQB, which you could request at IQB-Personal.\nAfter obtaining some sort of confirmation, you can follow this guide or this guide to connect GitHub Copilot with RStudio."
  },
  {
    "objectID": "docs/git/copilot/copilot.html#usage",
    "href": "docs/git/copilot/copilot.html#usage",
    "title": "GitHub Copilot in R-Studio",
    "section": "Usage",
    "text": "Usage\nAfter installation, Copilot will make code suggestions, which you can accept by pressing Tab. Enter/Return will ignore the suggestion. If you want to give Copilot some additional instructions, you can just write them into a comment over the line you want the code suggestions in:\n\nGenerally, the suggestions work best for smaller, compartimentalized problems."
  },
  {
    "objectID": "docs/git/copilot/copilot.html#footnotes",
    "href": "docs/git/copilot/copilot.html#footnotes",
    "title": "GitHub Copilot in R-Studio",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by NASA on Unsplash.↩︎"
  },
  {
    "objectID": "docs/R_tutorials/R_ws2.html",
    "href": "docs/R_tutorials/R_ws2.html",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "",
    "text": "1"
  },
  {
    "objectID": "docs/R_tutorials/R_ws2.html#zusammenführen-von-data.frames-merging",
    "href": "docs/R_tutorials/R_ws2.html#zusammenführen-von-data.frames-merging",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "1.1 Zusammenführen von data.frames (merging)",
    "text": "1.1 Zusammenführen von data.frames (merging)\nNehmen wir an, wir hätten nun einen weiteren data.frame, der die Nachnamen einiger Studienteilnehmer*innen enthält:\n\ndaten2 &lt;- data.frame(\n    ID = c(43678, 88475, 88766, 89045),\n    nachname = c(\"Tegemann\", \"Laffont\", \"Brandner\",\n                 \"Schreiner\"), stringsAsFactors = FALSE)\ndaten2\n\n     ID  nachname\n1 43678  Tegemann\n2 88475   Laffont\n3 88766  Brandner\n4 89045 Schreiner\n\n\n…und möchten diesen nun mit unseren Daten zusammenführen, dann geht das sehr flexibel mit der Funktion merge(). merge() verknüpft die Datensätze automatisch über Spalten in den beiden Datensätzen, die gleich benannt sind, in unserem Beispiel die Spalte ID:\n\ndat &lt;- merge(daten, daten2, all=TRUE)\ndat\n\n     ID    name geschlecht treatment bdi.wert  nachname\n1 43678  Stefan          m         1    13.00  Tegemann\n2 67743    Eike          m         1     9.95      &lt;NA&gt;\n3 69781 Annette          w         1     9.85      &lt;NA&gt;\n4 88475 Sylvain          m         1    11.75   Laffont\n5 88766  Marina          w         0    10.15  Brandner\n6 89045    Onno          m         0    12.50 Schreiner\n\n\nSind die Spalten mit den Schlüsselvariablen nicht gleich benannt kann man im by.x-Argument spezifizieren, wie die Variable im ersten Datensatz heißt und im by.y-Argument, wie sie im zweiten Datensatz heißt. Heißen mehrere Variablen in beiden Datensätzen gleich und man möchte nur eine dieser gleichnamigen Variablen zur Verknüpfung verwenden, spezifiziert man diese im by-Argument:\n\ndat &lt;- merge(daten, daten2, by=\"ID\", all=TRUE)\ndat\n\n     ID    name geschlecht treatment bdi.wert  nachname\n1 43678  Stefan          m         1    13.00  Tegemann\n2 67743    Eike          m         1     9.95      &lt;NA&gt;\n3 69781 Annette          w         1     9.85      &lt;NA&gt;\n4 88475 Sylvain          m         1    11.75   Laffont\n5 88766  Marina          w         0    10.15  Brandner\n6 89045    Onno          m         0    12.50 Schreiner\n\n\nWenn man zwei Datensätze untereinander schreiben möchte, müssen sie dieselbe Spaltenausdehnung haben:\n\nrbind(daten2, daten2)\n\n     ID  nachname\n1 43678  Tegemann\n2 88475   Laffont\n3 88766  Brandner\n4 89045 Schreiner\n5 43678  Tegemann\n6 88475   Laffont\n7 88766  Brandner\n8 89045 Schreiner\n\n\n…und wenn man zwei Datensätze nebeneinander schreiben möchte, müssen sie dieselbe Zeilenausdehnung haben:\n\ncbind(daten2, daten2)\n\n     ID  nachname    ID  nachname\n1 43678  Tegemann 43678  Tegemann\n2 88475   Laffont 88475   Laffont\n3 88766  Brandner 88766  Brandner\n4 89045 Schreiner 89045 Schreiner\n\n\nMöchte man viele Datensätze derselben Ausdehnung nebeneinander oder untereinander in einen data.frameschreiben, kann man die Funktion do.call() benutzen, die analog zu hier im Beispiel mit cbind() auch mit rbind() funktioniert:\n\ndo.call(\"cbind\", list(daten2, daten2, daten2, daten2))\n\n     ID  nachname    ID  nachname    ID  nachname    ID  nachname\n1 43678  Tegemann 43678  Tegemann 43678  Tegemann 43678  Tegemann\n2 88475   Laffont 88475   Laffont 88475   Laffont 88475   Laffont\n3 88766  Brandner 88766  Brandner 88766  Brandner 88766  Brandner\n4 89045 Schreiner 89045 Schreiner 89045 Schreiner 89045 Schreiner\n\n\nZum weiteren Umgang mit dem Listenformat list siehe Kapitel 2, weiter unten."
  },
  {
    "objectID": "docs/R_tutorials/R_ws2.html#navigation-in-data.frames-subsetting",
    "href": "docs/R_tutorials/R_ws2.html#navigation-in-data.frames-subsetting",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "1.2 Navigation in data.frames (subsetting)",
    "text": "1.2 Navigation in data.frames (subsetting)\nÄhnlich wie in Vektoren kann man in data.frames über eckige Klammern einzelne Elemente anzeigen lassen oder verändern. Da data.frames zwei Dimensionen haben (Vektoren haben nur eine), muss man hier das Element mit [Zeile, Spalte] auswählen, also beispielsweise\n\ndat[4,2]\n\n[1] \"Sylvain\"\n\n\nAlternativ kann man mit dem Dollar-Zeichen eine Variable ansteuern:\n\ndat[4,]$name\n\n[1] \"Sylvain\"\n\n\nOder man kann den Variablennamen (mit hochgestellten Anführungszeichen) verwenden:\n\ndat[4,\"name\"]\n\n[1] \"Sylvain\"\n\n\nDie komplette “name”-Spalte gibt man aus, indem man die Zeilenbezeichnung weglässt oder alle Zeilen explizit auswählt:\n\ndat$name\n\n[1] \"Stefan\"  \"Eike\"    \"Annette\" \"Sylvain\" \"Marina\"  \"Onno\"   \n\ndat[,\"name\"]\n\n[1] \"Stefan\"  \"Eike\"    \"Annette\" \"Sylvain\" \"Marina\"  \"Onno\"   \n\ndat[1:6,\"name\"]\n\n[1] \"Stefan\"  \"Eike\"    \"Annette\" \"Sylvain\" \"Marina\"  \"Onno\"   \n\n\nAuch die Reihenfolge zu variieren, ist möglich:\n\ndat[6:1,\"name\"]\n\n[1] \"Onno\"    \"Marina\"  \"Sylvain\" \"Annette\" \"Eike\"    \"Stefan\" \n\n\nUm sich nur ausgewählte Spalten in selbst definierter Reihenfolge des Datensatzes anzusehen bzw. in einem neuen Objekt zu speichern:\n\ndat2 &lt;- dat[,c(\"name\", \"nachname\", \"bdi.wert\", \"treatment\")]\ndat2\n\n     name  nachname bdi.wert treatment\n1  Stefan  Tegemann    13.00         1\n2    Eike      &lt;NA&gt;     9.95         1\n3 Annette      &lt;NA&gt;     9.85         1\n4 Sylvain   Laffont    11.75         1\n5  Marina  Brandner    10.15         0\n6    Onno Schreiner    12.50         0\n\n\nWenn man sich nur bestimmte Subgruppen anschauen möchte:\n\nAlle Mitglieder der Kontrollgruppe:\n\n\ndat2[dat2$treatment == 0,]\n\n    name  nachname bdi.wert treatment\n5 Marina  Brandner    10.15         0\n6   Onno Schreiner    12.50         0\n\n\n\nAlle mit einem BDI-Wert größer als 10:\n\n\ndat2[dat2$bdi.wert &gt; 10,]\n\n     name  nachname bdi.wert treatment\n1  Stefan  Tegemann    13.00         1\n4 Sylvain   Laffont    11.75         1\n5  Marina  Brandner    10.15         0\n6    Onno Schreiner    12.50         0\n\n\n\nAlle in der Treatment-Gruppe und einem BDI-Wert größer als 10:\n\n\ndat2[dat2$treatment == 1 & dat2$bdi.wert &gt; 10,]\n\n     name nachname bdi.wert treatment\n1  Stefan Tegemann    13.00         1\n4 Sylvain  Laffont    11.75         1\n\n\n\nAlle in der Treatment-Gruppe oder einem BDI-Wert größer als 10:\n\n\ndat2[dat2$treatment == 1 | dat2$bdi.wert &gt; 10,]\n\n     name  nachname bdi.wert treatment\n1  Stefan  Tegemann    13.00         1\n2    Eike      &lt;NA&gt;     9.95         1\n3 Annette      &lt;NA&gt;     9.85         1\n4 Sylvain   Laffont    11.75         1\n5  Marina  Brandner    10.15         0\n6    Onno Schreiner    12.50         0\n\n\n\nAlle, deren Vorname mit “S” beginnt:\n\n\ndat2[grep(\"^S\", dat2$name),]\n\n     name nachname bdi.wert treatment\n1  Stefan Tegemann    13.00         1\n4 Sylvain  Laffont    11.75         1\n\n\n\nAlle, für die kein Nachname hinterlegt ist:\n\n\ndat2[is.na(dat2$nachname),]\n\n     name nachname bdi.wert treatment\n2    Eike     &lt;NA&gt;     9.95         1\n3 Annette     &lt;NA&gt;     9.85         1\n\n\n\nDer Datensatz ohne Personen, für die kein Nachname hinterlegt ist:\n\n\ndat2[!is.na(dat2$nachname),]\n\n     name  nachname bdi.wert treatment\n1  Stefan  Tegemann    13.00         1\n4 Sylvain   Laffont    11.75         1\n5  Marina  Brandner    10.15         0\n6    Onno Schreiner    12.50         0\n\n\noder\n\ndat2[-which(is.na(dat2$nachname)),]\n\n     name  nachname bdi.wert treatment\n1  Stefan  Tegemann    13.00         1\n4 Sylvain   Laffont    11.75         1\n5  Marina  Brandner    10.15         0\n6    Onno Schreiner    12.50         0"
  },
  {
    "objectID": "docs/R_tutorials/R_ws2.html#rekodieren-von-variablen-in-data.frames",
    "href": "docs/R_tutorials/R_ws2.html#rekodieren-von-variablen-in-data.frames",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "1.3 Rekodieren von Variablen in data.frames",
    "text": "1.3 Rekodieren von Variablen in data.frames\nWenn man bestimmte Werte im data.frame ersetzen möchte oder Variablen in andere Variablen umkodieren möchte, hat man verschiedene Möglichkeiten.\n\nAlle Werte im Datensatz ersetzen:\n\n\n\n\nz.B. alle fehlenden Werte durch einen bestimmten Missingcode ersetzen:\n\n\ndat2[is.na(dat2)] &lt;- \"-97\"\ndat2\n\n     name  nachname bdi.wert treatment\n1  Stefan  Tegemann    13.00         1\n2    Eike       -97     9.95         1\n3 Annette       -97     9.85         1\n4 Sylvain   Laffont    11.75         1\n5  Marina  Brandner    10.15         0\n6    Onno Schreiner    12.50         0\n\n\n\noder einen bestimmen Wert durch andere Werte oder Missings ersetzen:\n\n\ndat2[dat2==\"-97\"] &lt;- NA\ndat2\n\n     name  nachname bdi.wert treatment\n1  Stefan  Tegemann    13.00         1\n2    Eike      &lt;NA&gt;     9.95         1\n3 Annette      &lt;NA&gt;     9.85         1\n4 Sylvain   Laffont    11.75         1\n5  Marina  Brandner    10.15         0\n6    Onno Schreiner    12.50         0\n\n\n\nNeue Variablen in Abhängigkeit von anderen Variablen bilden\n\nMit der Funktion ifelse formuliert man zunächst eine Bedingung (hier alle, die einen BDI kleiner als 10 haben und gleichzeitig in der Treatment-Gruppe sind), danach gibt man durch ein Komma abgetrennt an, welche Werte in der neuen Variable stehen sollen (hier \"Treatment war wirksam\"). Durch ein weiteres Komma abgetrennt kann dann angegeben werden, was passieren soll, wenn die Bedingung nicht zutrifft. Dabei kann dort sogar ein weiteres ifelse-Statement eingefügt werden, wie hier im Beispiel, das nach genau denselben Regeln aufgebaut ist.\n\ndat2$neueVar &lt;- ifelse(test=dat2$bdi.wert &lt; 10 & dat2$treatment==1,\n                       yes=\"Treatment war wirksam\",  \n                       no = ifelse(test=dat2$bdi.wert &gt;= 10 & dat2$treatment==1,   \n                                   yes=\"Treatment nicht wirksam\",\n                                   no=\"kein Treatment\"))\ndat2\n\n     name  nachname bdi.wert treatment                 neueVar\n1  Stefan  Tegemann    13.00         1 Treatment nicht wirksam\n2    Eike      &lt;NA&gt;     9.95         1   Treatment war wirksam\n3 Annette      &lt;NA&gt;     9.85         1   Treatment war wirksam\n4 Sylvain   Laffont    11.75         1 Treatment nicht wirksam\n5  Marina  Brandner    10.15         0          kein Treatment\n6    Onno Schreiner    12.50         0          kein Treatment\n\n\nAuch kann die Funktion recode aus dem Paket car verwendet werden. Hier werden die Werte oder Wertebereiche einer Variablen umkodiert. Der Wertebereich des niedrigsten aufgetretenen Wertes bis zum Wert 10 entspricht dem hier benutzten Statement lo:10. Wie man mit allen nicht explizit erwähnten Werten verfahren möchte, kann mit dem else-Argument festlegen.\n\nlibrary(car)\n\n\ndat2$neueVar &lt;- car::recode(dat2$bdi.wert, \"lo:10='leichte Depression'; else='schwere Depression'\")\ndat2\n\n     name  nachname bdi.wert treatment            neueVar\n1  Stefan  Tegemann    13.00         1 schwere Depression\n2    Eike      &lt;NA&gt;     9.95         1 leichte Depression\n3 Annette      &lt;NA&gt;     9.85         1 leichte Depression\n4 Sylvain   Laffont    11.75         1 schwere Depression\n5  Marina  Brandner    10.15         0 schwere Depression\n6    Onno Schreiner    12.50         0 schwere Depression"
  },
  {
    "objectID": "docs/R_tutorials/R_ws2.html#umstrukturieren-von-data.frames",
    "href": "docs/R_tutorials/R_ws2.html#umstrukturieren-von-data.frames",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "1.4 Umstrukturieren von data.frames",
    "text": "1.4 Umstrukturieren von data.frames\nUnser Datensatz befindet sich im sogenannten Wide-Format. Für manche Anwendungen kann es sinnvoll sein, den Datensatz in das sogenannte Long-Format zu bringen, in dem alle Werte der Personen in einer einzigen Variablen untereinander stehen. Früher benutzte man das Paket reshape2, um einen Datensatz ins Long-Format zu bringen, was auch jetzt noch immer unkompliziert möglich ist:\n\nlibrary(reshape2)\n\n\ndatl &lt;- reshape2::melt(dat, id.vars=\"ID\")\ndatl\n\n      ID   variable     value\n1  43678       name    Stefan\n2  67743       name      Eike\n3  69781       name   Annette\n4  88475       name   Sylvain\n5  88766       name    Marina\n6  89045       name      Onno\n7  43678 geschlecht         m\n8  67743 geschlecht         m\n9  69781 geschlecht         w\n10 88475 geschlecht         m\n11 88766 geschlecht         w\n12 89045 geschlecht         m\n13 43678  treatment         1\n14 67743  treatment         1\n15 69781  treatment         1\n16 88475  treatment         1\n17 88766  treatment         0\n18 89045  treatment         0\n19 43678   bdi.wert        13\n20 67743   bdi.wert      9.95\n21 69781   bdi.wert      9.85\n22 88475   bdi.wert     11.75\n23 88766   bdi.wert     10.15\n24 89045   bdi.wert      12.5\n25 43678   nachname  Tegemann\n26 67743   nachname      &lt;NA&gt;\n27 69781   nachname      &lt;NA&gt;\n28 88475   nachname   Laffont\n29 88766   nachname  Brandner\n30 89045   nachname Schreiner\n\n\nund mit dcast() formte man den Datensatz wieder zurück:\n\nreshape2::dcast(datl, ID ~ variable)\n\n     ID    name geschlecht treatment bdi.wert  nachname\n1 43678  Stefan          m         1       13  Tegemann\n2 67743    Eike          m         1     9.95      &lt;NA&gt;\n3 69781 Annette          w         1     9.85      &lt;NA&gt;\n4 88475 Sylvain          m         1    11.75   Laffont\n5 88766  Marina          w         0    10.15  Brandner\n6 89045    Onno          m         0     12.5 Schreiner\n\n\nIn jüngerer Zeit wurden dazu recht effiziente Funktionen entwickelt, die im Paket tidyr zu finden sind. Hier wird nur rudimentär in die Benutzung dieser Funktionen eingeführt – der/die interessierte Leser/in mag sich in folgende Seite vertiefen: http://tidyr.tidyverse.org/articles/pivot.html Hierbei ist zu beachten, dass bei Benutzung des Pakets tidyr die data.frames zu anderen Objekten werden, nämlich tibbles (die aber problemlos mit der Funktion as.data.frame() wieder in data.frames zurücktransformiert werden können. Darüber hinaus weicht die zu verwendende Syntax hier deutlich von der bisher gezeigten basalen R-Syntax ab. Eine besondere Rolle spielt hier der sogenannte Pipe-Operator %&gt;%, über den hier http://www.rdocumentation.org/packages/magrittr/versions/1.0.1/topics/%25%3E%25 oder an anderer Stelle weitergelesen werden kann.\n\nlibrary(tidyr)\n\nUmstrukturierung unserer Daten ins Long-Format:\n\ndat %&gt;% pivot_longer(\n  cols=name:nachname,\n  names_to = \"variable\",\n  values_to = \"value\"\n)\n\noder, äquivalent dazu, mit:\n\npivot_longer(dat, cols=name:nachname, names_to = \"variable\", values_to = \"value\")\n\n# A tibble: 30 × 3\n      ID variable   value   \n   &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;   \n 1 43678 name       Stefan  \n 2 43678 geschlecht m       \n 3 43678 treatment  1       \n 4 43678 bdi.wert   13      \n 5 43678 nachname   Tegemann\n 6 67743 name       Eike    \n 7 67743 geschlecht m       \n 8 67743 treatment  1       \n 9 67743 bdi.wert   9.95    \n10 67743 nachname   &lt;NA&gt;    \n# ℹ 20 more rows\n\n\nund mit pivot_wider() kann man den Datensatz wieder zurück formen:\n\ndatl  %&gt;% pivot_wider(\n  names_from = variable, values_from = value\n)\n\noder genauso:\n\npivot_wider(datl, names_from = variable, values_from = value)\n\n# A tibble: 6 × 6\n     ID name    geschlecht treatment bdi.wert nachname \n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;    \n1 43678 Stefan  m          1         13       Tegemann \n2 67743 Eike    m          1         9.95     &lt;NA&gt;     \n3 69781 Annette w          1         9.85     &lt;NA&gt;     \n4 88475 Sylvain m          1         11.75    Laffont  \n5 88766 Marina  w          0         10.15    Brandner \n6 89045 Onno    m          0         12.5     Schreiner"
  },
  {
    "objectID": "docs/R_tutorials/R_ws2.html#subsetting-in-listen",
    "href": "docs/R_tutorials/R_ws2.html#subsetting-in-listen",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "2.1 Subsetting in Listen",
    "text": "2.1 Subsetting in Listen\nAuch bei Listen gibt es wieder zwei Möglichkeiten, wie man auf die Elemente zugreifen kann:\n\nÜber den Index, z.B. wenn man im dritten Listenelement weitere Unterelemente ansteuern möchte, wie hier die zweite Spalte und die fünfte Zeile:\n\n\nL1[[3]][5,2]\n\n[1] \"Brandner\"\n\n\n\nÜber den Namen in Anführungszeichen oder mit vorangestelltem Dollar-Zeichen:\n\n\nL1[[\"Gesamt\"]][5,2]\n\n[1] \"Brandner\"\n\nL1[[\"Gesamt\"]][5,\"nachname\"]\n\n[1] \"Brandner\"\n\nL1$Gesamt$nachname[5]\n\n[1] \"Brandner\"\n\n\nEine Teilliste der Liste kann aufgerufen werden, indem die einzelnen Komponenten indiziert werden:\n\nL1[c(1,2)]\n\n$Werte\n[1] 12.50 13.00 11.75  9.85 10.15  9.95\n\n$Nachnamen\n[1] \"Tegemann\"  \"Laffont\"   \"Brandner\"  \"Schreiner\""
  },
  {
    "objectID": "docs/R_tutorials/R_ws2.html#merging-von-listen",
    "href": "docs/R_tutorials/R_ws2.html#merging-von-listen",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "2.2 Merging von Listen",
    "text": "2.2 Merging von Listen\nListen können kombiniert werden, indem sie mit c() verbunden werden:\n\nL2 &lt;- c(L1[2], L1[1])\nL2\n\n$Nachnamen\n[1] \"Tegemann\"  \"Laffont\"   \"Brandner\"  \"Schreiner\"\n\n$Werte\n[1] 12.50 13.00 11.75  9.85 10.15  9.95\n\n\nWeitere Komponenten können über Neuindizierung oder Namen hinzugefügt werden:\n\nL2[[3]] &lt;- TRUE\nL2$nochwas &lt;- FALSE\nL2[[\"undnochwas\"]] &lt;- data.frame(wahr=c(FALSE,TRUE,TRUE),falsch=c(TRUE,TRUE,FALSE))\nL2\n\n$Nachnamen\n[1] \"Tegemann\"  \"Laffont\"   \"Brandner\"  \"Schreiner\"\n\n$Werte\n[1] 12.50 13.00 11.75  9.85 10.15  9.95\n\n[[3]]\n[1] TRUE\n\n$nochwas\n[1] FALSE\n\n$undnochwas\n   wahr falsch\n1 FALSE   TRUE\n2  TRUE   TRUE\n3  TRUE  FALSE\n\n\nSollen Komponenten entfernt werden, kann man wieder den Minus-Operator benutzen:\n\nL2 &lt;- L2[-c(3,4)]\nL2\n\n$Nachnamen\n[1] \"Tegemann\"  \"Laffont\"   \"Brandner\"  \"Schreiner\"\n\n$Werte\n[1] 12.50 13.00 11.75  9.85 10.15  9.95\n\n$undnochwas\n   wahr falsch\n1 FALSE   TRUE\n2  TRUE   TRUE\n3  TRUE  FALSE"
  },
  {
    "objectID": "docs/R_tutorials/R_ws2.html#aufheben-der-listenstruktur",
    "href": "docs/R_tutorials/R_ws2.html#aufheben-der-listenstruktur",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "2.3 Aufheben der Listenstruktur",
    "text": "2.3 Aufheben der Listenstruktur\nMöchte man keine Liste mehr haben, hilft die Funktion unlist() weiter, die alle Elemente der Liste nacheinander in einen benannten Vektor schreibt, dessen Namen man aber auch entfernen kann:\n\n(L3 &lt;- unlist(L2))\n\n        Nachnamen1         Nachnamen2         Nachnamen3         Nachnamen4 \n        \"Tegemann\"          \"Laffont\"         \"Brandner\"        \"Schreiner\" \n            Werte1             Werte2             Werte3             Werte4 \n            \"12.5\"               \"13\"            \"11.75\"             \"9.85\" \n            Werte5             Werte6   undnochwas.wahr1   undnochwas.wahr2 \n           \"10.15\"             \"9.95\"            \"FALSE\"             \"TRUE\" \n  undnochwas.wahr3 undnochwas.falsch1 undnochwas.falsch2 undnochwas.falsch3 \n            \"TRUE\"             \"TRUE\"             \"TRUE\"            \"FALSE\" \n\nunname(unlist(L2))\n\n [1] \"Tegemann\"  \"Laffont\"   \"Brandner\"  \"Schreiner\" \"12.5\"      \"13\"       \n [7] \"11.75\"     \"9.85\"      \"10.15\"     \"9.95\"      \"FALSE\"     \"TRUE\"     \n[13] \"TRUE\"      \"TRUE\"      \"TRUE\"      \"FALSE\""
  },
  {
    "objectID": "docs/R_tutorials/R_ws2.html#balkendiagramme",
    "href": "docs/R_tutorials/R_ws2.html#balkendiagramme",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "1.1 Balkendiagramme",
    "text": "1.1 Balkendiagramme\nZ.B. Verteilung des BDI-Werts:\n\nbarplot(bdi.wert ~ name, data=dat2)\n\n\n\n\n\n\n\n\nFür einfache Häufigkeitsverteilungen:\n\nhist(dat2$bdi.wert)\n\n\n\n\n\n\n\n\nBoxplots:\n\nboxplot(bdi.wert ~ treatment, data=dat2)"
  },
  {
    "objectID": "docs/R_tutorials/R_ws2.html#die-plot-funktion-und-mehrere-grafiken-neben--oder-untereinander",
    "href": "docs/R_tutorials/R_ws2.html#die-plot-funktion-und-mehrere-grafiken-neben--oder-untereinander",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "1.2 Die plot()-Funktion und mehrere Grafiken neben- oder untereinander",
    "text": "1.2 Die plot()-Funktion und mehrere Grafiken neben- oder untereinander\nMöchte man in einem Fenster mehrere Grafiken unter- oder nebeneinander darstellen, kann man sich des Parameters mfrow der par()-Funktion bedienen. Die erste Zahl gibt an, in wie vielen Grafiken die Zeilen untereinander dargestellt werden sollen und die zweite Zahl, in wie vielen Spalten nebeneinander. Sollen die Daten zunächst geplottet werden und daneben deren Verteilung (im Beispiel nur bedingt sinnvoll), sieht das so aus:\n\npar(mfrow=c(1,2))\nplot(dat2$bdi.wert)\nplot(density(dat2$bdi.wert),main=\"Eine Verteilung\")"
  },
  {
    "objectID": "docs/R_tutorials/R_ws2.html#das-paket-ggplot2",
    "href": "docs/R_tutorials/R_ws2.html#das-paket-ggplot2",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "1.3 Das Paket ggplot2",
    "text": "1.3 Das Paket ggplot2\nEin mächtiges Paket zur Erstellung von Grafiken ist ggplot2, zu dem z.B. unter diesem Link eine gute Einführung gegeben wird: http://methodenlehre.github.io/einfuehrung-in-R/grafiken-mit-ggplot2.html"
  },
  {
    "objectID": "docs/R_tutorials/R_ws2.html#footnotes",
    "href": "docs/R_tutorials/R_ws2.html#footnotes",
    "title": "Data Frames, Listen und Grafiken in R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Van Tay Media on Unsplash.↩︎"
  },
  {
    "objectID": "docs/R_tutorials/R_ws3.html",
    "href": "docs/R_tutorials/R_ws3.html",
    "title": "Pakete(-Installation), Workspace, Daten laden und speichern in R",
    "section": "",
    "text": "1"
  },
  {
    "objectID": "docs/R_tutorials/R_ws3.html#csv",
    "href": "docs/R_tutorials/R_ws3.html#csv",
    "title": "Pakete(-Installation), Workspace, Daten laden und speichern in R",
    "section": ".csv",
    "text": ".csv\nBeim Speichern von comma seperated files (.csv) können die Funktionen write.csv() und write.csv2() verwendet werden, wobei letztere Funktion den deutschen Excel-Konventionen (“,” als Dezimaltrenner) entspricht.\n\n# Objekt speichern\nwrite.csv2(mtcars, \"Material_WSIII/mtcars.csv\")\n# Objekt laden\ndat &lt;- read.csv2(\"Material_WSIII/mtcars.csv\")\n# Objekt betrachten\nhead(dat)"
  },
  {
    "objectID": "docs/R_tutorials/R_ws3.html#xlsx-excel",
    "href": "docs/R_tutorials/R_ws3.html#xlsx-excel",
    "title": "Pakete(-Installation), Workspace, Daten laden und speichern in R",
    "section": ".xlsx (Excel)",
    "text": ".xlsx (Excel)\nZum Einlesen von Excel files empfiehlt sich die Funktion read_xlsx() aus dem Paket readxl. Achtung! Da das Paket standardmäßig einen tibble ausgibt, eine Spezialform von data.frames, empfiehlt sich die Umwandlung zu einem data.frame. Da das Paket leider kein Schreiben von Excel files unterstützt, empfiehlt sich hierfür die Funktion write_xlsx() aus dem Paket eatAnalysis.\n\n# Objekt speichern\neatAnalysis::write_xlsx(mtcars, \"Material_WSIII/mtcars.xlsx\", row.names = FALSE)\n# Objekt laden\ndat &lt;- readxl::read_xlsx(\"Material_WSIII/mtcars.xlsx\")\ndat &lt;- as.data.frame(dat)\nhead(dat)"
  },
  {
    "objectID": "docs/R_tutorials/R_ws3.html#sav-spss",
    "href": "docs/R_tutorials/R_ws3.html#sav-spss",
    "title": "Pakete(-Installation), Workspace, Daten laden und speichern in R",
    "section": ".sav (SPSS)",
    "text": ".sav (SPSS)\nZum Importieren von SPSS-Dateien bietet sich das Paket eatGADS an. Es ermöglicht das Einlesen von Daten in einem zwei-schrittigem Vorgehen. Zuerst werden die Daten eingelesen.\n\n# sav Datei einlesen\nspss &lt;- eatGADS::import_spss(\"Material_WSIII/example.sav\")\n\nDiese Datei enthält sämtliche Metadaten, die auch die originale spss-Datei beinhaltet (Variablen- und Wertelabel etc.). Diese können mithilfe von extractMeta abgefragt werden. Im Folgenden werden die Metadaten für die Variable \"PJgsep_a\" abgerufen:\n\n# sav Datei einlesen\neatGADS::extractMeta(spss, \"PJgsep_a\")\n\nUm Analysen in R durchzuführen, müssen die Daten aus diesem Objekt nun mithilfe der extractData()-Funktion extrahiert werden. Diese ermöglicht zum einen Missingcodes anzuwenden, zum anderen gelabelte Variablen entweder als numerische, character oder Faktor-Variablen auszugeben.\n\n# sav Datei einlesen\ndat &lt;- eatGADS::extractData(spss, convertLabel = \"character\", convertMiss = TRUE)\nhead(dat)"
  },
  {
    "objectID": "docs/R_tutorials/R_ws3.html#dta-stata",
    "href": "docs/R_tutorials/R_ws3.html#dta-stata",
    "title": "Pakete(-Installation), Workspace, Daten laden und speichern in R",
    "section": ".dta (Stata)",
    "text": ".dta (Stata)\nStata-Datein können mithilfe des Paktes haven sowohl gelesen als auch geschrieben werden.\n\n# Objekt speichern\nhaven::write_dta(mtcars, \"Material_WSIII/mtcars.dta\")\n# Objekt laden\ndat &lt;- haven::read_dta(\"Material_WSIII/mtcars.dta\")\ndat &lt;- as.data.frame(dat)\nhead(dat)"
  },
  {
    "objectID": "docs/R_tutorials/R_ws3.html#dat-mplus",
    "href": "docs/R_tutorials/R_ws3.html#dat-mplus",
    "title": "Pakete(-Installation), Workspace, Daten laden und speichern in R",
    "section": ".dat (Mplus)",
    "text": ".dat (Mplus)\nHäufig möchte man in Vorbereitung von Analysen mithilfe von Mplus Daten in R aufbereiten. Das Paket MplusAutomation beinhaltet die Funktion prepareMplusData(), die das schreiben von .dat Datein ermöglicht und zusätzlich einen Rohling für die Mplus-Analysesyntax erstellt. Außerdem beinhaltet das Paket zahlreiche Möglichkeiten verschiedene Analysen zu automatisieren.\n\n# Objekt speichern\nMplusAutomation::prepareMplusData(mtcars, filename = \"Material_WSIII/mtcars.dat\")"
  },
  {
    "objectID": "docs/R_tutorials/R_ws3.html#footnotes",
    "href": "docs/R_tutorials/R_ws3.html#footnotes",
    "title": "Pakete(-Installation), Workspace, Daten laden und speichern in R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Van Tay Media on Unsplash.↩︎"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#agenda",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#agenda",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Agenda",
    "text": "Agenda\n\neatGADS - Basics\n\nHintergrund\nGrundlegendes\nÜbersicht Funktionalität\n\neatGADS im BT-Kontext\n\nAufbereitungsziel\nHäufig verwendete Funktionen\nBest Practices"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#eatgads---scope",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#eatgads---scope",
    "title": "eatGADS - Datenaufbereitung",
    "section": "eatGADS - Scope",
    "text": "eatGADS - Scope\n\nDatenbankerstellung\nDatenbanknutzung"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#eatgads---scope-1",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#eatgads---scope-1",
    "title": "eatGADS - Datenaufbereitung",
    "section": "eatGADS - Scope",
    "text": "eatGADS - Scope\n\nDatenbankerstellung\nDatenbanknutzung\n(teil-automatisierte) Datenaufbereitung"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#ursprüngliche-idee",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#ursprüngliche-idee",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Ursprüngliche Idee",
    "text": "Ursprüngliche Idee\nR statt SPSS in der Datenaufbereitung\n\nkeine proprietäre Software\nbessere Automatisierungsmöglichkeiten\nbessere Integration mit dem eat-Versum"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#eatgads",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#eatgads",
    "title": "eatGADS - Datenaufbereitung",
    "section": "eatGADS",
    "text": "eatGADS\n\n\n# Stabile Version\ninstall.packages(\"eatGADS\")\n\n# Development Version\nremotes::install_github(\"beckerbenj/eatGADS\")"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#ressourcen",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#ressourcen",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Ressourcen",
    "text": "Ressourcen\n\nVignette: Comprehensive Data Cleaning Guide (BT-Perspektive)\nVignette: FDZ Data Cleaning\nkomplette Funktionsübersicht"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#gadsdat-objekte",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#gadsdat-objekte",
    "title": "eatGADS - Datenaufbereitung",
    "section": "GADSdat-Objekte",
    "text": "GADSdat-Objekte\nListe bestehend aus\n\nrohen Daten (dat)\nund Meta-Daten (labels)"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#gadsdat-objekte-1",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#gadsdat-objekte-1",
    "title": "eatGADS - Datenaufbereitung",
    "section": "GADSdat-Objekte",
    "text": "GADSdat-Objekte\nListe bestehend aus\n\nrohen Daten (dat)\n\nnumerische Variablen\ncharacter Variablen (Zeichenfolgen)\n\nMeta-Daten (labels)\n\nvarName - Variablenname\nvarLabel - Variablenlabel\nformat - SPSS-Format\nvalue - numerischer Wert\nvalLabel - Wertelabel\nmissings - Missingtags (miss oder valid)"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#gadsdat-objekte-2",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#gadsdat-objekte-2",
    "title": "eatGADS - Datenaufbereitung",
    "section": "GADSdat-Objekte",
    "text": "GADSdat-Objekte\nDaten"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#gadsdat-objekte-3",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#gadsdat-objekte-3",
    "title": "eatGADS - Datenaufbereitung",
    "section": "GADSdat-Objekte",
    "text": "GADSdat-Objekte\nMeta-Daten"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#gadsdat-objekte-4",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#gadsdat-objekte-4",
    "title": "eatGADS - Datenaufbereitung",
    "section": "GADSdat-Objekte",
    "text": "GADSdat-Objekte\nImport und Export\n\n# Import von .sav/.dta files\npisa &lt;- import_spss(\"pisa.sav\")\npisa &lt;- import_stata(\"pisa.dat\")\n\n# Export von .sav/.dta files\nwrite_spss(pisa, filePath = \"pisa.sav\")\nwrite_stata(pisa, filePath = \"pisa.dat\")"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#variablennamen",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#variablennamen",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Variablennamen",
    "text": "Variablennamen\nAnzeigen von Variablennamen im Datensatz via namesGADS()\n\nnamesGADS(pisa)[1:10]\n\n [1] \"idstud\"    \"idschool\"  \"idclass\"   \"schtype\"   \"sameteach\" \"g8g9\"     \n [7] \"ganztag\"   \"classsize\" \"repeated\"  \"gender\""
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#meta-daten",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#meta-daten",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Meta-Daten",
    "text": "Meta-Daten\nExtraktion von Meta-Daten via extractMeta()\n\nextractMeta(pisa, vars = c(\"idstud\", \"schtype\"))\n\n  varName     varLabel format display_width labeled value\n2  idstud   Student-ID   F8.0            NA      no    NA\n5 schtype School track   F8.0            NA     yes     1\n6 schtype School track   F8.0            NA     yes     2\n7 schtype School track   F8.0            NA     yes     3\n                                   valLabel missings\n2                                      &lt;NA&gt;     &lt;NA&gt;\n5                Gymnasium (academic track)    valid\n6                                Realschule    valid\n7 schools with several courses of education    valid"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#meta-daten-1",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#meta-daten-1",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Meta-Daten",
    "text": "Meta-Daten\nÄnderung von Meta-Daten\n\n# Variablenname\npisa2 &lt;- changeVarNames(pisa, oldNames = \"idstud\",\n                         newNames = \"IDSTUD\")\n\n# Variablenlabel\npisa2 &lt;- changeVarLabels(pisa2, varName = \"schtype\",\n                         varLabel = \"Schulart\")\n\n# Wertelabel\npisa2 &lt;- changeValLabels(pisa2, varName = \"schtype\",\n                         value = 1, valLabel = \"Gymnasium\")\n\n# Missingtag\npisa2 &lt;- changeMissings(pisa2, varName = \"schtype\",\n                         value = -99, missings = \"miss\")"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#meta-daten-2",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#meta-daten-2",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Meta-Daten",
    "text": "Meta-Daten\n\nextractMeta(pisa2, vars = c(\"IDSTUD\", \"schtype\"))\n\n  varName   varLabel format display_width labeled value\n1  IDSTUD Student-ID   F8.0            NA      no    NA\n4 schtype   Schulart   F8.0            NA     yes   -99\n5 schtype   Schulart   F8.0            NA     yes     1\n6 schtype   Schulart   F8.0            NA     yes     2\n7 schtype   Schulart   F8.0            NA     yes     3\n                                   valLabel missings\n1                                      &lt;NA&gt;     &lt;NA&gt;\n4                                      &lt;NA&gt;     miss\n5                                 Gymnasium    valid\n6                                Realschule    valid\n7 schools with several courses of education    valid"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#daten",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#daten",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Daten",
    "text": "Daten\nÄnderung von Daten\n\n# Variable duplizieren\npisa3 &lt;- cloneVariable(pisa2, varName = \"schtype\",\n                       new_varName = \"schtype_dich\")\n\n# Rekodierung\npisa3 &lt;- recodeGADS(pisa3, varName = \"schtype_dich\",\n                    oldValues = c(1, 2, 3),\n                    newValues = c(1, 2, 2),\n                    existingMeta = \"drop\")\n\n# Anpassung Wertelabel\npisa3 &lt;- changeValLabels(pisa3, varName = \"schtype_dich\",\n                     value = 2, valLabel = \"Nicht-Gymnasium\")"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#daten-1",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#daten-1",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Daten",
    "text": "Daten\n\nextractMeta(pisa3, vars = \"schtype_dich\")\n\n         varName varLabel format display_width labeled value        valLabel\n467 schtype_dich Schulart   F8.0            NA     yes   -99            &lt;NA&gt;\n468 schtype_dich Schulart   F8.0            NA     yes     1       Gymnasium\n469 schtype_dich Schulart   F8.0            NA     yes     2 Nicht-Gymnasium\n    missings\n467     miss\n468    valid\n469    valid"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#übung",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#übung",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Übung",
    "text": "Übung\n\nLadet den Datensatz example_data.sav aus dem eatFDZ Paket (© Annegret Rucker).\n\n\nremotes::install_github(\"beckerbenj/eatFDZ\")\n\n\nsav_path &lt;- system.file(\"extdata\", \"example_data.sav\", package = \"eatFDZ\")\nexample_gads &lt;- import_spss(sav_path)\n\n\nInspiziert die Meta-Daten der Variable \"books\".\nVergebt sinnvolle Wertelabel und Missingtags, wo diese bisher fehlen.\nBildet eine neue, dichotome Schulvariable (\"school_dich\") mit 1 = \"nicht-Gymnasium\" und 2 = \"Gymnasium\"."
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#übersicht-funktionalität-i",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#übersicht-funktionalität-i",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Übersicht Funktionalität I",
    "text": "Übersicht Funktionalität I\nImport-Funktionen\n\nimport_spss() - Import von .sav\nimport_stata() - Import von .dta\nimport_DF() - Import von data.frames\nimport_RDS() - Import von .RDS Dateien\nimport_raw() - Direkt-Import von Rohdaten & Metadaten\n\nExport-Funktionen\n\nwrite_spss() - Export von .sav\nwrite_spss2() - Alternativer Export von .sav\nwrite_stata() - Export von .dta\nextractData2() - Extraktion von Datensätzen innerhalb R"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#übersicht-funktionalität-ii",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#übersicht-funktionalität-ii",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Übersicht Funktionalität II",
    "text": "Übersicht Funktionalität II\nMeta-Daten bearbeiten\n\ngetChangeMeta() - Extrahiert Änderungen in den Meta-Daten\napplyChangeMeta() - Wendet Änderungen in den Meta-Daten an\nchangeVarLabels() - Änderungen Variablenlabel\nchangeValLabels() - Änderungen Wertelabel\nchangeMissings() - Änderungen Missing-Tags\nchangeVarNames()- Änderungen Variablennamen\nchangeSPSSformat() - Änderungen SPSS-Format\nreuseMeta() - Wiederverwendung von Meta-Daten\nupdateMeta() - Aktualisiert Meta-Daten im Datensatz"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#übersicht-funktionalität-iii",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#übersicht-funktionalität-iii",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Übersicht Funktionalität III",
    "text": "Übersicht Funktionalität III\nGrundlegende Daten-Struktur bearbeiten\n\nextractVars() - Extraktion ausgewählter Variablen\nremoveVars() - Entfernen bestimmter Variablen\ncloneVar() - Kopiert eine Variable\nrelocateVariable() - Verschiebt eine Variable an eine neue Position\norderLike() - Anordnung aller Variablen\n…"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#übersicht-funktionalität-iv",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#übersicht-funktionalität-iv",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Übersicht Funktionalität IV",
    "text": "Übersicht Funktionalität IV\nSemi-automatisierte Funktionen\n\ncalculateScale() - Erstellen einer Skala\ncollapseMC_Text() - Rekodierung eines forced Choice Items mit Freitextmöglichkeit\ncollapseMultiMC_Text() - Rekodierung eines multiple Choice Items mit Freitextmöglichkeit\ncomposeVar() - Kombination unterschiedlicher Informationsquellen\nconvertCase() - Änderung Groß-/Kleinschreibung\ndummies2char()\nfac2dummies()\nmultiChar2fac()\n…"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#übung-1",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#übung-1",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Übung",
    "text": "Übung\n\nEntfernt die Variablen \"ID_name\" und \"info\" aus Anonymisierungsgründen vollständig aus dem Datensatz.\nBildet den Notendurchschnitt aus den bestehenden Notenvariablen (\"grade_&lt;fach&gt;\")."
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#übersicht-funktionalität-v",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#übersicht-funktionalität-v",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Übersicht Funktionalität V",
    "text": "Übersicht Funktionalität V\nVergleichs-Funktionen\n\nequalGADS() - Abgleich zweier GADSdat Objekte\ninspectDifferences() - Datenunterschiede zweier Variablen\ninspectMetaDifferences() - Meta-Datenunterschiede zweier Variablen\ncompareGADS()"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#übersicht-funktionalität-vi",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#übersicht-funktionalität-vi",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Übersicht Funktionalität VI",
    "text": "Übersicht Funktionalität VI\nCheck-Funktionen\n\ncheckVarNames() - Konventionen Variablennamen\nfixEncoding() - Umlaute & Sonderzeichen\ncheckMissings() - Abgleich Wertelabels & Missingtags\ncheckMissingsByValues() - Abgleich gelabelte numerische Werte & Missingtags\ncheckEmptyValLabels() - Abgleich Wertelabels & Daten\ncheckMissingValLabels() - Abgleich Daten & Wertelabels"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#variablennamen-1",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#variablennamen-1",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Variablennamen",
    "text": "Variablennamen\nKonventionen Variablennamen\n\n→ Automatisch beim Import\n\n_ vs .\nGeschützte Wörter"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#variablennamen-2",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#variablennamen-2",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Variablennamen",
    "text": "Variablennamen\nKonventionen Variablennamen\n\n→ Automatisch beim Import\n\n_ vs .\nGeschützte Wörter\n\n\n\n# Import SPSS data\naepfel &lt;- import_spss(\"aepfel.sav\")"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#variablennamen-3",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#variablennamen-3",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Variablennamen",
    "text": "Variablennamen\nTest-Daten\n\n# Display the dataset\naepfel$dat\n\n  ID Ä_Größe Ä_Qualität     Ort\n1  1       1          2   unter\n2  2       2          2    über\n3  3       2          1 draußen"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#variablennamen-4",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#variablennamen-4",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Variablennamen",
    "text": "Variablennamen\nTest-Daten\n\naepfel$labels[, c(\"varName\", \"varLabel\", \"value\", \"valLabel\", \"missings\")]\n\n     varName   varLabel value          valLabel missings\n1         ID Identifier    NA              &lt;NA&gt;     &lt;NA&gt;\n2    Ä_Größe       &lt;NA&gt;     1              groß    valid\n3    Ä_Größe       &lt;NA&gt;     2             klein    valid\n4 Ä_Qualität       &lt;NA&gt;   -99 Missing Unbekannt     miss\n5 Ä_Qualität       &lt;NA&gt;   -97 Missing by Design    valid\n6 Ä_Qualität       &lt;NA&gt;   -98              &lt;NA&gt;     miss\n7        Ort       &lt;NA&gt;    NA              &lt;NA&gt;     &lt;NA&gt;"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#sonderzeichen",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#sonderzeichen",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Sonderzeichen",
    "text": "Sonderzeichen\nUmlaute & Sonderzeichen umwandeln\n\nVariablenlabel, Wertelabel, Daten\nß zu ss, ä zu ae usw.\nVorbeugen von Encoding-Problemen\n\n\n# Fix encoding issues\naepfel &lt;- fixEncoding(aepfel)"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#sonderzeichen-1",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#sonderzeichen-1",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Sonderzeichen",
    "text": "Sonderzeichen\nUmlaute & Sonderzeichen umwandeln\n\n# Display the dataset after fixing encoding\naepfel$dat\n\n  ID Ae_Groesse Ae_Qualitaet      Ort\n1  1          1            2    unter\n2  2          2            2    ueber\n3  3          2            1 draussen"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#sonderzeichen-2",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#sonderzeichen-2",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Sonderzeichen",
    "text": "Sonderzeichen\nUmlaute & Sonderzeichen umwandeln\n\n# Display specific columns of the labels data\naepfel$labels[, c(\"varName\", \"varLabel\", \"value\", \"valLabel\", \"missings\")]\n\n       varName   varLabel value          valLabel missings\n1           ID Identifier    NA              &lt;NA&gt;     &lt;NA&gt;\n2   Ae_Groesse       &lt;NA&gt;     1             gross    valid\n3   Ae_Groesse       &lt;NA&gt;     2             klein    valid\n4 Ae_Qualitaet       &lt;NA&gt;   -99 Missing Unbekannt     miss\n5 Ae_Qualitaet       &lt;NA&gt;   -97 Missing by Design    valid\n6 Ae_Qualitaet       &lt;NA&gt;   -98              &lt;NA&gt;     miss\n7          Ort       &lt;NA&gt;    NA              &lt;NA&gt;     &lt;NA&gt;"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#abgleich-missingtags",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#abgleich-missingtags",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Abgleich Missingtags",
    "text": "Abgleich Missingtags\nAbgleich Wertelabels und Missingtags\n\nAlle Werte mit spezifischen Labels auch als Missing getagged?\nAlle als Missing getaggeden Werte auch spezifische Labels?\n\n→ Reporting und/oder Anpassung\n\n# Check and adjust missing tags\naepfel &lt;- checkMissings(aepfel, missingLabel = \"Missing|missing\")"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#abgleich-missingtags-1",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#abgleich-missingtags-1",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Abgleich Missingtags",
    "text": "Abgleich Missingtags\nAbgleich gelabelte numerische Werte und Missingtags\n\nAlle gelabelten Werte in spezifischem numerischen Range auch als Missing getagged?\n\n→ Reporting und/oder Anpassung\n\n# Check and adjust missing tags\naepfel &lt;- checkMissingsByValues(aepfel, missingValues = -50:-99)"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#abgleich-wertelabels",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#abgleich-wertelabels",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Abgleich Wertelabels",
    "text": "Abgleich Wertelabels\nAbgleich Daten und Wertelabels\n\nAlle Werte mit Wertelabels auch in Daten?\n\n\n# Check if all value labels are present in the data\ncheckEmptyValLabels(aepfel)\n\n$ID\nNULL\n\n$Ae_Groesse\nNULL\n\n$Ae_Qualitaet\n  value          valLabel missings\n4   -99 Missing Unbekannt     miss\n6   -98              &lt;NA&gt;     miss\n5   -97 Missing by Design     miss\n\n$Ort\nNULL"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#abgleich-wertelabels-1",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#abgleich-wertelabels-1",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Abgleich Wertelabels",
    "text": "Abgleich Wertelabels\nAbgleich Daten und Wertelabels\n\nAlle Werte in den Daten auch mit Wertelabels?\n\n\n# Check if all values in the data have value labels for specific variables\ncheckMissingValLabels(aepfel, vars = c(\"Ae_Groesse\", \"Ae_Qualitaet\"))\n\n$Ae_Groesse\nNULL\n\n$Ae_Qualitaet\n$Ae_Qualitaet$varLabel\n[1] NA\n\n$Ae_Qualitaet$missing_labels\n[1] 1 2"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#übung-2",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#übung-2",
    "title": "eatGADS - Datenaufbereitung",
    "section": "Übung",
    "text": "Übung\n\nÜberprüft die Vergabe von Missingtags im Beispieldatensatz mithilfe der Funktionen checkMissings() und checkMissingsByValues().\nÜberprüft, ob alle Wertelabels auch tatsächlich in den Daten vorkommen (checkEmptyValLabels()). Sollten diese Wertelabel aus den Daten entfernt werden?\nÜberprüft, ob alle Werte auch tatsächlich gelabelet sind (checkMissingValLabels())."
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#section",
    "href": "docs/R_tutorials/2024_eatGADS_Datenaufbereitung/quarto_eatGADS.html#section",
    "title": "eatGADS - Datenaufbereitung",
    "section": "",
    "text": "Danke für Eure\n\n\nAufmerksamkeit!"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#agenda",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#agenda",
    "title": "eatPrep",
    "section": "Agenda",
    "text": "Agenda\n\n\nDas Paket eatPrep\n\nFokus\nFeatures\nInstallation\n\nDatenstrukturen\n\n…von “Papier-Kompetenzdaten” am IQB\nRepräsentation dieser Strukturen in eatPrep\n\nPraktisch angewendet\n\nHaupt-Funktionen und -Schritte der Papier-Kompetenzdatenaufbereitung\n\n[Übung 1]\n\nZusatzfunktionen: Kategorientrennschärfen, Testsitzungsprotokolle, Beurteilerübereinstimmung (Rater-Funktionen)\n\n[Übung 2]"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#was-ist-papier-kompetenzdatenaufbereitung",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#was-ist-papier-kompetenzdatenaufbereitung",
    "title": "eatPrep",
    "section": "Was ist “Papier-Kompetenzdatenaufbereitung”?",
    "text": "Was ist “Papier-Kompetenzdatenaufbereitung”?\nPapier-Tests\nSchülerinnen und Schüler…\n\nerhalten gedruckte Testbögen,\nfüllen diese aus und\nwerden dabei von speziell geschulten Testleiter:innen beaufsichtigt.\n\nDie Ergebnisse werden später zentral gesammelt.\n\n1a. eatPrep: Fokus"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#was-ist-papier-kompetenzdatenaufbereitung-1",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#was-ist-papier-kompetenzdatenaufbereitung-1",
    "title": "eatPrep",
    "section": "Was ist “Papier-Kompetenzdatenaufbereitung”?",
    "text": "Was ist “Papier-Kompetenzdatenaufbereitung”?\nAufbereitung der Kompetenzdaten\nDie ausgefüllten Bögen werden\n\neingescannt (idR durch Datenpartner)\nbei Multiple-Choice-Fragen oder Ankreuzaufgaben wird häufig ein optisches Scannersystem verwendet, das die markierten automatisch Felder erkennt und direkt in eine digitale Datenbank überträgt (idR durch Datenpartner)\n(teil-) offene Antworten werden durch geschulte Kodierer:innen bewertet (teils im Haus, teils durch Datenpartner)\n\nAnsatzpunkt für eatPrep: Standardisierung und Automatisierung des Umgangs mit solchen Daten, die vom Subkontraktor zumeist im SPSS- (.sav) Format übergeben werden.\n\n1a. eatPrep: Fokus"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#primäres-ziel-von-eatprep",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#primäres-ziel-von-eatprep",
    "title": "eatPrep",
    "section": "Primäres Ziel von eatPrep",
    "text": "Primäres Ziel von eatPrep\n\nPrüfung und Aufbereitung von Kompetenztestdaten für IRT-Analysen unter Verwendung von Meta-Informationen (z.B. aus der IQB-ItemDB)\noptimiert für die Aufbereitung von IQB-Kompetenzdaten, aber nicht nur für diese verwendbar\n\n\n1a. eatPrep: Fokus"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#features",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#features",
    "title": "eatPrep",
    "section": "Features",
    "text": "Features\n\nAutomatisierung der Aufbereitungs-Arbeitsschritte\nVielfältige Prüfungen, Plausibilitätschecks und Diagnostik\nBehandlung vieler verschiedener Missingtypen, wenn gewünscht Beibehaltung bis zum Schluss (inkl. Missing-not-reached-Berechnung)\nWeitere Tools (Kategorientrennschärfen, Raterfunktionen, teil-manuelles Datencleaning, Exportfunktionen…)\n\n\n1b. eatPrep: Features"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#installation",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#installation",
    "title": "eatPrep",
    "section": "Installation",
    "text": "Installation\n\neatPrep liegt auf der Entwicklerplattform GitHub\nR-Pakete kann man von GitHub z.B. über das R-Paket “remotes” installieren. Sofern es nicht vorhanden ist, kann es mit…\n\n\ninstall.packages(\"remotes\")\n\n…installiert werden. eatPrep kann anschließend mit folgenden Befehlszeilen installiert und geladen werden:\n\nremotes::install_github(\"sachseka/eatPrep\")\nlibrary(eatPrep)\n\n\n1c. eatPrep: Installation"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#subitems-items-aufgaben",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#subitems-items-aufgaben",
    "title": "eatPrep",
    "section": "Subitems, Items, Aufgaben",
    "text": "Subitems, Items, Aufgaben\n\n\n\n\n\n\n\n\n2a. Strukturen von Papier-Kompetenzdaten am IQB"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#subitems-items-aufgaben-1",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#subitems-items-aufgaben-1",
    "title": "eatPrep",
    "section": "Subitems, Items, Aufgaben",
    "text": "Subitems, Items, Aufgaben\n\n\n2a. Strukturen von Papier-Kompetenzdaten am IQB"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#subitems-items-aufgaben-und-values-und-scores",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#subitems-items-aufgaben-und-values-und-scores",
    "title": "eatPrep",
    "section": "Subitems, Items, Aufgaben und Values und Scores",
    "text": "Subitems, Items, Aufgaben und Values und Scores\n\n\n2a. Subitems in Items in Aufgaben"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#fehlende-werte",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#fehlende-werte",
    "title": "eatPrep",
    "section": "Fehlende Werte",
    "text": "Fehlende Werte\n\n\n\n\n\n\n\n\n\n\n\nCode\nAbbr\nLabel\nExplanation\n\n\n\n\n-98\nmir\nmissing invalid response\n(1) Item was edited, and (2a) empty answer or (2b) invalid (joke) answer.\n\n\n-99\nmbo/mbi\nmissing by omission/intention\nItem wasn’t edited but seen, or wasn’t seen, but there are seen or edited subsequent Items.\n\n\n-96\nmnr\nmissing not reached\n(1) Item wasn’t seen, and (2) all subsequent Items weren’t seen, either.\n\n\n-97\nmci\nmissing coding impossible\n(1) Item should/could have been edited, and (2) answer can’t be analysed due to technical problems.\n\n\n-94\nmbd\nmissing by design\nno answer, because Item wasn’t shown to the testperson by design.\n\n\n\n\n\n\n2a. Subitems in Items in Aufgaben"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#aufgaben-in-blöcken-und-blöcke-in-testheften",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#aufgaben-in-blöcken-und-blöcke-in-testheften",
    "title": "eatPrep",
    "section": "Aufgaben in Blöcken und Blöcke in Testheften",
    "text": "Aufgaben in Blöcken und Blöcke in Testheften\n \n\n2a. Strukturen von Papier-Kompetenzdaten am IQB"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#nützliches-vokabular",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#nützliches-vokabular",
    "title": "eatPrep",
    "section": "nützliches Vokabular",
    "text": "nützliches Vokabular\n\nTesthefte (booklets): bestehen aus Blöcken\nBlöcke (blocks/cluster): bestehen aus Aufgaben\nAufgaben (tasks): beinhalten Items (i.d.R. zu einem gemeinsamen Stimulus/testlet)\nItems (units): oft die am Ende interessierende Analyseeinheit\nSubitems (subunits): werden zu Items aggregiert\nWerte (values): Ausprägungen, die eine Person auf einem (Sub-)Item annehmen kann\nScores (valueRecodes): Eine Abbildung der ursprünglichen Werte (Values) auf eine kleinere Anzahl von Kategorien (i.d.R. mindestens Richtig/Falsch/Fehlend, also 1/0/NA), die besser für eine IRT-Skalierung geeignet sind\n\n\n2a. Strukturen von Papier-Kompetenzdaten am IQB"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#repräsentation-der-datenstrukturen-in-eatprep",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#repräsentation-der-datenstrukturen-in-eatprep",
    "title": "eatPrep",
    "section": "Repräsentation der Datenstrukturen in eatPrep",
    "text": "Repräsentation der Datenstrukturen in eatPrep\nWie werden Testhefte, Blöcke, Aufgaben, Items, Subitems, Werte und Scores in eatPrep hinterlegt?\n\nanalog einfacher relationaler Meta-Daten-Datenbank: eine Liste aus mehreren data.frames mit prädefinierter Struktur und festen Namen\nwir brauchen Meta-Daten über die Items\n\n\n2b. Metadaten-Struktur in eatPrep"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#repräsentation-der-datenstrukturen-in-eatprep-inputlisten-plätze-1-4",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#repräsentation-der-datenstrukturen-in-eatprep-inputlisten-plätze-1-4",
    "title": "eatPrep",
    "section": "Repräsentation der Datenstrukturen in eatPrep: inputListen-Plätze 1-4",
    "text": "Repräsentation der Datenstrukturen in eatPrep: inputListen-Plätze 1-4\n\n\n\n\n2b. Metadaten-Struktur in eatPrep"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#repräsentation-der-datenstrukturen-in-eatprep-inputlisten-plätze-5-7",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#repräsentation-der-datenstrukturen-in-eatprep-inputlisten-plätze-5-7",
    "title": "eatPrep",
    "section": "Repräsentation der Datenstrukturen in eatPrep: inputListen-Plätze 5-7",
    "text": "Repräsentation der Datenstrukturen in eatPrep: inputListen-Plätze 5-7\n\n\n\n\n\n\n\n\n2b. Metadaten-Struktur in eatPrep"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#repräsentation-der-datenstrukturen-in-eatprep-inputlisten-plätze-8-10",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#repräsentation-der-datenstrukturen-in-eatprep-inputlisten-plätze-8-10",
    "title": "eatPrep",
    "section": "Repräsentation der Datenstrukturen in eatPrep: inputListen-Plätze 8-10",
    "text": "Repräsentation der Datenstrukturen in eatPrep: inputListen-Plätze 8-10\n\n\n\n\n\n\n\n\n2b. Metadaten-Struktur in eatPrep"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#meta-daten-einlesen",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#meta-daten-einlesen",
    "title": "eatPrep",
    "section": "(Meta-)Daten einlesen",
    "text": "(Meta-)Daten einlesen\nreadDaemonXlsx() - einlesen der inputListe, die mithilfe des EDV-Tools “ZKDaemon” erzeugt wurde.\n\n(Dieses liegt unter i:\\EDV\\IQB-Apps\\ZKDaemon\\ZKDaemon.application. Eine ausführlichere, via Screenshots geführte Anleitung zur Bedienung des ZKDaemon findet sich hier:\ni:\\Methoden\\02_IQB-interne_eat_Workshops\\eatPrep_2021\\eatPrep_2021-06-18.pdf)\n\nreadSpss() - einlesen von SPSS-Dateien.\nreadMerkmalXlsx() - einlesen von zusätzlichen Item- und Aufgabenmerkmalen wie Bearbeitungszeiten, Formaten, inhaltlichen Kategorien, …\n\n(Erzeugen der Merkmal-Xlsx via Klick auf “Merkmalsauszug” in i:\\EDV\\IQB-Apps\\IQB-ItemDB\\IQB-ItemDB.application)\n\n\n3a. Praxis: Haupt-Funktionen in eatPrep"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#meta-daten-einlesen-inputliste",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#meta-daten-einlesen-inputliste",
    "title": "eatPrep",
    "section": "(Meta-)Daten einlesen: inputListe",
    "text": "(Meta-)Daten einlesen: inputListe\nItem Meta-Daten:\n\nfilename &lt;- system.file(\"extdata\", \"inputList.xlsx\", package = \"eatPrep\")\ninpustList &lt;- readDaemonXlsx(filename)\nstr(inpustList)\n&gt; List of 9\n&gt;  $ units        :'data.frame':    29 obs. of  6 variables:\n&gt;   ..$ unit             : chr [1:29] \"I01\" \"I02\" \"I03\" \"I04\" ...\n&gt;   ..$ unitLabel        : chr [1:29] \"Animals: Weight of a duck\" \"Animals: Weight of a horse\" \"Animals: Weight of a mouse\" \"Animals: Weight of a cat\" ...\n&gt;   ..$ unitDescription  : chr [1:29] NA NA NA NA ...\n&gt;   ..$ unitType         : chr [1:29] \"TI\" \"TI\" \"TI\" \"TI\" ...\n&gt;   ..$ unitAggregateRule: chr [1:29] NA NA NA NA ...\n&gt;   ..$ unitScoreRule    : chr [1:29] NA NA NA NA ...\n&gt;  $ subunits     :'data.frame':    30 obs. of  9 variables:\n&gt;   ..$ unit               : chr [1:30] \"I01\" \"I02\" \"I03\" \"I04\" ...\n&gt;   ..$ subunit            : chr [1:30] \"I01\" \"I02\" \"I03\" \"I04\" ...\n&gt;   ..$ subunitType        : chr [1:30] \"1\" \"1\" \"1\" \"1\" ...\n&gt;   ..$ subunitLabel       : chr [1:30] \"Animals: Weight of a duck\" \"Animals: Weight of a horse\" \"Animals: Weight of a mouse\" \"Animals: Weight of a cat\" ...\n&gt;   ..$ subunitDescription : chr [1:30] NA NA NA NA ...\n&gt;   ..$ subunitPosition    : chr [1:30] \"a)\" \"b)\" \"c)\" \"d)\" ...\n&gt;   ..$ subunitTransniveau : chr [1:30] NA NA NA NA ...\n&gt;   ..$ subunitRecoded     : chr [1:30] \"I01R\" \"I02R\" \"I03R\" \"I04R\" ...\n&gt;   ..$ subunitLabelRecoded: chr [1:30] \"Recoded Animals: Weight of a duck\" \"Recoded Animals: Weight of a horse\" \"Recoded Animals: Weight of a mouse\" \"Recoded Animals: Weight of a cat\" ...\n&gt;  $ values       :'data.frame':    220 obs. of  8 variables:\n&gt;   ..$ subunit                : chr [1:220] \"I01\" \"I01\" \"I01\" \"I01\" ...\n&gt;   ..$ value                  : chr [1:220] \"1\" \"2\" \"3\" \"6\" ...\n&gt;   ..$ valueRecode            : chr [1:220] \"0\" \"0\" \"1\" \"mnr\" ...\n&gt;   ..$ valueType              : chr [1:220] \"vc\" \"vc\" \"vc\" \"mnr\" ...\n&gt;   ..$ valueLabel             : chr [1:220] \"Response option 1 marked\" \"Response option 2 marked\" \"Response option 3 marked\" \"missing not reached\" ...\n&gt;   ..$ valueDescription       : chr [1:220] \"Response option 1 marked\" \"Response option 2 marked\" \"Response option 3 marked\" \"missing not reached\" ...\n&gt;   ..$ valueLabelRecoded      : chr [1:220] \"0\" \"0\" \"1\" \"mnr\" ...\n&gt;   ..$ valueDescriptionRecoded: chr [1:220] NA NA NA NA ...\n&gt;  $ unitRecodings:'data.frame':    7 obs. of  7 variables:\n&gt;   ..$ unit             : chr [1:7] \"I12\" \"I12\" \"I12\" \"I12\" ...\n&gt;   ..$ value            : chr [1:7] \"0\" \"1\" \"2\" \"3\" ...\n&gt;   ..$ valueRecode      : chr [1:7] \"0\" \"0\" \"0\" \"1\" ...\n&gt;   ..$ valueType        : chr [1:7] \"vc\" \"vc\" \"vc\" \"vc\" ...\n&gt;   ..$ valueLabel       : chr [1:7] NA NA NA NA ...\n&gt;   ..$ valueDescription : chr [1:7] NA NA NA NA ...\n&gt;   ..$ valueLabelRecoded: chr [1:7] NA NA NA NA ...\n&gt;  $ savFiles     :'data.frame':    3 obs. of  3 variables:\n&gt;   ..$ filename: chr [1:3] \"booklet1.sav\" \"booklet2.sav\" \"booklet3.sav\"\n&gt;   ..$ case.id : chr [1:3] \"ID\" \"ID\" \"ID\"\n&gt;   ..$ fullname: chr [1:3] NA NA NA\n&gt;  $ newID        :'data.frame':    1 obs. of  2 variables:\n&gt;   ..$ key  : chr \"master-id\"\n&gt;   ..$ value: chr \"ID\"\n&gt;  $ aggrMiss     :'data.frame':    7 obs. of  8 variables:\n&gt;   ..$ nam: chr [1:7] \"vc\" \"mvi\" \"mnr\" \"mci\" ...\n&gt;   ..$ vc : chr [1:7] \"vc\" \"mvi\" \"vc\" \"mci\" ...\n&gt;   ..$ mvi: chr [1:7] \"mvi\" \"mvi\" \"err\" \"mci\" ...\n&gt;   ..$ mnr: chr [1:7] \"vc\" \"err\" \"mnr\" \"mci\" ...\n&gt;   ..$ mci: chr [1:7] \"mci\" \"mci\" \"mci\" \"mci\" ...\n&gt;   ..$ mbd: chr [1:7] \"err\" \"err\" \"err\" \"err\" ...\n&gt;   ..$ mir: chr [1:7] \"vc\" \"err\" \"mir\" \"mci\" ...\n&gt;   ..$ mbi: chr [1:7] \"vc\" \"err\" \"mnr\" \"mci\" ...\n&gt;  $ booklets     :'data.frame':    3 obs. of  4 variables:\n&gt;   ..$ booklet: chr [1:3] \"booklet1\" \"booklet2\" \"booklet3\"\n&gt;   ..$ block1 : chr [1:3] \"bl1\" \"bl4\" \"bl3\"\n&gt;   ..$ block2 : chr [1:3] \"bl2\" \"bl3\" \"bl1\"\n&gt;   ..$ block3 : chr [1:3] \"bl3\" \"bl2\" \"bl4\"\n&gt;  $ blocks       :'data.frame':    30 obs. of  3 variables:\n&gt;   ..$ subunit             : chr [1:30] \"I01\" \"I02\" \"I03\" \"I04\" ...\n&gt;   ..$ block               : chr [1:30] \"bl1\" \"bl1\" \"bl1\" \"bl1\" ...\n&gt;   ..$ subunitBlockPosition: chr [1:30] \"1\" \"2\" \"3\" \"4\" ...\n\n\n3a. Praxis: Haupt-Funktionen in eatPrep"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#meta-daten-einlesen-spss-daten",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#meta-daten-einlesen-spss-daten",
    "title": "eatPrep",
    "section": "(Meta-)Daten einlesen: SPSS-Daten",
    "text": "(Meta-)Daten einlesen: SPSS-Daten\nExemplarisch ein Datensatz:\n\nfilename &lt;- system.file(\"extdata\", \"booklet1.sav\", package = \"eatPrep\")\nbooklet1 &lt;- readSpss(filename)\nhead(booklet1)\n&gt;          ID hisei I01 I02 I03 I04 I05 I06 I07 I08 I09 I10 I11 I12a I12b I12c\n&gt; 1 person002    57   3   4   2   3   1   1   1   1   3   2   3    0    1    4\n&gt; 2 person003    32   3   4   2   3   0   0   1   1   2   2   1    0    0    4\n&gt; 3 person004    59   3   4   2   3   0   0   1   1   4   4   3    0    0    4\n&gt; 4 person005    56   3   1   2   2   1   1   2   1   4   4   9    0    1    4\n&gt; 5 person006    55   3   4   2   2   0   0   1   1   2   2   2    0    1    4\n&gt; 6 person007    47   1   4   2   3   0   0   1   1   2   3   1    0    0    4\n&gt;   I13 I14  I15  I16  I17  I18  I19  I20  I21  I22  I23  I24  I25  I26  I27  I28\n&gt; 1   2   6 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;\n&gt; 2   2   6 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;\n&gt; 3   2   6 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;\n&gt; 4   2   6 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;\n&gt; 5   2   6 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;\n&gt; 6   2   6 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;\n\n\n3a. Praxis: Haupt-Funktionen in eatPrep"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#meta-daten-einlesen-merkmale",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#meta-daten-einlesen-merkmale",
    "title": "eatPrep",
    "section": "(Meta-)Daten einlesen: Merkmale",
    "text": "(Meta-)Daten einlesen: Merkmale\nWeitere Merkmale:\n\nfilename &lt;- system.file(\"extdata\", \"itemmerkmale.xlsx\", package = \"eatPrep\")\nmerkmale &lt;- readMerkmalXlsx(filename, tolcl = FALSE, alleM = TRUE)\nhead(merkmale)\n&gt; $Aufgabenmerkmale\n&gt;                      Aufgabe Zeit.A                     AufgID AufgTitel\n&gt; 1  Animals: Weight of a duck   0:00  Animals: Weight of a duck        NA\n&gt; 2 Animals: Weight of a horse   0:00 Animals: Weight of a horse        NA\n&gt; \n&gt; $Itemmerkmale\n&gt;                      Aufgabe Teilaufgabe Item Zeit.I Anforderungsbereich.MaP\n&gt; 1  Animals: Weight of a duck           A   01   0:00                       I\n&gt; 2 Animals: Weight of a horse           A   01   0:00                       I\n&gt; 3 Animals: Weight of a horse           B   02   0:00                      II\n&gt;   Bildungsstandards.MaP.allgemeine                Itemtyp.5er\n&gt; 1                               1a GA - Geschlossen Ankreuzen\n&gt; 2                             &lt;NA&gt; GA - Geschlossen Ankreuzen\n&gt; 3                             &lt;NA&gt; GA - Geschlossen Ankreuzen\n&gt;                       AufgID AufgTitel                       ItemID\n&gt; 1  Animals: Weight of a duck        NA  Animals: Weight of a duck01\n&gt; 2 Animals: Weight of a horse        NA Animals: Weight of a horse01\n&gt; 3 Animals: Weight of a horse        NA Animals: Weight of a horse02\n&gt; \n&gt; $AlleMerkmale\n&gt;                       AufgID                    Aufgabe Teilaufgabe Item\n&gt; 1  Animals: Weight of a duck  Animals: Weight of a duck           A   01\n&gt; 2 Animals: Weight of a horse Animals: Weight of a horse           A   01\n&gt; 3 Animals: Weight of a horse Animals: Weight of a horse           B   02\n&gt;                         ItemID Zeit.I Anforderungsbereich.MaP\n&gt; 1  Animals: Weight of a duck01   0:00                       I\n&gt; 2 Animals: Weight of a horse01   0:00                       I\n&gt; 3 Animals: Weight of a horse02   0:00                      II\n&gt;   Bildungsstandards.MaP.allgemeine                Itemtyp.5er Zeit.A\n&gt; 1                               1a GA - Geschlossen Ankreuzen   0:00\n&gt; 2                             &lt;NA&gt; GA - Geschlossen Ankreuzen   0:00\n&gt; 3                             &lt;NA&gt; GA - Geschlossen Ankreuzen   0:00\n\n\n3a. Praxis: Haupt-Funktionen in eatPrep"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#checken",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#checken",
    "title": "eatPrep",
    "section": "Checken",
    "text": "Checken\ncheckInputList() - eingelesene inputListe auf interne Konsistenz prüfen\ncheckData() - Datensätze gemäß Item-Meta-Informationen überprüfen und sonstige Plausibilitätsprüfungen der Daten\ncheckDesign() - Datensätze gemäß Meta-Informationen zum Testdesign überprüfen\n\n3a. Praxis: Haupt-Funktionen in eatPrep"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#checken-rekodieren-aggregieren-scoren",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#checken-rekodieren-aggregieren-scoren",
    "title": "eatPrep",
    "section": "Checken, Rekodieren, Aggregieren, Scoren",
    "text": "Checken, Rekodieren, Aggregieren, Scoren\ninputListe checken:\n\ncheckInputList(inputList)\n&gt; \n&gt; ── Checking sheets\n&gt; \n&gt; ── Check: Value Recoding\n&gt; ✔ Missing types `mir` and `mbi` are defined for all items in valueRecode.\n&gt; ✖ Missing type `mnr` is not defined as valueRecode for items: `I14`.\n&gt; ✖ Missing type `mbd` is not defined as valueRecode for items: `I14`.\n&gt; ℹ value contains the following values over all items: `0`, `1`, `2`, `3`, `4`,\n&gt; `5`, `6`, `7`, `8`, and `9`\n&gt; ✔ valueRecode contains only 0, 1, and the mistypes: `0`, `1`, `mbd`, `mbi`,\n&gt; `mir`, and `mnr`\n&gt; \n&gt; ── Check: Value Types\n&gt; ✔ No other values than `vc` and the mistypes in valueType.\n&gt; \n&gt; ── Check: Unit Equivalence\n&gt; ✔ All 28 units in units sheet are also defined in subunits.\n&gt; \n&gt; ── Check: Subunit Equivalence\n&gt; ✔ All 30 subunits in subunits sheet are also defined in values.\n&gt; \n&gt; ── Check: Unit Recoding\n&gt; ℹ Units with only one subunit: 27\n&gt; ℹ Units with more than one subunit: 1 (`I12`)\n&gt; ✔ All units with more than one subunit are defined in unitRecodings sheet.\n&gt; [1] FALSE\n\n\n3a. Praxis: Haupt-Funktionen in eatPrep"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#mergen-rekodieren-aggregieren-scoren",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#mergen-rekodieren-aggregieren-scoren",
    "title": "eatPrep",
    "section": "Mergen, Rekodieren, Aggregieren, Scoren",
    "text": "Mergen, Rekodieren, Aggregieren, Scoren\nmergeData() - zusammenführen der Datensätze und Diagnostik zu Passung\nrecodeData() - rekodieren der Subitems gemäß Meta-Informationen aus der inputListe\naggregateData() - Subitems zu Items aggregieren\nscoreData() - ehemals aus Subitems bestehende Items rekodieren\nmnrCoding() - rekodieren der letzten Items (falls leer) in jedem Block (siehe Testdesign) als “missing not reached”\n\n3a. Praxis: Haupt-Funktionen in eatPrep"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#wrapper-automatedatapreparation",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#wrapper-automatedatapreparation",
    "title": "eatPrep",
    "section": "Wrapper automateDataPreparation()",
    "text": "Wrapper automateDataPreparation()\n\n# Vorbereitung, da die Pfade für die SPSS-Dateien hier noch nicht in der InputListe eingetragen sind\ninputList$savFiles$fullname[1] &lt;- system.file(\"extdata\", \"booklet1.sav\", package = \"eatPrep\")\ninputList$savFiles$fullname[2] &lt;- system.file(\"extdata\", \"booklet2.sav\", package = \"eatPrep\")\ninputList$savFiles$fullname[3] &lt;- system.file(\"extdata\", \"booklet3.sav\", package = \"eatPrep\")\n\npreparedData &lt;- automateDataPreparation(inputList = inputList,\n    readSpss = TRUE, checkData = TRUE,  mergeData = TRUE,\n    recodeData = TRUE, aggregateData = TRUE, scoreData = TRUE,\n    recodeMnr = TRUE, breaks=c(1,2,3), writeSpss = FALSE, verbose = TRUE)\n&gt; Starting automateDataPreparation 2025-02-10 13:07:52.202756\n&gt; \n&gt; Load .sav-files.\n&gt; Successfully read in: booklet1.sav, booklet2.sav, booklet3.sav\n&gt; \n&gt; Check data...\n&gt; \n&gt; Checking dataset booklet1.sav\n&gt; Only valid codes in ID variable.\n&gt; No duplicated entries in ID variable.\n&gt; No duplicated variable names.\n&gt; Found no variable information about variable(s) hisei. This/These variables will not be checked for missings and invalid codes.\n&gt; Variable(s) I24, I25 contain(s) only missing values.\n&gt; Found no invalid codes.\n&gt; \n&gt; Checking dataset booklet2.sav\n&gt; Only valid codes in ID variable.\n&gt; No duplicated entries in ID variable.\n&gt; No duplicated variable names.\n&gt; Found no variable information about variable(s) hisei. This/These variables will not be checked for missings and invalid codes.\n&gt; Found no invalid codes.\n&gt; \n&gt; Checking dataset booklet3.sav\n&gt; Only valid codes in ID variable.\n&gt; No duplicated entries in ID variable.\n&gt; No duplicated variable names.\n&gt; Found no variable information about variable(s) hisei. This/These variables will not be checked for missings and invalid codes.\n&gt; Found no invalid codes.\n&gt; \n&gt; Start merging.\n&gt; Start merging of dataset 1.\n&gt; Start merging of dataset 2.\n&gt; Start merging of dataset 3.\n&gt; \n&gt; Start recoding.\n&gt; \n&gt; Found no recode information for variable(s): \n&gt; ID, hisei. \n&gt; This/These variable(s) will not be recoded.\n&gt; \n&gt; Variables... I01, I02, I03, I04, I05, I06, I07, I08, I09, I10, I11, I12a, I12b, I12c, I13, I14, I15, I16, I17, I18, I19, I20, I21, I22, I23, I24, I25, I26, I27, I28\n&gt; ...have been recoded.\n&gt; \n&gt; Start recoding Mbi to Mnr.\n&gt; ...identifying items in data (reference is blocks$subunit)\n&gt; Variables in data not recognized as items:\n&gt; ID, booklet, hisei\n&gt; If some of these excluded variables should have been identified as items (and thus be used for mnr coding) check 'blocks', 'subunits', 'dat'.\n&gt; ...identifying items with no mbi-codes ('mbi'):\n&gt; I04R, I07R\n&gt; If you expect mbi-codes on these variables check your data and option 'mbiCode'\n&gt; no mnr identified for any case. nothing recoded.\n&gt; \n&gt; Start aggregating\n&gt; Since inputList$aggrMiss exists, this will be used instead of default.\n&gt; All aggregation rules will be defaulted to 'SUM', because no other type is currently supported.\n&gt; Found 27 unit(s) with only one subunit in 'dat'. This/these subunit(s) will not be aggregated and renamed to their respective unit name(s).\n&gt; 1 units were aggregated: I12.\n&gt; \n&gt; Start scoring.\n&gt; ✔ 1 unit was scored: `I12`.\n&gt; \n&gt; No SPSS-File has been written.\n&gt; \n&gt; Missings are UNcollapsed.\n&gt; automateDataPreparation terminated successfully! 2025-02-10 13:07:52.569825\n\n\n(automateDataPreparation() arbeitetet alternativ auch mit Daten, die als einzelner (ggf. bereits zusammengeführter) R-data.frame übergeben werden (via Argument “datList”))\n\n\n3a. Praxis: Haupt-Funktionen in eatPrep"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#wrapper-automatedatapreparation-1",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#wrapper-automatedatapreparation-1",
    "title": "eatPrep",
    "section": "Wrapper automateDataPreparation()",
    "text": "Wrapper automateDataPreparation()\n\n…arbeitetet auch mit Daten, die als Liste von R-data.frames übergeben werden (Argument datList):\n\n\n# Einbauen von Problem in Daten zur Illustration der Diagnostik von mergeData()\ninputDat[[3]]$ID[1] &lt;- inputDat[[2]]$ID[1]\n\npreparedData &lt;- automateDataPreparation(datList = inputDat, inputList = inputList, \n    readSpss = FALSE, checkData = TRUE,  mergeData = TRUE,\n    recodeData = TRUE, aggregateData = TRUE, scoreData = TRUE,\n    recodeMnr = TRUE, breaks=c(1,2,3), writeSpss = FALSE, verbose = TRUE)\n&gt; Starting automateDataPreparation 2025-02-10 13:07:52.58896\n&gt; \n&gt; Check data...\n&gt; \n&gt; Checking dataset booklet1\n&gt; Only valid codes in ID variable.\n&gt; No duplicated entries in ID variable.\n&gt; No duplicated variable names.\n&gt; Found no variable information about variable(s) hisei. This/These variables will not be checked for missings and invalid codes.\n&gt; Found no invalid codes.\n&gt; \n&gt; Checking dataset booklet2\n&gt; Only valid codes in ID variable.\n&gt; No duplicated entries in ID variable.\n&gt; No duplicated variable names.\n&gt; Found no variable information about variable(s) hisei. This/These variables will not be checked for missings and invalid codes.\n&gt; Found no invalid codes.\n&gt; \n&gt; Checking dataset booklet3\n&gt; Only valid codes in ID variable.\n&gt; No duplicated entries in ID variable.\n&gt; No duplicated variable names.\n&gt; Found no variable information about variable(s) hisei. This/These variables will not be checked for missings and invalid codes.\n&gt; Found no invalid codes.\n&gt; \n&gt; Start merging.\n&gt; Start merging of dataset 1.\n&gt; Start merging of dataset 2.\n&gt; Start merging of dataset 3.\n&gt; Multiple different valid codes in variable: 'hisei' in 'dataset 3': \n&gt;  The first value has been kept. \n&gt;  IDs: person200\n&gt;  Values: 69&49\n&gt; Multiple different valid codes in variable: 'I15' in 'dataset 3': \n&gt;  The first value has been kept. \n&gt;  IDs: person200\n&gt;  Values: 4&3\n&gt; Multiple different valid codes in variable: 'I16' in 'dataset 3': \n&gt;  The first value has been kept. \n&gt;  IDs: person200\n&gt;  Values: 4&1\n&gt; Multiple different valid codes in variable: 'I18' in 'dataset 3': \n&gt;  The first value has been kept. \n&gt;  IDs: person200\n&gt;  Values: 1&4\n&gt; Multiple different valid codes in variable: 'I20' in 'dataset 3': \n&gt;  The first value has been kept. \n&gt;  IDs: person200\n&gt;  Values: 4&3\n&gt; Multiple different valid codes in variable: 'I21' in 'dataset 3': \n&gt;  The first value has been kept. \n&gt;  IDs: person200\n&gt;  Values: 2&3\n&gt; Multiple different valid codes in variable: 'I22' in 'dataset 3': \n&gt;  The first value has been kept. \n&gt;  IDs: person200\n&gt;  Values: 1&3\n&gt; Multiple different valid codes in variable: 'I23' in 'dataset 3': \n&gt;  The first value has been kept. \n&gt;  IDs: person200\n&gt;  Values: 9&3\n&gt; Multiple different valid codes in variable: 'I25' in 'dataset 3': \n&gt;  The first value has been kept. \n&gt;  IDs: person200\n&gt;  Values: 1&0\n&gt; Multiple different valid codes in variable: 'I26' in 'dataset 3': \n&gt;  The first value has been kept. \n&gt;  IDs: person200\n&gt;  Values: 9&1\n&gt; Multiple different valid codes in variable: 'I28' in 'dataset 3': \n&gt;  The first value has been kept. \n&gt;  IDs: person200\n&gt;  Values: 1&0\n&gt; Start adding mbd according to data pattern.\n&gt; \n&gt; Start recoding.\n&gt; \n&gt; Found no recode information for variable(s): \n&gt; ID, hisei. \n&gt; This/These variable(s) will not be recoded.\n&gt; \n&gt; Variables... I01, I02, I03, I04, I05, I06, I07, I08, I09, I10, I11, I12a, I12b, I12c, I13, I14, I15, I16, I17, I18, I19, I20, I21, I22, I23, I24, I25, I26, I27, I28\n&gt; ...have been recoded.\n&gt; \n&gt; Start recoding Mbi to Mnr.\n&gt; ...identifying items in data (reference is blocks$subunit)\n&gt; Variables in data not recognized as items:\n&gt; ID, booklet, hisei\n&gt; If some of these excluded variables should have been identified as items (and thus be used for mnr coding) check 'blocks', 'subunits', 'dat'.\n&gt; ...identifying items with no mbi-codes ('mbi'):\n&gt; I04R, I08R\n&gt; If you expect mbi-codes on these variables check your data and option 'mbiCode'\n&gt; mnr statistics:\n&gt;      mnr cells: 553\n&gt;      unique cases with at least one mnr code: 89\n&gt;      unique items with at least one mnr code: 16\n&gt; unique cases ('ID') per booklet and booklet section (0s omitted):\n&gt;    booklet booklet.section N.ID\n&gt; 1 booklet1               2   11\n&gt; 2 booklet1               3   28\n&gt; 3 booklet2               1   28\n&gt; 4 booklet2               2   11\n&gt; 5 booklet2               3    1\n&gt; 6 booklet3               3   31\n&gt; start recoding (item-wise)\n&gt; done\n&gt; elapsed time: 0.1 secs\n&gt; \n&gt; Start aggregating\n&gt; Since inputList$aggrMiss exists, this will be used instead of default.\n&gt; All aggregation rules will be defaulted to 'SUM', because no other type is currently supported.\n&gt; Found 27 unit(s) with only one subunit in 'dat'. This/these subunit(s) will not be aggregated and renamed to their respective unit name(s).\n&gt; 1 units were aggregated: I12.\n&gt; \n&gt; Start scoring.\n&gt; ✔ 1 unit was scored: `I12`.\n&gt; \n&gt; No SPSS-File has been written.\n&gt; \n&gt; Missings are UNcollapsed.\n&gt; automateDataPreparation terminated successfully! 2025-02-10 13:07:52.847506\n\n\n3a. Praxis: Haupt-Funktionen in eatPrep"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#vollständigkeit-der-daten-überprüfen",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#vollständigkeit-der-daten-überprüfen",
    "title": "eatPrep",
    "section": "Vollständigkeit der Daten überprüfen",
    "text": "Vollständigkeit der Daten überprüfen\n\nprepDat &lt;- automateDataPreparation(datList = inputDat, inputList = inputList, \n    readSpss = FALSE, checkData = TRUE,  mergeData = TRUE,\n    recodeData = TRUE, aggregateData = FALSE, scoreData = FALSE,\n    writeSpss = FALSE, verbose = TRUE)\n\n\ncheckDesign(dat = prepDat, booklets = inputList$booklets, blocks = inputList$blocks,\n    rotation = inputList$rotation, subunits = inputList$subunits, \n    sysMis = \"mbd\", id=\"ID\", verbose = TRUE)\n&gt; \n&gt; ── Check: Subunit recoding\n&gt; ℹ Use names for recoded subunits.\n&gt; \n&gt; ── Check: Variables in the dataset\n&gt; ℹ The following 1 variable is not in info (`subunit` in blocks) but in dataset.\n&gt; It will be ignored during check: `hisei`\n&gt; \n&gt; ── Check: Valid and missing codes\n&gt; ℹ Deviations from design detected!\n&gt; ✖ Found for 7 subunits valid codes instead of sysMis for booklet `booklet2`:\n&gt; I01R, I02R, I03R, I04R, I05R, I06R, and I07R\n&gt; ℹ I01R, I02R, I03R, I04R, I05R, I06R, I07R (1 cases): person200\n\n\n3a. Praxis: Haupt-Funktionen in eatPrep"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#export",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#export",
    "title": "eatPrep",
    "section": "Export",
    "text": "Export\ncollapseMissings() - rekodiert die Missingtypen in prädefinierte Scores (i.d.R. 0,1,NA). Ein solcher “collapster” R-data.frame kann direkt nach eatModel zur Skalierung übergeben werden.\nwriteSpss() - produziert eine SPSS-Syntax und einen .txt-Datensatz, der mit der Syntax in SPSS inklusive aller Meta-Daten eingelesen werden kann.\nprep2GADS() - sowohl die Roh-Datensätze als auch die fertigen, gescorten Datensätze können inklusive aller ihrer Meta-Daten in ein GADSdat-Objekt exportiert werden, zur Datenaufbewahrung oder Weiterverarbeitung in eatGADS."
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#übung-1-1",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#übung-1-1",
    "title": "eatPrep",
    "section": "Übung 1",
    "text": "Übung 1\n\nLest die Meta-Daten (inputListe) und Daten (booklet1.sav, booklet2.sav, booklet3.sav) ein und lasst diese automatisiert prüfen. Bereitet die Daten bis zum gescorten Zustand weiter auf.\nÜberprüft, ob die Daten zum Testdesign passen oder ob es Dateneinträge gibt, wo per Design fehlende Werte sein müssten oder per Design fehlende Werte, wo es valide Codes oder andere Missingtypen geben müsste.\nExportiert die aufbereiteten (aber “uncollapsten”) Daten ins eatGADS-Format.\n\n\n3a. Praxis: Haupt-Funktionen in eatPrep – Übung 1"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#kategorientrennschärfen---funktionen",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#kategorientrennschärfen---funktionen",
    "title": "eatPrep",
    "section": "Kategorientrennschärfen - Funktionen",
    "text": "Kategorientrennschärfen - Funktionen\nEin essenzielles diagnostisches Tool sind die Kategorientrennschärfen. Diese geben wichtige Hinweise auf falsch zugewiesene Scores, fälschlicherweise richtige Distraktoren und falsche Attraktoren.\ncatPbc() - berechnet die Kategorientrennschärfen.\nevalPbc() - findet und markiert Auffälligkeiten in Lösungshäufigkeiten und Kategorientrennschärfen (nach anpassbaren Kriterien) und berichtet diese.\n\n3b. Praxis: Zusatz-Funktionen in eatPrep"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#kategorientrennschärfen---berechnen",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#kategorientrennschärfen---berechnen",
    "title": "eatPrep",
    "section": "Kategorientrennschärfen - Berechnen",
    "text": "Kategorientrennschärfen - Berechnen\n\ndatRaw &lt;- automateDataPreparation(datList = inputDat, inputList = inputList, \n    readSpss = FALSE, checkData = FALSE,  mergeData = TRUE,\n    recodeData = FALSE, aggregateData = FALSE, scoreData = FALSE,\n    writeSpss = FALSE, verbose = FALSE)\ndatRec &lt;- automateDataPreparation(datList = inputDat, inputList = inputList, \n    readSpss = FALSE, checkData = FALSE,  mergeData = TRUE,\n    recodeData = TRUE, aggregateData = FALSE, scoreData = FALSE,\n    writeSpss = FALSE, verbose = FALSE)\n\npbcs   &lt;- catPbc(datRaw, datRec, idRaw = \"ID\", idRec = \"ID\",\n                 context.vars = \"hisei\", values = inputList$values,\n                 subunits = inputList$subunits)\npbcs\n&gt;     item cat   n freq   freq.rel       catPbc recodevalue subunitType\n&gt; 1    I01   1 200   27 0.13500000 -0.063232955           0           1\n&gt; 2    I01   2 200   84 0.42000000 -0.343664917           0           1\n&gt; 3    I01   3 200   35 0.17500000  0.155770249           1           1\n&gt; 4    I01   8 200   48 0.24000000  0.266128316         mir           1\n&gt; 5    I01   9 200    6 0.03000000  0.107748105         mbi           1\n&gt; 6    I02   1 200   19 0.09500000  0.132177188           1           1\n&gt; 7    I02   2 200   20 0.10000000 -0.051926292           0           1\n&gt; 8    I02   3 200   79 0.39500000 -0.205996229           0           1\n&gt; 9    I02   4 200   80 0.40000000  0.127329573           0           1\n&gt; 10   I02   9 200    2 0.01000000  0.152207590         mbi           1\n&gt; 11   I03   1 200   40 0.20000000 -0.160857919           0           1\n&gt; 12   I03   2 200   27 0.13500000  0.237117930           1           1\n&gt; 13   I03   3 200   83 0.41500000 -0.289819086           0           1\n&gt; 14   I03   8 200   49 0.24500000  0.289329609         mir           1\n&gt; 15   I03   9 200    1 0.00500000  0.023785359         mbi           1\n&gt; 16   I04   1 200   75 0.37500000 -0.387652382           0           1\n&gt; 17   I04   2 200   87 0.43500000  0.415424524           1           1\n&gt; 18   I04   3 200   38 0.19000000 -0.046592327           0           1\n&gt; 19   I05   0 200   84 0.42000000 -0.160533926           0           3\n&gt; 20   I05   1 200   71 0.35500000  0.268786591           1           3\n&gt; 21   I05   9 200   45 0.22500000 -0.118264295         mbi           3\n&gt; 22   I06   0 200   64 0.32000000 -0.057353034           0           3\n&gt; 23   I06   1 200   66 0.33000000  0.355146259           1           3\n&gt; 24   I06   9 200   70 0.35000000 -0.294023906         mbi           3\n&gt; 25   I07   1 200   19 0.09500000  0.181585888           1           1\n&gt; 26   I07   2 200   39 0.19500000 -0.048018612           0           1\n&gt; 27   I07   3 200   73 0.36500000  0.251073049           0           1\n&gt; 28   I07   4 200   16 0.08000000  0.028825332           0           1\n&gt; 29   I07   8 200   51 0.25500000 -0.379667500         mir           1\n&gt; 30   I07   9 200    2 0.01000000  0.025823402         mbi           1\n&gt; 31   I08   0 200   95 0.47500000 -0.252225049           0           3\n&gt; 32   I08   1 200  105 0.52500000  0.252225049           1           3\n&gt; 33   I09   1 200   47 0.23500000 -0.074215726           0           1\n&gt; 34   I09   2 200   51 0.25500000 -0.108418730           0           1\n&gt; 35   I09   3 200   42 0.21000000 -0.093964942           0           1\n&gt; 36   I09   4 200   57 0.28500000  0.270623274           1           1\n&gt; 37   I09   9 200    3 0.01500000 -0.042513823         mbi           1\n&gt; 38   I10   1 200   50 0.25000000 -0.104673710           0           1\n&gt; 39   I10   2 200   52 0.26000000  0.301910231           1           1\n&gt; 40   I10   3 200   48 0.24000000 -0.109540598           0           1\n&gt; 41   I10   4 200   48 0.24000000 -0.089923339           0           1\n&gt; 42   I10   9 200    2 0.01000000 -0.019250867         mbi           1\n&gt; 43   I11   1 200   51 0.25500000 -0.057103471           0           1\n&gt; 44   I11   2 200   56 0.28000000 -0.085129296           0           1\n&gt; 45   I11   3 200   42 0.21000000  0.289059924           1           1\n&gt; 46   I11   4 200   47 0.23500000 -0.098430636           0           1\n&gt; 47   I11   9 200    4 0.02000000 -0.092070476         mbi           1\n&gt; 48  I12a   0 200   81 0.40500000 -0.377460800           0           3\n&gt; 49  I12a   1 200  115 0.57500000  0.360817945           1           3\n&gt; 50  I12a   9 200    4 0.02000000  0.049461993         mbi           3\n&gt; 51  I12b   0 200   97 0.48500000 -0.175548250           0           3\n&gt; 52  I12b   1 200   96 0.48000000  0.183183281           1           3\n&gt; 53  I12b   9 200    7 0.03500000 -0.020588340         mbi           3\n&gt; 54  I12c   1 200   22 0.11000000 -0.002560038           0           1\n&gt; 55  I12c   2 200   34 0.17000000  0.002990612           0           1\n&gt; 56  I12c   3 200   22 0.11000000  0.026479006           0           1\n&gt; 57  I12c   4 200  118 0.59000000  0.002977254           1           1\n&gt; 58  I12c   9 200    4 0.02000000 -0.071940609         mbi           1\n&gt; 59   I13   1 200   33 0.16500000 -0.027874396           0           1\n&gt; 60   I13   2 200   38 0.19000000  0.191722148           1           1\n&gt; 61   I13   3 200   25 0.12500000 -0.113940947           0           1\n&gt; 62   I13   4 200   92 0.46000000  0.007694984           0           1\n&gt; 63   I13   9 200   12 0.06000000 -0.130613859         mbi           1\n&gt; 64   I14   1 200   25 0.12500000 -0.055947188           0           1\n&gt; 65   I14   2 200   23 0.11500000 -0.055042918           0           1\n&gt; 66   I14   3 200   69 0.34500000 -0.005842116           0           1\n&gt; 67   I14   4 200   24 0.12000000  0.065389131           0           1\n&gt; 68   I14   5 200   23 0.11500000  0.038993154           0           1\n&gt; 69   I14   6 200    0 0.00000000           NA           1           1\n&gt; 70   I14   7 200    0 0.00000000           NA           0           1\n&gt; 71   I14   9 200   36 0.18000000  0.013408102         mbi           1\n&gt; 72   I15   1 299   60 0.20066890  0.148165571           1           1\n&gt; 73   I15   2 299   34 0.11371237 -0.031673606           0           1\n&gt; 74   I15   3 299   99 0.33110368  0.040042720           0           1\n&gt; 75   I15   4 299   46 0.15384615 -0.039930537           0           1\n&gt; 76   I15   9 299   60 0.20066890 -0.134139071         mbi           1\n&gt; 77   I16   1 299   41 0.13712375 -0.140413534           0           1\n&gt; 78   I16   2 299   42 0.14046823 -0.069670830           0           1\n&gt; 79   I16   3 299   87 0.29096990 -0.110210224           0           1\n&gt; 80   I16   4 299   48 0.16053512  0.138153062           1           1\n&gt; 81   I16   8 299   50 0.16722408  0.077959773         mir           1\n&gt; 82   I16   9 299   31 0.10367893  0.140260350         mbi           1\n&gt; 83   I17   1 299   55 0.18394649  0.056927815           0           1\n&gt; 84   I17   2 299   38 0.12709030  0.125919235           1           1\n&gt; 85   I17   3 299   88 0.29431438  0.034146364           0           1\n&gt; 86   I17   4 299   87 0.29096990 -0.283689189           0           1\n&gt; 87   I17   9 299   31 0.10367893  0.161709601         mbi           1\n&gt; 88   I18   1 299   44 0.14715719  0.107933501           1           1\n&gt; 89   I18   2 299   36 0.12040134 -0.049314330           0           1\n&gt; 90   I18   3 299   46 0.15384615 -0.072949177           0           1\n&gt; 91   I18   4 299  138 0.46153846 -0.113108105           0           1\n&gt; 92   I18   9 299   35 0.11705686  0.188244072         mbi           1\n&gt; 93   I19   1 299   50 0.16722408 -0.024898457           0           1\n&gt; 94   I19   2 299   40 0.13377926 -0.057560331           0           1\n&gt; 95   I19   3 299   41 0.13712375 -0.119477020           0           1\n&gt; 96   I19   4 299   39 0.13043478  0.157842457           1           1\n&gt; 97   I19   9 299  129 0.43143813  0.033970884         mbi           1\n&gt; 98   I20   1 299   25 0.08361204 -0.017281536           0           1\n&gt; 99   I20   2 299   98 0.32775920  0.211463845           1           1\n&gt; 100  I20   3 299   74 0.24749164 -0.336332944           0           1\n&gt; 101  I20   4 299   27 0.09030100 -0.031893614           0           1\n&gt; 102  I20   9 299   75 0.25083612  0.137972775         mbi           1\n&gt; 103  I21   1 299   35 0.11705686 -0.057356034           0           1\n&gt; 104  I21   2 299   99 0.33110368 -0.122486964           0           1\n&gt; 105  I21   3 299   38 0.12709030  0.129346339           1           1\n&gt; 106  I21   4 299   42 0.14046823 -0.097293263           0           1\n&gt; 107  I21   9 299   85 0.28428094  0.148108941         mbi           1\n&gt; 108  I22   1 199   21 0.10552764  0.203181896           1           1\n&gt; 109  I22   2 199   21 0.10552764 -0.102561126           0           1\n&gt; 110  I22   3 199   70 0.35175879  0.142451132           0           1\n&gt; 111  I22   4 199   65 0.32663317 -0.127297485           0           1\n&gt; 112  I22   9 199   22 0.11055276 -0.125126539         mbi           1\n&gt; 113  I23   1 199   66 0.33165829  0.062867843           1           1\n&gt; 114  I23   2 199    9 0.04522613  0.001841798           0           1\n&gt; 115  I23   3 199   24 0.12060302 -0.074686626           0           1\n&gt; 116  I23   4 199   26 0.13065327 -0.245502028           0           1\n&gt; 117  I23   9 199   74 0.37185930  0.159487857         mbi           1\n&gt; 118  I24   1 199   99 0.49748744  0.215084724           0           1\n&gt; 119  I24   2 199   18 0.09045226 -0.123842852           1           1\n&gt; 120  I24   3 199   24 0.12060302 -0.103496094           0           1\n&gt; 121  I24   4 199   19 0.09547739 -0.050262541           0           1\n&gt; 122  I24   9 199   39 0.19597990 -0.059310341         mbi           1\n&gt; 123  I25   0 199   39 0.19597990 -0.141672687           0           3\n&gt; 124  I25   1 199  102 0.51256281  0.273449060           1           3\n&gt; 125  I25   9 199   58 0.29145729 -0.177020237         mbi           3\n&gt; 126  I26   0 199   39 0.19597990 -0.163860787           0           3\n&gt; 127  I26   1 199   51 0.25628141  0.162189524           1           3\n&gt; 128  I26   9 199  109 0.54773869 -0.011579889         mbi           3\n&gt; 129  I27   0 199   54 0.27135678 -0.102379789           0           3\n&gt; 130  I27   1 199   42 0.21105528  0.238689431           1           3\n&gt; 131  I27   9 199  103 0.51758794 -0.103813945         mbi           3\n&gt; 132  I28   0 199   35 0.17587940 -0.107657030           0           3\n&gt; 133  I28   1 199   73 0.36683417  0.283901197           1           3\n&gt; 134  I28   8 199   31 0.15577889 -0.033997058         mir           3\n&gt; 135  I28   9 199   60 0.30150754 -0.181968752         mbi           3\n\n\n3b. Praxis: Zusatz-Funktionen in eatPrep"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#kategorientrennschärfen---evaluieren",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#kategorientrennschärfen---evaluieren",
    "title": "eatPrep",
    "section": "Kategorientrennschärfen - Evaluieren",
    "text": "Kategorientrennschärfen - Evaluieren\n\nepbcs   &lt;- evalPbc(pbcs)\n&gt; ✖ The attractors (score 1) of the following 1 item were chosen with a frequency\n&gt; of zero: I14. This should not happen. Please check.\n&gt; ! The distractors (score 0) of the following 1 item were chosen with a\n&gt; frequency of zero: I14_7. This may happen, but is probably not intended.\n&gt; ✖ catPbcs for attractors (score 1) of the following 3 items are worrisome low (&lt; 0.05) or missing: I12c:_0, I14:_NA, and I24:_-0.12\n&gt; ✖ catPbcs for distractors (score 0) of the following 9 items are unexpectedly high (&gt; 0.005): I02_4_0.13, I07_3_0.25, I07_4_0.03, I12c_3_0.03, I13_4_0.01, I14_4_0.07, I14_5_0.04, I15_3_0.04, I17_1_0.06, I17_3_0.03, I22_3_0.14, and I24_1_0.22\n&gt; ! catPbcs for mistype 'mir' of the following 3 items are relatively high (&gt;\n&gt; 0.07): I01_8_0.27, I03_8_0.29, and I16_8_0.08\n&gt; ! catPbcs for mistype 'mbi' of the following 8 items are relatively high (&gt;\n&gt; 0.07): I01_9_0.11, I02_9_0.15, I16_9_0.14, I17_9_0.16, I18_9_0.19, I20_9_0.14,\n&gt; I21_9_0.15, and I23_9_0.16\n&gt; ℹ For a list of problematic items, save the `output` of this function and\n&gt; return the item names as a vector:\n&gt; • `output$zeroFreqAtt`\n&gt; • `output$zeroFreqDis`\n&gt; • `output$lowMisPbcAtt`\n&gt; • `output$highPbcDis`\n&gt; • `output$highPbcMis$mir`\n&gt; • `output$highPbcMis$mbi`\n\n\n3b. Praxis: Zusatz-Funktionen in eatPrep"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#testsitzungsprotokolle",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#testsitzungsprotokolle",
    "title": "eatPrep",
    "section": "Testsitzungsprotokolle",
    "text": "Testsitzungsprotokolle\n…werden oft außerhalb von eatPrep behandelt und Änderungen am Datensatz projektintern dokumentiert. Manchmal besteht jedoch das Bedürfnis, die von den Testleiter:innen geflaggten Teildaten visuell zu inspizieren, ggf. zu rekodieren und dieses zu dokumentieren.\nvisualSubsetRecode() - erlaubt dokumentiertes Ansehen (+ggf. Rekodieren) von einzelnen Testteilen für einzelne Personen oder ganze Testgruppen.\n\n3b. Praxis: Zusatz-Funktionen in eatPrep"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#testsitzungsprotokolle-beispiel",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#testsitzungsprotokolle-beispiel",
    "title": "eatPrep",
    "section": "Testsitzungsprotokolle – Beispiel",
    "text": "Testsitzungsprotokolle – Beispiel\n\nsubsetInfoMax &lt;- data.frame(\n                  ID=c(\"person100\", \"person101\", \"person102\", \"person103\",\n                        \"person104\", \"person105\", \"person106\", \"person107\",\n                        \"person108\", \"person109\", \"person110\"),\n                   IDgroup=c(1,1,1,1,1,2,2,2,2,2,2),\n                   datCols=c(\"I01\", \"I02\", \"I03\", \"I01\", \"I02\", \"I03\",\n                                   \"I04\", \"I05\", \"I02\", \"I03\", \"I04\"),\n                   comment=c(rep(\"Es gab Feueralarm\",5), \n                             rep(\"Der klassenraum musste gewechselt werden, \n                                 wir hatten keine Zeit mehr.\",6)))\n\ndatVisRec &lt;- visualSubsetRecode(dat=preparedData, subsetInfo=subsetInfoMax, ID=\"ID\",\n                                 toRecodeVal=\"mci\", useGroups=\"IDgroup\") \n&gt; \n&gt; ── Begin visual Inspection 2025-02-10 13:07:53.516728 ──────────────────────────\n&gt; \n&gt; ── Display subset (1 of 2)\n&gt; → group 1\n&gt; → 5 cases: person100, person101, person102, person103, and person104\n&gt; → 3 variables: I01, I02, and I03\n&gt; \n&gt; subgroup 1 :\n&gt;          ID I01 I02 I03\n&gt; 1 person100   0   0   0\n&gt; 2 person101 mbi   0   1\n&gt; 3 person102   1   0   1\n&gt; 4 person103   0   0   0\n&gt; 5 person104   1   0   0\n&gt; \n&gt; → Table of Values and NAs:\n&gt; \n&gt;   0   1 mbi \n&gt;  10   4   1\n&gt; \n&gt; ℹ Do you want to recode this subset to 'mci'?\n&gt; Error in menu(choices1): menu() cannot be used non-interactively"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#beurteilerübereinstimmung",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#beurteilerübereinstimmung",
    "title": "eatPrep",
    "section": "Beurteilerübereinstimmung",
    "text": "Beurteilerübereinstimmung\nIn Koderschulung und für Technischen Bericht benötigt:\n\nWie gut stimmen Bewertende bei der Beurteilung der offenen Items überein?\n\nmeanAgree() - prozentuale Übereinstimmung\nmeanKappa() - Cohen’s Kappa für alle Beurteilerpaare eines Items, und Mittelung der Werte (gewichtet)\n\nBeide Funktionen operieren itemweise. Möchte man mehrere Items behandeln, braucht es Schleifen.\n\n\n3b. Praxis: Zusatz-Funktionen in eatPrep"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#beurteilerübereinstimmung-1",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#beurteilerübereinstimmung-1",
    "title": "eatPrep",
    "section": "Beurteilerübereinstimmung",
    "text": "Beurteilerübereinstimmung\n\ndata(rater)\ndat &lt;- reshape2::dcast(subset(rater, variable == \"V01\"), id~rater, value.var = \"value\")\nmeanAgree(dat[,-1])\n&gt; $agree.pairwise\n&gt;    Coder1  Coder2  N agree\n&gt; 1   Carol Dolores 50  0.98\n&gt; 2   Carol  Edward 50  0.98\n&gt; 3   Carol    John 50  0.98\n&gt; 4 Dolores  Edward 50  0.96\n&gt; 5 Dolores    John 50  1.00\n&gt; 6  Edward    John 50  1.00\n&gt; \n&gt; $meanagree\n&gt; [1] 0.9833333\nmeanKappa(dat[,-1])\n&gt; $agree.pairwise\n&gt;    Coder1  Coder2  N     kappa\n&gt; 1   Carol Dolores 50 0.9690977\n&gt; 2   Carol  Edward 50 0.9652053\n&gt; 3   Carol    John 50 0.9651811\n&gt; 4 Dolores  Edward 50 0.9402628\n&gt; 5 Dolores    John 50 1.0000000\n&gt; 6  Edward    John 50 1.0000000\n&gt; \n&gt; $meankappa\n&gt; [1] 0.9732911\n\n\n3b. Praxis: Zusatz-Funktionen in eatPrep"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#übung-2-1",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#übung-2-1",
    "title": "eatPrep",
    "section": "Übung 2",
    "text": "Übung 2\n\nBerechnet und evaluiert die Kategorientrennschärfen auf Basis der in Übung 1 eingelesenen und aufbereiteten SPSS-Daten (booklet1.sav, booklet2.sav, booklet3.sav).\nGeht manuell das erste Beispiel der Testsitzungsprotokoll-Funktion visualSubsetRecode() durch.\nBerechnet die Beurteilerübereinstimmung für die Variablen v02 und v03 aus dem Datensatz “rater”.\n\n\n3b. Praxis: Zusatz-Funktionen in eatPrep"
  },
  {
    "objectID": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#ende",
    "href": "docs/R_tutorials/eatPrep2024_files/eatPrep2024.html#ende",
    "title": "eatPrep",
    "section": "Ende",
    "text": "Ende\nBitte berichtet alle\n\nBugs\nFeature Requests\nsonstige Fragen/Probleme\n\neatPrep betreffend an karoline.sachse@iqb.hu-berlin.de\n\n\nAusblick"
  },
  {
    "objectID": "posts/newsletter/23_08_09/index.html",
    "href": "posts/newsletter/23_08_09/index.html",
    "title": "09-08-2023",
    "section": "",
    "text": "eatGADS\nDie Funktion insertVariable() wurde in relocateVariable() umbenannt. Die Funktion erlaubt die Einsortierung einer Variable innerhalb eines GADSdat-Ojekts, nun auch ganz an den Anfang eines Datensatzes.\nEine neue Funktion, recodeNA2missing(), erlaubt es NAs (in SPSS auch Sysmis genannt) automatisch in spezifische Missing Codes umzuwandeln (z.B. -99 = \"Missing By Design\").\nDie Funktion emptyTheseVariables() erlaubt es nun, mehrere Variablen gleichzeitig zu leeren (= auf NA zu setzen), was z.B. aus Datenschutzgründen relevant sein kann.\nBesonders hervoheben möchten wir an dieser Stelle noch die Funktion fixEncoding(), die es erlaubt, automatisch Umlaute und Sonderzeichen aus Variablennamen, Variablen- und Wertelabeln, sowie Variablen an sich zu entfernen (z.B. “ü” wird zu “ue”).\nDie Dokumentation des Pakets ist nun übrigens leicht einsehbar hier zu finden.\nAlle Änderungen finden sich wie immer erst einmal in der Github-Version des Pakets."
  },
  {
    "objectID": "posts/newsletter/24_01_12/index.html",
    "href": "posts/newsletter/24_01_12/index.html",
    "title": "12-01-2024",
    "section": "",
    "text": "1"
  },
  {
    "objectID": "posts/newsletter/24_01_12/index.html#footnotes",
    "href": "posts/newsletter/24_01_12/index.html#footnotes",
    "title": "12-01-2024",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Giulia May on Unsplash.↩︎"
  },
  {
    "objectID": "posts_help.html",
    "href": "posts_help.html",
    "title": "Help",
    "section": "",
    "text": "eatAnalysiseatATAeatCodebookeatFDZeatGADSeatModeleatPloteatPrepeatRecodeeatRepeatTools\n\n\n\n\n\nContact\nEmail\n\n\n\n\nBenjamin Becker\nb.becker[at]iqb.hu-berlin.de\n\n\nSebastian Weirich\nsebastian.weirich[at]iqb.hu-berlin.de\n\n\nKaroline Sachse\nkaroline.sachse[at]iqb.hu-berlin.de\n\n\n\n\n\n\n\n\nContact\nEmail\n\n\n\n\nBenjamin Becker\nb.becker[at]iqb.hu-berlin.de\n\n\n\n\n\n\n\n\nContact\nEmail\n\n\n\n\nBenjamin Becker\nb.becker[at]iqb.hu-berlin.de\n\n\n\n\n\n\n\n\nContact\nEmail\n\n\n\n\nBenjamin Becker\nb.becker[at]iqb.hu-berlin.de\n\n\n\n\n\n\n\n\nContact\nEmail\n\n\n\n\nBenjamin Becker\nb.becker[at]iqb.hu-berlin.de\n\n\n\n\n\n\n\n\nContact\nEmail\n\n\n\n\nSebastian Weirich\nsebastian.weirich[at]iqb.hu-berlin.de\n\n\n\n\n\n\n\n\nContact\nEmail\n\n\n\n\nNicklas Hafiz\nnicklas.jakob.hafiz[at]hu-berlin.de\n\n\nPhilipp Franikowski\nphilipp.franikowski[at]iqb.hu-berlin.de\n\n\n\n\n\n\n\n\nContact\nEmail\n\n\n\n\nKaroline Sachse\nkaroline.sachse[at]iqb.hu-berlin.de\n\n\n\n\n\n\n\n\nContact\nEmail\n\n\n\n\nBenjamin Becker\nb.becker[at]iqb.hu-berlin.de\n\n\nNicklas Hafiz\nnicklas.jakob.hafiz[at]hu-berlin.de\n\n\n\n\n\n\n\n\nContact\nEmail\n\n\n\n\nSebastian Weirich\nsebastian.weirich[at]iqb.hu-berlin.de\n\n\nBenjamin Becker\nb.becker[at]iqb.hu-berlin.de\n\n\n\n\n\n\n\n\nContact\nEmail\n\n\n\n\nSebastian Weirich\nsebastian.weirich[at]iqb.hu-berlin.de\n\n\nBenjamin Becker\nb.becker[at]iqb.hu-berlin.de\n\n\nKaroline Sachse\nkaroline.sachse[at]iqb.hu-berlin.de"
  },
  {
    "objectID": "posts_help.html#contact-for-eat-packages",
    "href": "posts_help.html#contact-for-eat-packages",
    "title": "Help",
    "section": "",
    "text": "eatAnalysiseatATAeatCodebookeatFDZeatGADSeatModeleatPloteatPrepeatRecodeeatRepeatTools\n\n\n\n\n\nContact\nEmail\n\n\n\n\nBenjamin Becker\nb.becker[at]iqb.hu-berlin.de\n\n\nSebastian Weirich\nsebastian.weirich[at]iqb.hu-berlin.de\n\n\nKaroline Sachse\nkaroline.sachse[at]iqb.hu-berlin.de\n\n\n\n\n\n\n\n\nContact\nEmail\n\n\n\n\nBenjamin Becker\nb.becker[at]iqb.hu-berlin.de\n\n\n\n\n\n\n\n\nContact\nEmail\n\n\n\n\nBenjamin Becker\nb.becker[at]iqb.hu-berlin.de\n\n\n\n\n\n\n\n\nContact\nEmail\n\n\n\n\nBenjamin Becker\nb.becker[at]iqb.hu-berlin.de\n\n\n\n\n\n\n\n\nContact\nEmail\n\n\n\n\nBenjamin Becker\nb.becker[at]iqb.hu-berlin.de\n\n\n\n\n\n\n\n\nContact\nEmail\n\n\n\n\nSebastian Weirich\nsebastian.weirich[at]iqb.hu-berlin.de\n\n\n\n\n\n\n\n\nContact\nEmail\n\n\n\n\nNicklas Hafiz\nnicklas.jakob.hafiz[at]hu-berlin.de\n\n\nPhilipp Franikowski\nphilipp.franikowski[at]iqb.hu-berlin.de\n\n\n\n\n\n\n\n\nContact\nEmail\n\n\n\n\nKaroline Sachse\nkaroline.sachse[at]iqb.hu-berlin.de\n\n\n\n\n\n\n\n\nContact\nEmail\n\n\n\n\nBenjamin Becker\nb.becker[at]iqb.hu-berlin.de\n\n\nNicklas Hafiz\nnicklas.jakob.hafiz[at]hu-berlin.de\n\n\n\n\n\n\n\n\nContact\nEmail\n\n\n\n\nSebastian Weirich\nsebastian.weirich[at]iqb.hu-berlin.de\n\n\nBenjamin Becker\nb.becker[at]iqb.hu-berlin.de\n\n\n\n\n\n\n\n\nContact\nEmail\n\n\n\n\nSebastian Weirich\nsebastian.weirich[at]iqb.hu-berlin.de\n\n\nBenjamin Becker\nb.becker[at]iqb.hu-berlin.de\n\n\nKaroline Sachse\nkaroline.sachse[at]iqb.hu-berlin.de"
  },
  {
    "objectID": "posts_eat.html",
    "href": "posts_eat.html",
    "title": "eat Packages",
    "section": "",
    "text": "Various useful help functions, such as saving Excel files, saving analysis results from lm4 and simulating IRT responses.\n\n\n\n\n\nBenjamin Becker, Sebastian Weirich, Karoline Sachse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutomated block occupation/automated test booklet creation.\n\n\n\n\n\nBenjamin Becker\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutomated creation of scale manuals.\n\n\n\n\n\nBenjamin Becker\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAutomated anonymisation of data sets, matching of pdf documents (e.g. scale manuals) and data sets.\n\n\n\n\n\nBenjamin Becker\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAllows import and data preparation of SPSS data sets in R. Generates the General Analysis Data Set (GADS) for IQB Bildungstrend studies as a SQLite3 database. Parts of the data set can then be loaded into R using the package. It also allows the export of SPSS files to and from R.\n\n\n\n\n\nBenjamin Becker\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nServes as an interface for the ConQuest software. The required control files (script, labels, data set in ‘fixed width’ format) are automatically generated and ConQuest is called via the command line. The resulting files (showfile, WLEs, PVs, etc.) can be imported back into R and edited further. Newer versions of ‘eatModel’ also allow the integration of the R package ‘tam’ and parallelisation.\n\n\n\n\n\nSebastian Weirich\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreating plots from the eatRep output (main use: Bildungstrend).\n\n\n\n\n\nNicklas Hafiz\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreparation of test item data for IRT scaling using metadata provided by a predefined list structure as well as several tools and checks. Raw data can be read in and will be subjected to plausibility checks. Multiple data sets can be merged in a single step, incorporating detailed diagnostics for non-identical values among identical cases and variables. Data will be recoded according to the provided meta data, aggregated and scored. Handling different types of missing data is customizable according to user specifications. Further, missing patterns can be checked, various rater agreement measures and category discriminations can be calculated. The input metadata can be generated by the IQB-internal tool ‘AnalyseInput’, which extracts item and test design information from the IQB database and formats it into a standardized xlsx file. This file can then be read by functions specifically designed for this task. Alternatively, the metadata can be provided in R-specific data formats.\n\n\n\n\n\nKaroline Sachse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreate and apply recoding databases.\n\n\n\n\n\nBenjamin Becker, Nicklas Hafiz\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCalculates means, standard deviations, variances, frequency tables, percentiles and linear (logistic) regressions, as well as trends for all these analyses in clustered multilevel structures with imputed data. The package implements part of the functionality of the WesVar computer software in R and is mainly relevant for the IQB Bildungstrend studies.\n\n\n\n\n\nSebastian Weirich, Benjamin Becker\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVarious help functions that are also required by the packages ‘eatPrep’, ‘eatModel’, ‘eatGADS’ and ‘eatRep’, among others.\n\n\n\n\n\nSebastian Weirich, Benjamin Becker, Karoline Sachse\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts_eat.html#installing-r-packages",
    "href": "posts_eat.html#installing-r-packages",
    "title": "eat Packages",
    "section": "Installing R packages",
    "text": "Installing R packages\nDetailed instructions for installing the R packages can be found here: installing R packages"
  },
  {
    "objectID": "posts_eat.html#compatibility",
    "href": "posts_eat.html#compatibility",
    "title": "eat Packages",
    "section": "Compatibility",
    "text": "Compatibility\nMost packages of the “eat” family are not executable in isolation, which means that a package is usually dependent on another package in order to be executable. This means:\n\n“eatTools” is a package with help functions required by other packages. “eatTools” does not depend on other “eat” packages.\n“eatPrep” requires “eatTools”.\n“eatRep” needs “eatTools” and “eatGADS”.\n“eatModel” requires “eatTools” and “eatRep” (and thus also “eatGADS”). The package optionally accesses the computer programme Conquest or the R package “TAM” for parameter estimation. For Conquest, the command line executable is sufficient, e.g. “console_Feb2007.exe”; “TAM” is installed when the package is loaded. “TAM” and Conquest are based on the same statistical measurement model, and overlap considerably in their range of functions.\n“eatGADS” requires “eatTools” and “eatDB”.\n\nThe interdependence also extends to different versions of the packages. For example, old versions of “eatRep” are not always compatible with new versions of “eatTools” (and vice versa). The current package versions (see table above) should be compatible with each other. Usually (but not always) version conflicts are indicated by an error message. It is recommended to always have the latest package versions installed.\nSince individual functions have also changed substantially in the course of the package development, it may no longer be possible to replicate past analyses with new package versions and the identical script (e.g. from the Ländervergleich 2011). In this case, the old script would either have to be adapted or the package versions used at that time would have to be restored."
  },
  {
    "objectID": "posts_learn.html",
    "href": "posts_learn.html",
    "title": "Welcome to our Learning Page",
    "section": "",
    "text": "Here you can find articles and workshops about R, RStudio, Git and GitHub, quarto and overall information about some statistical questions. Click on the topic you’re interested in to get to the article’s overview.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeginners\n\n\nHere you can find R tutorials to start your R journey.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWorkflow\n\n\nHere you can find articles about the general workflow when working with RStudio or Github.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR-SIG\n\n\nHere you can find all the articles that were discussed in R-SIG.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStatistical Questions\n\n\nHere you can find some answers to common questions about statistics or our r-packages.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvanced\n\n\nHere you can find some more advanced R tutorials.\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IQB Methods Team",
    "section": "",
    "text": "This website hosts all kind of material around R, programming, statistics and psychological methods."
  },
  {
    "objectID": "posts/newsletter/24_08_26/index.html",
    "href": "posts/newsletter/24_08_26/index.html",
    "title": "26-08-2024",
    "section": "",
    "text": "Liebe IQBler:innen,\nhier der Methoden-Newsletter für die letzten Monate, in dem wir kurz Neuerungen in den R-Paketen der eat-Reihe vorstellen, Updates zu Gruppen und Workshops geben und über sonstige methodische Entscheidungen am Institut informieren."
  },
  {
    "objectID": "posts/newsletter/24_08_26/index.html#eatpreptba-eatautocode",
    "href": "posts/newsletter/24_08_26/index.html#eatpreptba-eatautocode",
    "title": "26-08-2024",
    "section": "eatPrepTBA & eatAutoCode",
    "text": "eatPrepTBA & eatAutoCode\neatPrepTBA zur Aufbereitung von Daten aus dem IQB-TestCenter und eatAutoCode zur Kodierung von KA1&2-Aufgaben im TBA-Kontext werden derzeit entwickelt. Eine ausführlichere Vorstellung der Pakete erfolgt nach dem ersten Release."
  },
  {
    "objectID": "posts/newsletter/24_08_26/index.html#eatprep",
    "href": "posts/newsletter/24_08_26/index.html#eatprep",
    "title": "26-08-2024",
    "section": "eatPrep",
    "text": "eatPrep\nmbo-Kompatibilität: Das Handling der neuen Missings, “mbo” https://iqb-berlin.github.io/coding-info/data-structures/missings.html, die perspektivisch die alten, “mbi”, ersetzen, ist jetzt in eatPrep möglich. Dabei ist die Änderung von “mbi” zu “mbo” lediglich eine Namensänderung. Diese wurde eingeführt, damit direkt aus dem Label heraus klar ersichtlich wird, was gemeint ist; inhaltlich ändert sich nichts und “mbi” kann (wie im Paper&Pencil-Format üblich) auch weiterverwendet werden.\nZwischen Juli und August gab es einen Bug in mergeData(): Wenn mehr als zwei Datensätze in einer Liste gemergt wurden, wurde “mbd” gleichrangig mit validen Codes behandelt und überschrieb diese ggf., was aber auch in den zugehörigen Messages reported wurde (d. h. es ist hoffentlich immer aufgefallen). Der Bug ist nun behoben. Bitte achtet darauf, dass ihr eatPrep ab Version 1.0.1 benutzt.\nFeature Request für checkDesign()-Output: Redundanzen wurden gekürzt; der Output von checkDesign() ist jetzt hoffentlich besser lesbar, wenn es viele Abweichungen im Datensatz vom Testdesign gibt.\nDie Funktion prep2GADS() kann nun sowohl rohe als auch gescorte Itemdatensätze inklusive aller Meta-Daten aus der IQB-DB in das GADSdat-Format exportieren. Für alle, die schon immer ihre Itemdatensätze inklusive der Meta-Daten (z. B. Labels der Auswahlantworten) archivieren wollten.\nWenn addLeadingZeros=TRUE gesetzt wurde, gab es bei ID-Variablen mit vielen Stellen in readSpss() oder automateDataPreparation() ein Problem. Dieses wurde in eatTools durch Überarbeitung der Funktion addLeadingZerosToCharInt() behoben."
  },
  {
    "objectID": "posts/newsletter/24_08_26/index.html#eattools",
    "href": "posts/newsletter/24_08_26/index.html#eattools",
    "title": "26-08-2024",
    "section": "eatTools",
    "text": "eatTools\nBug in addLeadingZerosToCharInt(): Bei großen Zahlen mit über 10 Stellen kam es zum Abbruch der Funktion. Dies ist nun behoben."
  },
  {
    "objectID": "posts/newsletter/24_08_26/index.html#workshops",
    "href": "posts/newsletter/24_08_26/index.html#workshops",
    "title": "26-08-2024",
    "section": "Workshops",
    "text": "Workshops\nGeplant sind je ein Workshop zu:\neatPrep\neatModel\nGithub allgemein\nBei Interesse tragt euch gerne in folgende Liste ein:\nt:\\ ein t:\\SIG\\SIG Methoden\\Workshops\\InteresseWorkshops.xlsx\nDanach doodeln wir Termine mit allen Interessierten."
  },
  {
    "objectID": "posts/newsletter/24_08_26/index.html#r-sig",
    "href": "posts/newsletter/24_08_26/index.html#r-sig",
    "title": "26-08-2024",
    "section": "R-SIG",
    "text": "R-SIG\nSchaut gerne auf der Methoden-Seite vorbei, wenn ihr einen Überblick über vergangene und zukünftige Themen bekommen wollt:\nhttps://iqb-research.github.io/IQB-Methods/posts_r_sig.html\nMitgebrachte R-Probleme können aber auch weiterhin besprochen werden. Meldet euch gerne bei Nicklas, wenn er euch hinzufügen soll."
  },
  {
    "objectID": "posts/newsletter/24_08_26/index.html#sig-methoden",
    "href": "posts/newsletter/24_08_26/index.html#sig-methoden",
    "title": "26-08-2024",
    "section": "SIG Methoden",
    "text": "SIG Methoden\n\nLesegruppe\nDie Lesegruppe war in der Sommerpause. Am 10. September treffen wir uns wieder zur Besprechung von:\nSchroeders, U., & Gnambs, T. (2024, July 24). Sample Size Planning in Item Response Theory: A Tutorial. https://doi.org/10.31234/osf.io/hv6zt\nInteressierte sind herzlich willkommen! Meldet euch gerne bei Karoline, wenn sie euch hinzufügen soll.\n\n\nAustauschrunde\nDie Liste für methodische Fragen am IQB ist daueroffen; tragt Fragen gerne anonym und unkompliziert in folgendes Dokument ein:\nt:\\SIG\\SIG Methoden\\Liste methodischer Fragen.docx\nViele Grüße\nEuer Methoden-Team (Sebastian, Karoline, Benjamin, Philipp, Kristoph, Janine, Edna, Alina, Nicklas)"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#automatisierte-blockbesetzung",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#automatisierte-blockbesetzung",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Automatisierte Blockbesetzung",
    "text": "Automatisierte Blockbesetzung\nBlockbesetzung\nZuordnung von Items zu Blöcken aus einem Itempool unter Berücksichtigung von Testspezifikationen\nAutomatisiert\nNicht händisch, sondern unter Verwendung von Optimierungsalgorithmen"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#vorstellungsrunde",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#vorstellungsrunde",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Vorstellungsrunde",
    "text": "Vorstellungsrunde\n30 Sekunden pro Person:\n\nName\nProjekt\nHabt ihr schon mal selbst eine Blockbesetzung umgesetzt?\nWenn ja, händisch oder mit eatATA?"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#agenda",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#agenda",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Agenda",
    "text": "Agenda\n\nHintergrund: Wofür?\nGrundlagen: Mathematical Programming\nTheorie: Automated Test Assembly/Automatisierte Blockbesetzung\nPraxis: eatATA"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#begrifflichkeiten",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#begrifflichkeiten",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Begrifflichkeiten",
    "text": "Begrifflichkeiten\n\nItem\n→ Eine Frage (kleinste Einheit)\nAufgabe/Unit\n→ Set von Items mit gemeinsamem Stimulus\nBlock/Cluster\n→ Zusammenstellung von Aufgaben, meist als fixer Kontext, ca. 20 Minuten\nTestform/Testheft\n→ Zusammenstellung von Blöcken, eine Person bearbeitet eine Testform"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#parallele-testformen",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#parallele-testformen",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Parallele Testformen",
    "text": "Parallele Testformen\nWieso?\n\nLow-stakes Assessments\n→ Breite inhaltliche Abdeckung\n→ Messgenauigkeit auf Gruppenebene\nHigh-stakes Assessments\n→ Abschreiben/Betrugsversuche verhindern\n→ Weitergabe Testinhalte verhindern\nPilotierungen\n→ Testung großer Itemzahlen"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#block-vs.-testform",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#block-vs.-testform",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Block vs. Testform",
    "text": "Block vs. Testform\nAnforderungen Blockbesetzung\n\nParallelität (inhaltlich, Formate, …)\n\nAnforderungen Testformen\n\nParallelität\nLinking"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#parallele-blöcke",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#parallele-blöcke",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Parallele Blöcke",
    "text": "Parallele Blöcke\nHinsichtlich?\n\nInhaltliche Bereiche\nAufgabenformate\nSchwierigkeit/Testinformation\nZeitaufwand/Speededness\n…\n\nzusätzlich\n\nItemunverträglichkeiten"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#blockbesetzung",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#blockbesetzung",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Blockbesetzung",
    "text": "Blockbesetzung\nHäufig händisch (via Excel), aber:\n\nviele Items\nviele Constraints\n→ z.B. viele Unverträglichkeiten\nhoher Aufwand/kognitiver Load!"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#definition",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#definition",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Definition",
    "text": "Definition\nSynonyme\n\nMathematical Optimization/Mathematical Programming\n\nRelevante Subklasse\n\nMixed Integer (Linear) Programming (MIP/MILP)\n\nGrundidee:\nMaximierungs- oder Minimierungsproblem, wobei Lösungsraum durch (Ung-)Gleichungen eingeschränkt werden kann"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#zentrale-konzepte",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#zentrale-konzepte",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Zentrale Konzepte",
    "text": "Zentrale Konzepte\nBranch and Bound Algorithmen\n\nGrundidee: Probieren aller möglichen Lösungen (“Brute Forcing”)\nEffiziente Reduktion des Lösungsraumes\nKombinieren von Constraints"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#zentrale-konzepte-1",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#zentrale-konzepte-1",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Zentrale Konzepte",
    "text": "Zentrale Konzepte\n\nDecision Variables\nConstraints\nObjective Function"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#beispiel-variiertes-rucksackproblem",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#beispiel-variiertes-rucksackproblem",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Beispiel: Variiertes Rucksackproblem",
    "text": "Beispiel: Variiertes Rucksackproblem\n\nAnstellungsoptionen StuMis, Docs, Postdocs\nMaximal 8 Büroplätze\nMaximale Kosten 120$: StuMis (5$), Docs (18$), Postdocs (25$)\nEs braucht von jeder Statusgruppe mindestens 2 Personen\nPublikationen: StuMis (1), Docs (2), Postdocs (3)\nAnzahl der Publikationen maximieren\n\nFrage: Welche Kombination aus Personen soll eingestellt werden?"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#beispiel-variiertes-rucksackproblem-1",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#beispiel-variiertes-rucksackproblem-1",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Beispiel: Variiertes Rucksackproblem",
    "text": "Beispiel: Variiertes Rucksackproblem\nDecision Variables:\n\nAnstellungsoptionen StuMis, Docs, Postdocs\n\nConstraints:\n\nMaximal 8 Büroplätze \\[\nS + D + P \\leq 8\n\\]\nMaximale Kosten 120$: StuMis (5$), Docs (18$), Postdocs (25$) \\[\n5S + 18D + 25P \\leq 120\n\\]"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#beispiel-variiertes-rucksackproblem-2",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#beispiel-variiertes-rucksackproblem-2",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Beispiel: Variiertes Rucksackproblem",
    "text": "Beispiel: Variiertes Rucksackproblem\nDecision Variables:\n\nAnstellungsoptionen StuMis, Docs, Postdocs\n\nConstraints:\n\nEs braucht von jeder Statusgruppe mindestens 2 Personen \\[\nS \\geq 2  \n\\] \\[\nD \\geq 2\n\\] \\[\nP \\geq 2\n\\]"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#beispiel-variiertes-rucksackproblem-3",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#beispiel-variiertes-rucksackproblem-3",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Beispiel: Variiertes Rucksackproblem",
    "text": "Beispiel: Variiertes Rucksackproblem\nDecision Variables:\n\nAnstellungsoptionen StuMis, Docs, Postdocs\n\nObjective Function:\n\nPublikationen: StuMis (1), Docs (2), Postdocs (3)\nAnzahl der Publikationen maximieren \\[\nMaximiere \\quad  1S + 2D + 3P\n\\]"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#solver",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#solver",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Solver",
    "text": "Solver\nOpen Source\n\nGLPK\nlpSolve\nSymphony\n…\n\nKommerziell\n\nGurobi\nCPLEX\n…"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#übung",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#übung",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Übung",
    "text": "Übung\n\nVersucht das vorgestellte Beispiel händisch zu lösen!"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#lösung-mithilfe-von-rglpk",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#lösung-mithilfe-von-rglpk",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Lösung mithilfe von Rglpk",
    "text": "Lösung mithilfe von Rglpk\n\n# Define objective function\nobj &lt;- c(1, 2, 3)\nmax &lt;- TRUE\n\n# Define constraints\nmat &lt;- matrix(c(1, 5, 1, 0, 0, 1, 18, 0, 1, 0, 1, 25, 0, 0, 1), nrow = 5)\ndir &lt;- c(\"&lt;=\", \"&lt;=\", \"&gt;=\", \"&gt;=\", \"&gt;=\")\nrhs &lt;- c(8, 120, 2, 2, 2)\n\n# Define problem type (MIP)\ntypes &lt;- c(\"I\", \"I\", \"I\")\n\n# Call solver\nRglpk::Rglpk_solve_LP(obj, mat, dir, rhs, \n               types = types, max = max, \n               control = list(\"verbose\" = TRUE, \"canonicalize_status\" = FALSE))"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#lösung-mithilfe-von-rglpk-1",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#lösung-mithilfe-von-rglpk-1",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Lösung mithilfe von Rglpk",
    "text": "Lösung mithilfe von Rglpk\n\n\nGLPK Simplex Optimizer 5.0\n5 rows, 3 columns, 9 non-zeros\n      0: obj =  -0.000000000e+00 inf =   6.000e+00 (3)\n      3: obj =   1.200000000e+01 inf =   0.000e+00 (0)\n*     5: obj =   1.540000000e+01 inf =   0.000e+00 (0)\nOPTIMAL LP SOLUTION FOUND\nGLPK Integer Optimizer 5.0\n5 rows, 3 columns, 9 non-zeros\n3 integer variables, none of which are binary\nInteger optimization begins...\nLong-step dual simplex will be used\n+     5: mip =     not found yet &lt;=              +inf        (1; 0)\n+     7: &gt;&gt;&gt;&gt;&gt;   1.500000000e+01 &lt;=   1.500000000e+01   0.0% (1; 0)\n+     7: mip =   1.500000000e+01 &lt;=     tree is empty   0.0% (0; 1)\nINTEGER OPTIMAL SOLUTION FOUND\n\n\n$optimum\n[1] 15\n\n$solution\n[1] 3 3 2\n\n$status\n[1] 5\n\n$solution_dual\n[1] NA\n\n$auxiliary\n$auxiliary$primal\n[1]   8 119   3   3   2\n\n$auxiliary$dual\n[1] NA\n\n\n$sensitivity_report\n[1] NA"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#automatisierte-blockbesetzung-2",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#automatisierte-blockbesetzung-2",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Automatisierte Blockbesetzung",
    "text": "Automatisierte Blockbesetzung"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#automatisierte-blockbesetzung-3",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#automatisierte-blockbesetzung-3",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Automatisierte Blockbesetzung",
    "text": "Automatisierte Blockbesetzung\nVerwendet Konzepte der Mathematical Optimization (Mixed Integer Programming) zur Blockbesetzung (Kuhn & Kiefer, 2015; van der Linden, 2005)\nZentrale Konzepte\n\nDecision Variables (0/1, Item x Block)\nConstraints (Testspezifikationen)\nObjective Function (wichtigste relative Testspezifikation)"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#minimalbeispiel-item-pool",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#minimalbeispiel-item-pool",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Minimalbeispiel: Item Pool",
    "text": "Minimalbeispiel: Item Pool\n\n30 Items\nItem Formate (MC, offen, Zuordnung)\nDurchschnittliche Antwortzeiten\nSchwierigkeitsparameter (1PL-Modell)"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#minimalbeispiel-item-pool-1",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#minimalbeispiel-item-pool-1",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Minimalbeispiel: Item Pool",
    "text": "Minimalbeispiel: Item Pool\n\n\n\nErste fünf Items des simulierten Itempools.\n\n\nitem\nformat\ntime\ndifficulty\n\n\n\n\n1\nmc\n27.78586\n-1.8809028\n\n\n2\nmc\n15.45258\n0.8429586\n\n\n3\nmc\n31.01590\n1.1188154\n\n\n4\nmc\n29.87421\n0.7286774\n\n\n5\nmc\n23.13401\n-0.4887099"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#minimalbeispiel-spezifikationen",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#minimalbeispiel-spezifikationen",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Minimalbeispiel: Spezifikationen",
    "text": "Minimalbeispiel: Spezifikationen\nSpezifikationen\n\n1 Block\nMinimale durchschnittliche Blockzeit\nExakt 10 Items im Block\n4 MC-Items, 3 offene Items, 3 Zuordnungsitems"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#minimalbeispiel-decision-variables",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#minimalbeispiel-decision-variables",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Minimalbeispiel: Decision Variables",
    "text": "Minimalbeispiel: Decision Variables\nDecision Variables\n\nMatrix mit\n\nSpalten = Anzahl Items (+ 1)\nZeilen = Anzahl Blöcke\n\n30 Items, 1 Block \\[\n  i_{1, b1}, i_{2, b1}, i_{3, b1}, \\ldots, i_{30, b1}\n\\]"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#minimalbeispiel-objective-function",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#minimalbeispiel-objective-function",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Minimalbeispiel: Objective Function",
    "text": "Minimalbeispiel: Objective Function\nObjective Function\n\n‘Relative Testspezifikation’\nso viel/wenig/nah wie möglich (an) …\nWichtig: Exakt eine Testspezifikation muss hierfür ausgewählt werden\nMin/Max/Minimax/Maximin\nMinimale Blockzeit \\[\nminimiere \\quad  27.79i_{1, b1} + 15.45i_{2, b1} + \\ldots + 19.50i_{30, b1}\n\\]"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#minimalbeispiel-constraints",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#minimalbeispiel-constraints",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Minimalbeispiel: Constraints",
    "text": "Minimalbeispiel: Constraints\nConstraints\n\nAlle anderen Testspezifikationen\nGenau 10 Items pro Block \\[\ni_{1, b1} + i_{2, b1} + \\ldots + i_{30, b1} = 10\n\\]\n4 MC Items, 3 offene Items, 3 Zuordnungsitems \\[\n  1i_{1, b1} + 1i_{2, b1} + \\ldots + 0i_{30, b1} = 4\n\\] \\[\n  0i_{1, b1} + 0i_{2, b1} + \\ldots + 0i_{30, b1} = 3\n\\] \\[\n  0i_{1, b1} + 0i_{2, b1} + \\ldots + 1i_{30, b1} = 3\n\\]"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#übung-1",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#übung-1",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Übung",
    "text": "Übung\nNotiert die Decision Variables, Objective Function und Constraints für folgendes ATA-Problem:\n\n2 Blöcke\nbeide Blöcke bzgl. Testzeit so nah wie möglich an 450 Sekunden\njedes Item darf maximal nur in einem Block vorkommen\npro Block müssen alle 3 Itemformate mindestens 3 mal verwendet werden"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#lösung",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#lösung",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Lösung",
    "text": "Lösung\n\nDecision Variables für 2 Blöcke und Item-Pool aus 30 Items\n\n\\[\n    i_{1, b1}, i_{2, b1}, i_{3, b1}, \\ldots, i_{30, b1}\n\\] \\[\n    i_{1, b2}, i_{2, b2}, i_{3, b2}, \\ldots, i_{30, b2}\n\\]"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#lösung-1",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#lösung-1",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Lösung",
    "text": "Lösung\n\nbeide Blöcke bzgl. Testzeit so nah wie möglich an 450 Sekunden\nMaximin-Ansatz\n\n\\[\n  27.79i_{1, b1} + 15.45i_{2, b1} + \\ldots + 19.50i_{30, b1} - y &lt;= 450\n\\] \\[\n  27.79i_{1, b1} + 15.45i_{2, b1} + \\ldots + 19.50i_{30, b1} + y &gt;= 450\n\\] \\[\n  27.79i_{1, b2} + 15.45i_{2, b2} + \\ldots + 19.50i_{30, b2} - y &lt;= 450\n\\] \\[\n  27.79i_{1, b2} + 15.45i_{2, b2} + \\ldots + 19.50i_{30, b2} + y &gt;= 450\n\\] \\[\nminimiere \\quad y\n\\]"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#lösung-2",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#lösung-2",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Lösung",
    "text": "Lösung\n\njedes Item darf maximal nur in einem Block vorkommen\n\n\\[\n    i_{1, b1} + i_{1, b2} &lt;= 1\n\\] \\[\n    i_{2, b1} + i_{2, b2} &lt;= 1\n\\] \\[\n    \\ldots\n\\]"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#lösung-3",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#lösung-3",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Lösung",
    "text": "Lösung\n\njedes Itemformat sollte mindestens 3 Mal pro Block vorkommen\n\n\\[\n    1i_{1, b1} + 1i_{2, b1} + \\ldots + 0i_{30, b1} &gt;= 3\n\\] \\[\n    1i_{1, b2} + 1i_{2, b2} + \\ldots + 0i_{30, b2} &gt;= 3\n\\] \\[\n    \\ldots\n\\]"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#eatata",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#eatata",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "eatATA",
    "text": "eatATA\nEntwickelt basierend auf Feedback von:\n\nPauline Kohrt (ehemals VERA 3 Math)\nSimone Dubiel (ehemals VERA 8 German)\nKaroline Sachse (BT/Methoden)\n\nPaketautoren:\n\nDries Debeer (Ghent University)\nBenjamin Becker (IQB)"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#eatata-resources-i",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#eatata-resources-i",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "eatATA: Resources I",
    "text": "eatATA: Resources I\nVignettes available on CRAN"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#eatata-resources-ii",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#eatata-resources-ii",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "eatATA: Resources II",
    "text": "eatATA: Resources II\nor on pkgdown"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#eatata-resources-iii",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#eatata-resources-iii",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "eatATA: Resources III",
    "text": "eatATA: Resources III\neatATA Tutorial Paper (Becker et al., 2021)"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#code-objective-function",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#code-objective-function",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Code: Objective Function",
    "text": "Code: Objective Function\nMinimiere durchschnittliche Blockzeit\n\nBtime &lt;- minObjective(\n    nForms = 1, \n    itemValues = items_mini$time,\n    itemIDs = items_mini$item\n)"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#code-constraint-1",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#code-constraint-1",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Code: Constraint 1",
    "text": "Code: Constraint 1\nAnzahl Items im Block\n\nBlength &lt;- itemsPerFormConstraint(\n    nForms = 1, \n    operator = \"=\",\n    targetValue = 10,\n    itemIDs = items_mini$item\n)"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#code-constraint-2",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#code-constraint-2",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Code: Constraint 2",
    "text": "Code: Constraint 2\nItemformate\n\nBcat &lt;- itemCategoryConstraint(\n  nForms = 1, \n  as.factor(items_mini$format),\n  targetValues = c(4, 3, 3),\n  itemIDs = items_mini$item)"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#code-solver-call",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#code-solver-call",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Code: Solver Call",
    "text": "Code: Solver Call\nSolver Call\n\nsolver_out &lt;- useSolver(\n    list(Btime, Blength, Bcat),\n    solver = \"GLPK\"\n)\n\nGLPK Simplex Optimizer 5.0\n5 rows, 31 columns, 91 non-zeros\n      0: obj =   0.000000000e+00 inf =   1.000e+01 (1)\n     14: obj =   2.758548505e+02 inf =   0.000e+00 (0)\n*    15: obj =   2.758548505e+02 inf =   0.000e+00 (0)\nOPTIMAL LP SOLUTION FOUND\nGLPK Integer Optimizer 5.0\n5 rows, 31 columns, 91 non-zeros\n30 integer variables, all of which are binary\nInteger optimization begins...\nLong-step dual simplex will be used\n+    15: mip =     not found yet &gt;=              -inf        (1; 0)\n+    15: &gt;&gt;&gt;&gt;&gt;   2.758548505e+02 &gt;=   2.758548505e+02   0.0% (1; 0)\n+    15: mip =   2.758548505e+02 &gt;=     tree is empty   0.0% (0; 1)\nINTEGER OPTIMAL SOLUTION FOUND"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#code-inspect-solution",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#code-inspect-solution",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Code: Inspect Solution",
    "text": "Code: Inspect Solution\nZusammengestellten Block inspizieren\n\ninspectSolution(\n    solver_out, \n    items = items_mini, \n    idCol = \"item\"\n)\n\n$form_1\n    item format      time difficulty\n2      2     mc  15.45258  0.8429586\n5      5     mc  23.13401 -0.4887099\n6      6     mc  25.19305  0.4727387\n10    10     mc  15.35510  1.3539724\n12    12   open  35.94400  2.4992738\n16    16   open  45.12778 -1.2862969\n17    17   open  48.11908 -0.8612431\n21    21  order  22.47400 -0.4314714\n29    29  order  25.55363  0.2409175\n30    30  order  19.50162 -0.5143411\nSum  148   &lt;NA&gt; 275.85485  1.8277985"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#code-append-solution",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#code-append-solution",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Code: Append Solution",
    "text": "Code: Append Solution\nBlockbesetzung zu Itempool hinzufügen\n\nitem_mini_out &lt;- appendSolution(\n    solver_out, \n    items = items_mini, \n    idCol = \"item\"\n)\nitem_mini_out[1:10, ]\n\n   item format     time difficulty form_1\n1     1     mc 27.78586 -1.8809028      0\n2     2     mc 15.45258  0.8429586      1\n3     3     mc 31.01590  1.1188154      0\n4     4     mc 29.87421  0.7286774      0\n5     5     mc 23.13401 -0.4887099      1\n6     6     mc 25.19305  0.4727387      1\n7     7     mc 25.66340 -1.1805427      0\n8     8     mc 30.21856 -0.3670765      0\n9     9     mc 26.61642 -0.5687943      0\n10   10     mc 15.35510  1.3539724      1"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#itempool-vorbereiten",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#itempool-vorbereiten",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Itempool vorbereiten",
    "text": "Itempool vorbereiten\n\ncalculateIIF() - Berechnung Item-Informationsfunktion\ncalculatExpectedRT() - Berechnung erwarteter Antwortzeiten\ndummiesToFactor() - Transformation von Dummy-Variablen in Faktoren\ncomputeTargetValues() - Berechnung von sinnvollen Zielwerten"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#objective-function",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#objective-function",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Objective Function",
    "text": "Objective Function\n\nmaxObjective() - Maximieren\nminObjective() - Minimieren\nmaximinObjective() - Maximieren eines Minimums\nminimaxObjective() - Minimieren eines Maximums\ncappedMaximinObjective() - Capped Maximin"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#constraints",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#constraints",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Constraints",
    "text": "Constraints\nItemverwendung\n\ndepletePoolConstraint() - Erschöpfung des Itempools\nitemUsageConstraint() - Itemnutzung\n\nAnzahl Items pro Form\n\nitemsPerFormConstraint() - Anzahl Items pro Form"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#constraints-1",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#constraints-1",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Constraints",
    "text": "Constraints\nKategoriale Constraints\n\nitemCategoryConstraint() - Kategoriale Constraints\nitemCategoryDeviationConstraint() - Abweichung von Zielwert\nitemCategoryMaxConstraint() - Maximum\nitemCategoryMinConstraint() - Minimum\nitemCategoryRangeConstraint() - Maximum und Minimum"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#constraints-2",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#constraints-2",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Constraints",
    "text": "Constraints\nMetrische Constraints\n\nautoItemValuesMinMaxConstraint() - Automatische Min/Max-Berechnung\nitemValuesConstraint() - Metrische Constraints\nitemValuesDeviationConstraint() - Abweichung von Zielwert\nitemValuesMaxConstraint() - Maximum\nitemValuesMinConstraint() - Minimum\nitemValuesRangeConstraint() - Maximum und Minimum"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#constraints-3",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#constraints-3",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Constraints",
    "text": "Constraints\nMetrische Constraints über Testformen\n\nacrossFormsConstraint() - Über Testformen\n\nIteminklusionen und -exklusionen\n\nitemExclusionConstraint() - Itemexklusionen\nitemInclusionConstraint() - Iteminklusionen\n\nVorbereitung von Iteminklusionen und -exklusionen\n\nitemTuples() - Vorbereitung von Iteminklusionen und -exklusionen\nmatrixExclusionTuples() - Vorbereitung von Itemexklusionen\nstemInclusionTuples() - Vorbereitung von Iteminklusionen"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#übung-2",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#übung-2",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Übung",
    "text": "Übung\nErstellt Blöcke mit folgenden Testspezifikationen mithilfe von eatATA (siehe auch letzte Übung):\n\n2 Blöcke\nbeide Blöcke Testzeit so nah wie möglich an 450 Sekunden (via minimaxObjective() Funktion)\njedes Item darf maximal nur in einem Block vorkommen (via itemUsageConstraint() Funktion)\npro Block müssen alle 3 Itemformate mindestens 3 mal verwendet werden (via itemCategoryMinConstraint() Funktion)\n\nSetzt für die Lösung des Problems dem Solver ein Zeitlimit von 10 Sekunden!"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#lösung-4",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#lösung-4",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Lösung",
    "text": "Lösung\nSiehe R-Syntax"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#praktische-tipps",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#praktische-tipps",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Praktische Tipps",
    "text": "Praktische Tipps\n\nATA ist ein Skill für sich\nEs gibt immer mehrere Wege zum Ziel\nPragmatisches Vorgehen:\n\nHäufig muss die Lösung nicht perfekt sein\nDer Weg zum Ziel ist irrelevant\n\nSchrittweises Vorgehen (Spaccapanico Proietti et al., 2020)\n\nProblem schrittweise aufbauen oder\nProblem schrittweise vereinfachen"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#references",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#references",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "References",
    "text": "References\n\n\nBecker, B., Debeer, D., Sachse, K. A., & Weirich, S. (2021). Automated test assembly in R: The eatATA package. Psych, 3(2), 96–112. https://doi.org/10.3390/psych3020010\n\n\nKuhn, J.-T., & Kiefer, T. (2015). Optimal test assembly in practice. Zeitschrift für Psychologie, 221(3), 190–200. https://doi.org/10.1027/2151-2604/a000146\n\n\nSpaccapanico Proietti, G., Matteucci, M., & Mignani, S. (2020). Automated test assembly for large-scale standardized assessments: Practical issues and possible solutions. Psych, 2(4), 315–337. https://doi.org/10.3390/psych2040024\n\n\nvan der Linden, W. J. (2005). Linear models for optimal test assembly. Springer. https://doi.org/10.1007/0-387-29054-0"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#item-inclusions",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#item-inclusions",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Item Inclusions",
    "text": "Item Inclusions\nGründe\n\nGemeinsamer Stimulus (‘Aufgabe’)\nandere Gründe\n\nUmsetzung\n\nAufgaben und nicht Items als Assembling Unit (e.g., VERA 3 Math)\nexplizite Item Inclusion (siehe eatATA Tutorial)"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#item-exclusions",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#item-exclusions",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Item Exclusions",
    "text": "Item Exclusions\nGründe\n\nItem beinhaltet Info zu Lösung eines anderen Items\nItems inhaltlich zu ähnlich\n…\n\nUmsetzung\n\nExplizite Item Exclusions"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#code-item-inclusions-input",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#code-item-inclusions-input",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Code: Item Inclusions (Input)",
    "text": "Code: Item Inclusions (Input)\nInput: Spalte mit Gruppierung\n\nincluTup &lt;- stemInclusionTuples(\n    items_lsa, \n    idCol = \"item\", \n    stemCol = \"testlet\"\n)\n\nOutput: Inclusion Tuples"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#code-item-inclusions-constraints",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#code-item-inclusions-constraints",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Code: Item Inclusions (Constraints)",
    "text": "Code: Item Inclusions (Constraints)\nErstellung von Inclusion Constraints\n\nincluCons &lt;- itemInclusionConstraint(\n    nForms = 8,  \n    itemTuples = incluTup,\n    itemIDs = items_lsa$item\n)"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#code-item-exclusions-input",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#code-item-exclusions-input",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Code: Item Exclusions (Input)",
    "text": "Code: Item Exclusions (Input)\nInput: Spalte mit Exclusion-Listung\n\nexclusionTuples &lt;- itemTuples(\n    items_pilot, \n    idCol = \"item\",\n    infoCol = \"exclusions\", \n    sepPattern = \", \"\n)\n\nOutput: Exclusion Tuples"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#code-item-exclusions-constraints",
    "href": "docs/R_tutorials/2024_eatATA/eatATA_2024.html#code-item-exclusions-constraints",
    "title": "eatATA - Automatisierte Blockbesetzung",
    "section": "Code: Item Exclusions (Constraints)",
    "text": "Code: Item Exclusions (Constraints)\nErstellung von Exclusion COnstraints\n\nexcl_constraints &lt;- itemExclusionConstraint(\n    nForms = nForms,\n    itemTuples = exclusionTuples, \n    itemIDs = items_pilot$item\n)"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#agenda",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#agenda",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Agenda",
    "text": "Agenda\n\nHintergrund\nGrundlegendes\nÜbersicht Funktionalität\nÜbung\nPraxis-Tipps"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#eatgads---scope",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#eatgads---scope",
    "title": "eatGADS - Datenbanknutzung",
    "section": "eatGADS - Scope",
    "text": "eatGADS - Scope\n\n(teil-automatisierte) Datenaufbereitung\nDatenbankerstellung\nDatenbanknutzung"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#eatgads---scope-1",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#eatgads---scope-1",
    "title": "eatGADS - Datenbanknutzung",
    "section": "eatGADS - Scope",
    "text": "eatGADS - Scope\n\n(teil-automatisierte) Datenaufbereitung\nDatenbankerstellung\nDatenbanknutzung"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#was-ist-ein-gads",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#was-ist-ein-gads",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Was ist ein GADS?",
    "text": "Was ist ein GADS?\nGenereller/Gesamt- Analyse-Datensatz\n\nBerichts-GADS\nnach-Berichts-GADS\nFDZ-GADS"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#wie-war-es-früher",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#wie-war-es-früher",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Wie war es früher?",
    "text": "Wie war es früher?\nDatei-Format\n\n.Rdata\n.sav\n\nDaten-Format\n\nlong\nwide"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#gads-ordner",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#gads-ordner",
    "title": "eatGADS - Datenbanknutzung",
    "section": "GADS-Ordner",
    "text": "GADS-Ordner\nBT22 nach-Berichts-GADS"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#warum-machen-wir-das",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#warum-machen-wir-das",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Warum machen wir das?",
    "text": "Warum machen wir das?\n\n.db (SQLite3) benötigt weniger Speicherplatz\nZugriff auf Metadaten ohne Daten laden zu müssen\nDaten müssen für Analysen nicht gereshaped werden\nVariablenselektion beim Laden der Daten (weniger Arbeitsspeicher-Überlastung)\nflexibels Anwenden von Wertelabeln und Missingtags"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#warum-braucht-ihr-das",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#warum-braucht-ihr-das",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Warum braucht ihr das?",
    "text": "Warum braucht ihr das?\n\nAlle BT-Daten seit BT18 intern nur noch als Datenbank verfügbar\nFDZ-Daten (SPSS, wide-Format) nutzbar, aber für IQB-relevante Analysen (z.B. mit eatRep) nicht optimal"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#eatgads",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#eatgads",
    "title": "eatGADS - Datenbanknutzung",
    "section": "eatGADS",
    "text": "eatGADS\n\n\n# Stabile Version\ninstall.packages(\"eatGADS\")\n\n# Development Version\nremotes::install_github(\"beckerbenj/eatGADS\")"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#ressourcen",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#ressourcen",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Ressourcen",
    "text": "Ressourcen\n\nVignette: getGADS: Using a relational eatGADS data base"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#daten-in-datenbank",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#daten-in-datenbank",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Daten in Datenbank",
    "text": "Daten in Datenbank\n\nnumerische Variablen\ncharacter Variablen (Zeichenfolgen)"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#meta-daten-in-datenbank",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#meta-daten-in-datenbank",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Meta-Daten in Datenbank",
    "text": "Meta-Daten in Datenbank\n\nvarName - Variablenname\nvarLabel - Variablenlabel\nformat - SPSS-Format\nvalue - numerischer Wert\nvalLabel - Wertelabel\nmissings - Missingtags (miss oder valid)\ndata_table - Datenblatt"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#meta-daten-in-datenbank-1",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#meta-daten-in-datenbank-1",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Meta-Daten in Datenbank",
    "text": "Meta-Daten in Datenbank\n\n\n         varName                                         varLabel format\n165 computer_age                           First use of computers   F8.0\n166 computer_age                           First use of computers   F8.0\n167 computer_age                           First use of computers   F8.0\n168 computer_age                           First use of computers   F8.0\n169 computer_age                           First use of computers   F8.0\n331      norms_f Subjective Norms - Parents Like Mathematics (T1)   F8.0\n332      norms_f Subjective Norms - Parents Like Mathematics (T1)   F8.0\n333      norms_f Subjective Norms - Parents Like Mathematics (T1)   F8.0\n334      norms_f Subjective Norms - Parents Like Mathematics (T1)   F8.0\n356     repeated                                 Grade repetition   F8.0\n357     repeated                                 Grade repetition   F8.0\n    display_width labeled value               valLabel missings data_table\n165            NA     yes     1 6 years old or younger    valid      noImp\n166            NA     yes     2          7-9 years old    valid      noImp\n167            NA     yes     3        10-12 years old    valid      noImp\n168            NA     yes     4 13 years old  or older    valid      noImp\n169            NA     yes     5                  Never    valid      noImp\n331            NA     yes     1      Strongly disagree    valid      noImp\n332            NA     yes     2               Disagree    valid      noImp\n333            NA     yes     3                  Agree    valid      noImp\n334            NA     yes     4         Strongly agree    valid      noImp\n356            NA     yes     1 Did not repeat a grade    valid      noImp\n357            NA     yes     2       Repeated a grade    valid      noImp"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#übliche-bt-struktur",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#übliche-bt-struktur",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Übliche BT-Struktur",
    "text": "Übliche BT-Struktur\n\nnoImp\nimp\nPVs\nwgts"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#übliche-bt-struktur-1",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#übliche-bt-struktur-1",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Übliche BT-Struktur",
    "text": "Übliche BT-Struktur\n\nnoImp\n\nunimputierter Datensatz auf SuS-Ebene\nQuellen: SFB, EFB, Tracking\n1 Zeile pro SuS\n\nimp\n\nimputierter Datensatz auf SuS-Ebene\nQuelle: Imputationen\n1 Zeile pro Imputation x SuS (= 15 Zeilen pro SuS)"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#übliche-bt-struktur-2",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#übliche-bt-struktur-2",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Übliche BT-Struktur",
    "text": "Übliche BT-Struktur\n\nPVs\n\nKompetenzdaten\nQuelle: PV-Ziehung\n1 Zeile pro Kompetenzbereich x Imputation x SuS (&gt; 75 Zeilen pro SuS)\n\nwgts\n\nbereichs-/fachspezifische Gewichte\nQuelle: Gewichtsdaten\n1 Zeile pro Kompetenzbereich x Imputation x SuS (&gt; 75 Zeilen pro SuS)"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#übersicht-funktionalität-1",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#übersicht-funktionalität-1",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Übersicht Funktionalität",
    "text": "Übersicht Funktionalität\n\nnamesGADS() - Variablennamen und Datenbankstruktur\nextractMeta() - Extraktion Metadaten\ngetGADS() - Extraktion aus DB\ngetGADS_fast() - Extraktion aus DB mit Caching\ngetTrendGADS() - Extraktion Trend-GADSe aus DB\nextractData2() - Extraktion Daten"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#beispiel-datenbank",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#beispiel-datenbank",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Beispiel-Datenbank",
    "text": "Beispiel-Datenbank\nPISA-Plus Daten (FDZ Campus Files)\n\ndb_path &lt;- system.file(\"extdata\", \"pisa.db\", package = \"eatGADS\")"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#datenbank-struktur",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#datenbank-struktur",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Datenbank-Struktur",
    "text": "Datenbank-Struktur\nDatenbankstruktur und Variablennamen inspizieren\n\nnam &lt;- namesGADS(db_path)\nnam\n\n$noImp\n  [1] \"idstud\"       \"idschool\"     \"idclass\"      \"schtype\"      \"sameteach\"   \n  [6] \"g8g9\"         \"ganztag\"      \"classsize\"    \"repeated\"     \"gender\"      \n [11] \"age\"          \"language\"     \"migration\"    \"hisced\"       \"hisei\"       \n [16] \"homepos\"      \"books\"        \"pared\"        \"computer_age\" \"internet_age\"\n [21] \"int_use_a\"    \"int_use_b\"    \"truancy_a\"    \"truancy_b\"    \"truancy_c\"   \n [26] \"int_a\"        \"int_b\"        \"int_c\"        \"int_d\"        \"instmot_a\"   \n [31] \"instmot_b\"    \"instmot_c\"    \"instmot_d\"    \"norms_a\"      \"norms_b\"     \n [36] \"norms_c\"      \"norms_d\"      \"norms_e\"      \"norms_f\"      \"anxiety_a\"   \n [41] \"anxiety_b\"    \"anxiety_c\"    \"anxiety_d\"    \"anxiety_e\"    \"selfcon_a\"   \n [46] \"selfcon_b\"    \"selfcon_c\"    \"selfcon_d\"    \"selfcon_e\"    \"worketh_a\"   \n [51] \"worketh_b\"    \"worketh_c\"    \"worketh_d\"    \"worketh_e\"    \"worketh_f\"   \n [56] \"worketh_g\"    \"worketh_h\"    \"worketh_i\"    \"intent_a\"     \"intent_b\"    \n [61] \"intent_c\"     \"intent_d\"     \"intent_e\"     \"behav_a\"      \"behav_b\"     \n [66] \"behav_c\"      \"behav_d\"      \"behav_e\"      \"behav_f\"      \"behav_g\"     \n [71] \"behav_h\"      \"teach_a\"      \"teach_b\"      \"teach_c\"      \"teach_d\"     \n [76] \"teach_e\"      \"cognact_a\"    \"cognact_b\"    \"cognact_c\"    \"cognact_d\"   \n [81] \"cognact_e\"    \"cognact_f\"    \"cognact_g\"    \"cognact_h\"    \"cognact_i\"   \n [86] \"discpline_a\"  \"discpline_b\"  \"discpline_c\"  \"discpline_d\"  \"discpline_e\" \n [91] \"relation_a\"   \"relation_b\"   \"relation_c\"   \"relation_d\"   \"relation_e\"  \n [96] \"belong_a\"     \"belong_b\"     \"belong_c\"     \"belong_d\"     \"belong_e\"    \n[101] \"belong_f\"     \"belong_g\"     \"belong_h\"     \"belong_i\"     \"attitud_a\"   \n[106] \"attitud_b\"    \"attitud_c\"    \"attitud_d\"    \"attitud_e\"    \"attitud_f\"   \n[111] \"attitud_g\"    \"attitud_h\"    \"grade_de\"     \"grade_ma\"     \"grade_bio\"   \n[116] \"grade_che\"    \"grade_phy\"    \"grade_sci\"   \n\n$PVs\n[1] \"idstud\"    \"dimension\" \"imp\"       \"value\""
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#metadaten",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#metadaten",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Metadaten",
    "text": "Metadaten\nMetadaten extrahieren\n\nextractMeta(GADSobject = db_path, \n            vars = c(\"repeated\", \"norms_f\", \"computer_age\"))\n\n         varName                                         varLabel format\n165 computer_age                           First use of computers   F8.0\n166 computer_age                           First use of computers   F8.0\n167 computer_age                           First use of computers   F8.0\n168 computer_age                           First use of computers   F8.0\n169 computer_age                           First use of computers   F8.0\n331      norms_f Subjective Norms - Parents Like Mathematics (T1)   F8.0\n332      norms_f Subjective Norms - Parents Like Mathematics (T1)   F8.0\n333      norms_f Subjective Norms - Parents Like Mathematics (T1)   F8.0\n334      norms_f Subjective Norms - Parents Like Mathematics (T1)   F8.0\n356     repeated                                 Grade repetition   F8.0\n357     repeated                                 Grade repetition   F8.0\n    display_width labeled value               valLabel missings data_table\n165            NA     yes     1 6 years old or younger    valid      noImp\n166            NA     yes     2          7-9 years old    valid      noImp\n167            NA     yes     3        10-12 years old    valid      noImp\n168            NA     yes     4 13 years old  or older    valid      noImp\n169            NA     yes     5                  Never    valid      noImp\n331            NA     yes     1      Strongly disagree    valid      noImp\n332            NA     yes     2               Disagree    valid      noImp\n333            NA     yes     3                  Agree    valid      noImp\n334            NA     yes     4         Strongly agree    valid      noImp\n356            NA     yes     1 Did not repeat a grade    valid      noImp\n357            NA     yes     2       Repeated a grade    valid      noImp"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#metadaten-1",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#metadaten-1",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Metadaten",
    "text": "Metadaten\nMetadaten extrahieren\n\nall_meta &lt;- extractMeta(db_path)\nunique(all_meta[grep(\"grade\", all_meta$varLabel), c(\"varName\", \"varLabel\")])\n\n      varName                                                 varLabel\n196 grade_bio     School grade in biology (First school semester) (T1)\n201 grade_che   School grade in chemistry (First school semester) (T1)\n206  grade_de      School grade in German (First school semester) (T1)\n211  grade_ma School grade in mathematics (First school semester) (T1)\n216 grade_phy     School grade in physics (First school semester) (T1)\n221 grade_sci     School grade in science (First school semester) (T1)"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#gadsdat",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#gadsdat",
    "title": "eatGADS - Datenbanknutzung",
    "section": "GADSdat",
    "text": "GADSdat\nGADSdat aus Datenbank ziehen\n\npisa_gads &lt;- getGADS(db_path, vSelect = c(\"schtype\", \"sameteach\"))"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#gadsdat-1",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#gadsdat-1",
    "title": "eatGADS - Datenbanknutzung",
    "section": "GADSdat",
    "text": "GADSdat\nGADSdat aus Datenbank ziehen\n\n# resultierendes \"GADSdat\"-Objekt\nstr(pisa_gads)\n\nList of 2\n $ dat   :'data.frame': 500 obs. of  3 variables:\n  ..$ idstud   : num [1:500] 1 2 3 4 5 6 7 9 10 11 ...\n  ..$ schtype  : num [1:500] 2 3 1 3 2 3 1 3 2 1 ...\n  ..$ sameteach: num [1:500] 2 1 1 2 2 1 2 1 2 2 ...\n $ labels:'data.frame': 6 obs. of  8 variables:\n  ..$ varName      : chr [1:6] \"idstud\" \"sameteach\" \"sameteach\" \"schtype\" ...\n  ..$ varLabel     : chr [1:6] \"Student-ID\" \"Same math teacher in both school years\" \"Same math teacher in both school years\" \"School track\" ...\n  ..$ format       : chr [1:6] \"F8.0\" \"F8.0\" \"F8.0\" \"F8.0\" ...\n  ..$ display_width: num [1:6] NA NA NA NA NA NA\n  ..$ labeled      : chr [1:6] \"no\" \"yes\" \"yes\" \"yes\" ...\n  ..$ value        : num [1:6] NA 1 2 1 2 3\n  ..$ valLabel     : chr [1:6] NA \"No\" \"Yes\" \"Gymnasium (academic track)\" ...\n  ..$ missings     : chr [1:6] NA \"valid\" \"valid\" \"valid\" ...\n - attr(*, \"class\")= chr [1:2] \"GADSdat\" \"list\""
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#daten",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#daten",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Daten",
    "text": "Daten\nDaten extrahieren\n\npisa_dat &lt;- extractData2(pisa_gads, labels2character = \"sameteach\")\nstr(pisa_dat)\n\n'data.frame':   500 obs. of  3 variables:\n $ idstud   : num  1 2 3 4 5 6 7 9 10 11 ...\n  ..- attr(*, \"label\")= chr \"Student-ID\"\n $ schtype  : num  2 3 1 3 2 3 1 3 2 1 ...\n  ..- attr(*, \"label\")= chr \"School track\"\n $ sameteach: chr  \"Yes\" \"No\" \"No\" \"Yes\" ...\n  ..- attr(*, \"label\")= chr \"Same math teacher in both school years\""
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#daten-1",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#daten-1",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Daten",
    "text": "Daten\nKompetenz-Daten extrahieren (Long-Format)\n\npisa_gads2 &lt;- getGADS(db_path, vSelect = c(\"schtype\", \"sameteach\", nam$PVs))\npisa_dat2 &lt;- extractData2(pisa_gads2, labels2character = c(\"sameteach\", \"dimension\"))\nstr(pisa_dat2)\n\n'data.frame':   7500 obs. of  6 variables:\n $ idstud   : num  1 1 1 1 1 1 1 1 1 1 ...\n  ..- attr(*, \"label\")= chr \"Student-ID\"\n $ schtype  : num  2 2 2 2 2 2 2 2 2 2 ...\n  ..- attr(*, \"label\")= chr \"School track\"\n $ sameteach: chr  \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n  ..- attr(*, \"label\")= chr \"Same math teacher in both school years\"\n $ dimension: chr  \"ma\" \"rea\" \"sci\" \"ma\" ...\n  ..- attr(*, \"label\")= chr \"Achievement dimension (math, reading, science)\"\n $ imp      : num  1 1 1 2 2 2 3 3 3 4 ...\n  ..- attr(*, \"label\")= chr \"Number of imputation of plausible values\"\n $ value    : num  0.1537 0.4391 0.1318 -0.0412 0.0199 ...\n  ..- attr(*, \"label\")= chr \"Plausible Value\""
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#übung-1",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#übung-1",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Übung",
    "text": "Übung\n\nWelche Variablen zum Thema elterliche Bildung sind in der Beispiel-DB enthalten?\nWie sind die Metadaten dieser Variablen strukturiert? (Wertelabel, Fehlende Werte, etc.)\nZieht diese Variablen zusammen mit der Geschlechtervariable ‘gender’ aus der Datenbank und betrachtet ihre univariaten und bivariaten Verteilungen.\nZieht nun diese drei Variablen zusammen mit dem Kompetenzschätzer (‘value’) aus der Datenbank.\nKönnen wir mithilfe der elterlichen Bildung die Mathematik-Kompetenz der Schüler:innen vorhersagen?"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#warum-machen-wir-das-1",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#warum-machen-wir-das-1",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Warum machen wir das?",
    "text": "Warum machen wir das?\n\n.db (SQLite3) benötigt weniger Speicherplatz\nZugriff auf Metadaten ohne Daten laden zu müssen\nDaten müssen für Analysen nicht gereshaped werden\nVariablenselektion beim Laden der Daten (weniger Arbeitsspeicher-Überlastung)\nflexibels Anwenden von Wertelabeln und Missingtags"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#praxis-tipps-1",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#praxis-tipps-1",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Praxis-Tipps",
    "text": "Praxis-Tipps\n\n\n\n\n\n\nTip\n\n\nFür Datenbanken, die auf den Netzlaufkwerken liegen, getGADS_fast() und getTrendGADS(..., fast = TRUE) nutzen."
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#praxis-tipps-2",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#praxis-tipps-2",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Praxis-Tipps",
    "text": "Praxis-Tipps\n\n\n\n\n\n\nTip\n\n\nFür konkrete Analysen passende Daten aus der Datenbank ziehen.\n\n\n\ndon’t:\n\neinfach mal alle Daten aus Datenbank ziehen und dann schauen, was man braucht\n\ndo\n\nanhand Meta-Daten Variablenauswahl treffen\nfür verschiedene Analyselevel verschiedene Datensätze ziehen"
  },
  {
    "objectID": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#praxis-tipps-3",
    "href": "docs/R_tutorials/2024_eatGADS_Datenbanknutzung/eatGADS_2024_Datenbanknutzung.html#praxis-tipps-3",
    "title": "eatGADS - Datenbanknutzung",
    "section": "Praxis-Tipps",
    "text": "Praxis-Tipps\n\n\n\n\n\n\nTip\n\n\nextractData2() nutzen um Anwendung von Wertelabels und Missingstags bewusst zu steuern.\n\n\n\ndon’t\n\nalle Variablen als numerisch extrahieren und dann mühsam Wertelabel wiederherstellen\nalle Variablen als character extrahieren und dann Variablen mühsam in numerisch umwandeln\n\ndo\n\nvorab überlegen: Welche Variablen brauche ich numerisch, welche als character?\nextractData2() nutzen um das umzusetzen"
  },
  {
    "objectID": "docs/R_tutorials/R_ws1.html",
    "href": "docs/R_tutorials/R_ws1.html",
    "title": "R Workshop Einführung",
    "section": "",
    "text": "1"
  },
  {
    "objectID": "docs/R_tutorials/R_ws1.html#einleitung",
    "href": "docs/R_tutorials/R_ws1.html#einleitung",
    "title": "R Workshop Einführung",
    "section": "1. Einleitung",
    "text": "1. Einleitung\nR ist eine Programmiersprache für Datenmanipulation, statistische Datenanalyse und grafische Darstellung von Daten (Yanada, 2018).\nDatenmanipulation:\n\nImport und Export: Einlesen und Schreiben von SPSS-, Excel-, ASCII- oder trennzeichenbasierten Dateien\nKopieren, verschieben, löschen, packen und entpacken von Dateien und Verzeichnissen\nVariablen- und Fallselektion, Rekodieren/Aggregieren von Variablen\nUmstrukturieren von Datensätzen (long/wide)\nManipulation von Zeichenketten (Verknüpfen, extrahieren, ersetzen, z.B. auch mithilfe regulärer Ausdrücke: sehr mächtig, aber zuweilen kompliziert)\n\nstatistische Datenanalyse:\n\nlineare und nichtlineare Regression\nVarianzanalyse\nStrukturgleichungsmodelle\nMehrebenenanalyse\nMultiple Imputation\nItem-Response-Modelle\ndecision trees\nmixed models, u.v.m.\n\ngrafische Darstellung von Daten:\n\nBoxplots\nHistogramme\nHeat Maps"
  },
  {
    "objectID": "docs/R_tutorials/R_ws1.html#r-als-taschenrechner",
    "href": "docs/R_tutorials/R_ws1.html#r-als-taschenrechner",
    "title": "R Workshop Einführung",
    "section": "2. R als Taschenrechner",
    "text": "2. R als Taschenrechner\nIn der R Konsole kann man (mathematische) Funktionen eingeben und sie evaluieren lassen. Im einfachsten Fall funktioniert das wie ein Taschenrechner.\n\n2+3\n\n[1] 5\n\n2*3\n\n[1] 6\n\n\nDas Dezimaltrennzeichen in R ist ein Punkt, kein Komma.\n\n5/4\n\n[1] 1.25\n\n\nExponentialschreibweise:\n\n2^3\n\n[1] 8\n\n\nObwohl es nicht so aussieht, werden bei diesen Operationen im Hintergrund Funktionen ausgeführt. So kann man sich beispielsweise die Wurzel aus 2 einfach in Exponentialschreibweise oder mithilfe der Wurzelfunktion ausgeben lassen:\n\n2^0.5\n\n[1] 1.414214\n\n\nWurzelfunktion:\n\nsqrt(2)\n\n[1] 1.414214\n\n\nAllgemein gilt auch in R: “Punktrechnung vor Strichrechnung”:\n\n2*3+1\n\n[1] 7\n\n2*(3+1)\n\n[1] 8"
  },
  {
    "objectID": "docs/R_tutorials/R_ws1.html#grundlagen",
    "href": "docs/R_tutorials/R_ws1.html#grundlagen",
    "title": "R Workshop Einführung",
    "section": "3. Grundlagen",
    "text": "3. Grundlagen\nR ist zugleich eine Sprache und eine Umgebung für statistische Datenbearbeitung. R ist objektbasiert. Alles in R ist ein Objekt: Zahlen, Vektoren, Matrizen, Funktionen. Das grundlegende Funktionsprinzip ist dabei: “Definiere ein Objekt und weise ihm einen Wert zu.” Im einfachsten Fall wird im folgenden Beispiel das Objekt b erzeugt und ihm der Wert 2 zugewiesen. Um sich den Wert von b anzeigen zu lassen, kann man b einfach in die Konsole tippen:\n\nb &lt;- 2\nb\n\n[1] 2\n\n\nb** ist nun intern gespeichert und kann ebenfalls für Zuweisungen benutzt werden. Hier wird ein neues Objekt d erzeugt und ihm als Wert die Quadratwurzel von b zugewiesen:\n\nd &lt;- sqrt(b)\n\nMöglich ist es auch, b wieder mit einem anderen Wert zu überschreiben:\n\nb &lt;- 100 * b\nb\n\n[1] 200\n\n\nMit dem Befehl class kann man sich die Klasse von b anzeigen lassen.\n\nclass(b)\n\n[1] \"numeric\"\n\n\nDie wichtigsten Klassen für skalare Objekt (also solche, die nur aus einem einzigen Element bestehen), sind\n\nnumeric: reelle Ziffer oder Zahlen\ncharacter: Zeichenkette\nlogical: logischer Wert, der nur zwei Zustände annehmen kann, TRUE oder FALSE\n\nIm folgenden verschiedene Beispiele für character- bzw. logische Zuweisungen, hier jeweils wiederum nur für die Länge 1. Zuweisungen der Klasse character erfolgen mit hochgestellten Anführungszeichen:\n\nd &lt;- \"hallo\"\nclass(d)\n\n[1] \"character\"\n\nlength(d)\n\n[1] 1\n\n\nWenn einem Objekt die Zahl 220 in hochgestellten Anführungszeichen zugewiesen wird, wird der Wert nicht als numerisch, sondern als character behandelt:\n\ne &lt;- \"220\"\nclass(e)\n\n[1] \"character\"\n\n\nWenn einem Objekt der Austruck TRUE in hochgestellten Anführungszeichen zugewiesen wird, wird der Wert nicht als logical, sondern als character behandelt:\n\nf &lt;- TRUE\nclass(f)\n\n[1] \"logical\"\n\ng &lt;- \"TRUE\"\nclass(g)\n\n[1] \"character\"\n\n\n\n3.1 Vektoren\nVektoren sind definiert als eine Reihe von Elementen derselben Klasse. Sie können unter anderem mit der Funktion c() erzeugt werden:\n\na &lt;- c(1,4,2,2,89)\nb &lt;- c(\"gut\", \"schlecht\")\nd &lt;- c(TRUE, TRUE, TRUE, FALSE, TRUE, TRUE)\n\nÄhnlich wie in den vorher aufgeführten Beispielen kann man sich mit verschiedenen Befehlen verschiedene Eigenschaften dieser Vektoren zeigen lassen, etwa ihre Länge (= die Anzahl ihrer Elemente) mit length(), oder ihre Klasse mit class(). Bestimmte Funktionen wiederum kann man sinnvoll nur für numerische Vektoren anweden (z.B. sum(), mean(), min(), max() etc. Andere wiederum sind nur für Vektoren der Klasse character sinnvoll, etwa nchar(), das einem die Anzahl der Zeichen einer Zeichenkette gibt. Ganz allgemein gilt: Funktionen, die man auf Skalare anwenden kann, kann man in der Regel auch auf Vektoren anwenden:\n\nskalar &lt;- 2\nsqrt(skalar)\n\n[1] 1.414214\n\nvektor &lt;- c(1,4,2,2,89)\nsqrt(vektor)\n\n[1] 1.000000 2.000000 1.414214 1.414214 9.433981\n\n\nDie Funktion sqrt gibt dabei genauso viele Elemente zurück, wie der Vektor besitzt, den man der Funktion übergeben hat. Das ist nicht bei allen Funktionen so; die mean-Funktion gibt (sinnvollerweise) immer nur ein Element zurück.\n\nskalar &lt;- 2\nmean(skalar)\n\n[1] 2\n\nvektor &lt;- c(1,4,2,2,89)\nmean(vektor)\n\n[1] 19.6\n\n\nWas passiert, wenn man Vektoren “unzulässig” definiert, also beispielsweise die Regel, dass alle Elemente dieselbe Klasse haben müssen, missachtet? Vektoren werden in die “kleinste gemeinsame Klasse” umgewandelt. Es gibt hier keine Warnmeldung, und manchmal führt das zu unerwünschten Nebenwirkungen. Zuerst betrachten wir einen Vektor, der aus Elementen der Klasse numeric, character und logical besteht:\n\nb &lt;- c(1,6,\"hallo\",TRUE,11,FALSE)\nb\n\n[1] \"1\"     \"6\"     \"hallo\" \"TRUE\"  \"11\"    \"FALSE\"\n\n\nDer gesamte Vektor wird als character definiert:\n\nclass(b)\n\n[1] \"character\"\n\n\nBesteht der Vektor nur aus Elementen der Klassen numeric und logical, wird der Vektor als numeric definiert:\n\nb &lt;- c(1,6,TRUE,11,FALSE)\nb\n\n[1]  1  6  1 11  0\n\nclass(b)\n\n[1] \"numeric\"\n\n\nAn diesen Bespielen erkennt man prototypisch, wie R sich bei “widersinnigen” Benutzereingaben verhält: Anstatt bei formal falschen oder unsinnigen Eingaben wie nchar(15) eine Fehlermeldung auszugeben, wird versucht zu “antizipieren”, was der Benutzer gemeint oder beabsichtigt haben könnte. Bei nchar(15) wird also zunächst der numerische Ausdruck in einen character-Ausdruck umgewandelt und anschließend die Anzahl der Zeichen dieses Ausdrucks ausgegeben. Intern wertet R statt nchar(15) folgenden Ausdruck aus: nchar(\"15\") bzw. nchar(as.character(15)). Ein solches oder ähnliches Verhalten wendet R in unzähligen Fällen an, und daraus ergeben sich zugleich Vor- und Nachteile: es erlaubt dem Anwender, syntaktisch “unsauberen” Code zu verwenden, ohne dass es zu Fehlermeldungen kommt. In der Regel erhält man das gewünschte Ergebnis. Außerdem kann man R-Syntaxen teils sehr sparsam und “schreibfaul” erstellen; nchar(15) ist ja viel kürzer als nchar(as.character(15)). Dass R diese Nachlässigkeiten erlaubt, hat aber auch Nachteile: die syntaktische Logik der R-Sprache ist dadurch weniger transparent, und falls es doch zu Fehlermeldungen kommt, sind diese erstmal weniger verständlich.\nAlternative Möglichkeiten, Vektoren zu erzeugen. Alle Zahlen von 1 bis 20:\n\na &lt;- 1:20\n\nErzeuge eine Zahlenreihe von -2 bis +2 in Intervallen von 0.2:\n\na &lt;- seq(-2,2,0.2) \n\nRepliziere die Ziffer 4 dreimal:\n\na &lt;- rep(4,3)\n\nRepliziere die Zahlenfolge von 1 bis 4 dreimal:\n\na &lt;- rep(1:4,3)\n\nRepliziere in der Zahlenfolge von 1 bis 4 jede einzelne Ziffer dreimal:\n\na &lt;- rep(1:4,each=3)\n\nRepliziere in der Zahlenfolge von 1 bis 4 jede einzelne Ziffer dreimal, und repliziere den egsamten Vektor zweimal:\n\na &lt;- rep(1:4,each=3, times = 2)\n\nRepliziere in der Zahlenfolge von 1 bis 4 die 1 einmal, die 2 zweimal, die 3 dreimal, etc.:\n\na &lt;- rep(1:4,1:4)\n\n\n\n3.2 Navigation in Vektoren (subsetting)\nMithilfe eckiger Klammern kann man sich einzelne Elemente eines Vektors anzeigen lassen oder auch verändern.\n\nb &lt;- sqrt(1:5)\n\nDer gesamte Vektor b besteht aus fünf Zahlen:\n\nb\n\n[1] 1.000000 1.414214 1.732051 2.000000 2.236068\n\n\nMit b[2] kann man sich nur das zweite Element des Vektors anzeigen lassen; mit b[2] &lt;- 1000 kann man das zweite Element durch die Zahl 1000 ersetzen:\n\nb[2] &lt;- 1000\nb\n\n[1]    1.000000 1000.000000    1.732051    2.000000    2.236068\n\n\nMit b[4:5] &lt;- c(400, 500) kann man das vierte und fünfte Element durch die Zahlen 400 und 500 ersetzen:\n\nb[4:5] &lt;- c(400, 500)\nb\n\n[1]    1.000000 1000.000000    1.732051  400.000000  500.000000\n\n\nHier ein weiteres Beispiel für ein syntaktisch “fehlerhaftes” Subsetting, das trotzdem funktioniert. Man würde erwarten, dass b[4:5] &lt;- 45 eine Fehlermeldung gibt: zwei Elemente in einem Vektor sollen durch eine Zahl ersetzt werden. Die “sauberere” Lösung wäre b[4:5] &lt;- c(45, 45). Dennoch funktionier auch b[4:5] &lt;- 45:\n\nb[4:5] &lt;- 45\nb\n\n[1]    1.000000 1000.000000    1.732051   45.000000   45.000000\n\n\nWeitere “unzulässige” Operationen haben wieder denselben Effekt wie oben beschrieben. Ersetze ich ein Element des numerischen Vektors durch ein character-Element, wird der gesamte Vektor ebenfalls nach character umgewandelt.\n\nb[1] &lt;- \"hallo\"\nclass(b)\n\n[1] \"character\"\n\nb\n\n[1] \"hallo\"            \"1000\"             \"1.73205080756888\" \"45\"              \n[5] \"45\"              \n\n\n\n\n3.3 Funktionsliste I: Deskriptive Statistiken für numerische Vektoren\nAlle Funktionen, die sich sinnvoll auf numerische Vektoren anwenden lassen, können hier in ihrer Vollständigkeit nicht aufgeführt werden. Im Folgenden sollen jedoch die gebräuchlichsten und am häufigsten verwendeten aufgelistet werden:\n\nsum(). Berechnet die Summe aller Elemente eines Vektors. Nicht definiert für nicht-numerische Vektoren.\nmean(). Arithmetischer Mittelwert aller Elemente eines Vektors. Nicht definiert für nicht-numerische Vektoren.\nsd(). Standardabweichung\nvar(). Varianz\nmin(). Minimum\nmax(). Maximum\nscale(). Funktion zum Zentrieren oder z-Standardisieren. Die Funktion besitzt zusätzliche Argumente, je nachdem ob standardisiert oder nur zentriert werden soll. Für die zusätzlichen Argumente sind Standardeinstellungen (defaults) definiert – also “Voreinstellungen” der Argumente, die benutzt werden, wenn der Anwender die Funktionsargumente selbst nicht explizit definiert. Ein Vektor a &lt;- rnorm(100, mean = 2, sd = 8) mit Mittelwert 2 und Standardabweichung 8 wird mit scale(a, center = TRUE, scale = FALSE) zentriert und mit scale(a, center = TRUE, scale = TRUE) standardisiert. (Bei scale(a, center = FALSE, scale = FALSE) passiert einfach gar nichts; der Vektor wird 1:1 so zurückgegeben, wie er war.)\ntable() gibt eine Häufigkeitsverteilung aller Werte eines Vektors. Das ist sowohl für numerische als auch für nicht-numerische Vektoren möglich und für letztere häufig sinnvoller.\nsort(). Elemente auf- oder absteigend sortieren. Geht auch für nicht-numerische Vektoren (bei character-Vektoren wird in diesem Fall sortiert, bei Faktoren nach Ordnung der factor levels). Auch sort() enthält zusätzliche Argumente mit Voreinstellungen, z.B. das Argument decreasing, das angibt, ob auf- oder absteigend sortiert werden soll. Der default ist hier decreasing = FALSE; es wird also standardmäßig aufsteigend sortiert.\norder() funktioniert ähnlich wie sort(), gibt aber anstelle des Vektor-Wertes die Position zurück. Am einfachsten lässt sich das mit einem character-Vektor veranschaulichen – hier erkennt man auch, dass verschiedene R-Funktionen zueinander häufig redundant sind; es gibt verschiedene syntaktische Möglichkeiten, ein und dasselbe Ergebnis zu erhalten. Das macht R zum einen recht flexibel, zum anderen nicht unbedingt übersichtlich.\n\n\nvek &lt;- c(\"oh\", \"je\", \"mi\", \"neh\")\nsort(vek)\n\n[1] \"je\"  \"mi\"  \"neh\" \"oh\" \n\norder(vek)\n\n[1] 2 3 4 1\n\nvek[order(vek)]\n\n[1] \"je\"  \"mi\"  \"neh\" \"oh\" \n\n\n\nrev() kehrt die Reihenfolge der Elemente eines Vektors um\nunique() zeigt die Elemente des Vektors und lässt alle mehrfach vorhandenen Werte aus.\nduplicated() gibt einen logischen Vektor zurück, der für jedes Element anzeigt, ob es einzigartig ist (FALSE) oder mindestens zweimal vorkommt (TRUE)\nwhich() gibt zurück, an welcher Stelle (oder welchen Stellen) eines Vektors sich ein bestimmtes Element befindet, z.B. which(x == 5), oder eine bestimmte Bedingung erfüllt ist which(x &gt; 5), oder which(x != 5)\n\nDas sind, wie gesagt, bei weitem nicht alle Funktionen für numerische Vektoren. Wenn man eine bestimmte Operation durchführen möchte und den R-Befehl nicht kennt, hilft es häufig, die gewünschte Operation bei Google mit dem Zusatz “R” oder “R CRAN” einzugeben, vorzugsweise in englisch, z.B. “R sort by more than one variable”.\n\n\n3.4 Funktionsliste II: Bearbeiten von character-Vektoren\nIm Anwendungsfall von Large-scale Assessments im Bildungsforschungsbereich kommen character-Vektoren bspw. in Variablen- oder Itemnamen vor. Weniger häufig begegnet man ihnen unter anderem auch in Freitextfeldern in Schülerfragebögen. R bietet zahlreiche Möglichkeiten zur Bearbeitung von character-Vektoren, die auch reguläre Ausdrücke einschließen. Hier sollen nur die wichtigsten anhand prominenter Anwendungsfälle genannt werden. Man könnte sich beispielsweise vorstellen, in einem großen Datensatz mit vielen Variablen bestimmte Spalten oder Variablen identifizieren beziehungsweise verändern zu wollen. Der beispielhaft verwendete Vektor mit Variablennamen sei der folgende:\n\nvarnamen &lt;- c(\"idstud\", \"idclass\", \"D10101a\", \"D10102a\", \"D10102b\", \"D10103a\", \"D10201a\", \"D10301\", \"sex\", \"M15511a\", \"M15612a\", \"M15712b\", \"M15712c\", \"M15712d\", \"hisced\", \"parid\")\n\nInsgesamt gibt es hier nur 14 Variablen – in großen Large-scale Datensätzen hat man es ja zuweilen mit 1000 variablen und mehr zu tun.\n\nDie Funktion grep()\ngrep() erlaubt, einen character-vektor nach einem bestimmten Muster zu durchsuchen. Zurückgegeben werden alle Positionen, an denen dieses Muster auftritt. Man kann sich das ein bisschen wie die Suchfunktion in Word vorstellen. grep() hat verschiedene Argumente – pattern gibt das Muster an, was gesucht werden soll, x gibt den character-Vektor an, in dem gesucht werden soll, und value gibt als logisches Argument an, ob der Wert selbst oder seine Position zurückgegeben werden soll. Die Flexibilität von grep() rührt unter anderem auch daher, dass man als Suchmuster (pattern) auch reguläre Ausdrücke verwenden kann.\n\ngrep(pattern=\"id\", x=varnamen) findet die Positionen der Variablennamen, die ein “id” im Variablennamen haben.\ngrep(pattern=\"id\", x=varnamen, value=TRUE) zeigt die Variablennamen an, die ein “id” im Variablennamen haben.\ngrep(pattern=\"^id\", x=varnamen, value=TRUE) zeigt die Variablennamen an, die mit einem “id” im Variablennamen beginnen. (Der “Haken” vor dem “id” besagt, dass der Variablenname mit “id” beginnen muss)\nWenn ich id-Variablen finden will, mit aber nicht sicher bin, ob die in dem Datensatz groß oder klein geschrieben sind, ich aber im Zweifel beide haben will, kann man die “Oder”-verknüpfung nehmen (genaueres im Abschnitt “Logische Operatoren”): grep(pattern=\"ID|id\", x=varnamen, value=TRUE)\nAuch den letzten Befehl kann man “einengen”, dass nur die Variablennamen gesucht werden sollen, die mit einem groß oder kleingeschriebenen “ID” beginnen: grep(pattern=\"^ID|^id\", x=varnamen, value=TRUE)\nDas ist auch sinnvoll, wenn ich beispielsweise alle Variablennamen der Deutsch-Items identifizieren will und weiß, Deutsch-Items beginnen mit einem groß geschriebenen “D”: grep(pattern=\"^D\", x=varnamen, value=TRUE)\nGenauso kann man auch nur die Variablennamen suchen, die mit einem klein geschriebenen “a” aufhören: grep(pattern=\"a$\", x=varnamen, value=TRUE). Das “$”-Zeichen gibt an, dass nach dem Zeichen “a” der Variablenname zuende sein muss.\nMöglich (aber etwas komplizierter) sind auch Verknüpfungen der Art: Finde alle Variablennamen, die mit einem “D” beginnen und einem “a” aufhören. Hier handelt es sich um eine logische Verknüpfung zweier Bedingungen – genauer wird darauf im folgenden Abschnitt “Logische Operatoren” eingegangen. In R kann man das auf verschiedenen Wegen realisieren; eine Möglichkeit soll hier kurz demonstriert werden:\n\n\nbeginnt_mit_D &lt;- grep(pattern=\"^D\", x=varnamen, value=TRUE)\nendet_mit_a   &lt;- grep(pattern=\"a$\", x=varnamen, value=TRUE)\nbeides        &lt;- intersect(beginnt_mit_D, endet_mit_a)\nbeides\n\n[1] \"D10101a\" \"D10102a\" \"D10103a\" \"D10201a\"\n\n\n\n\nDie Funktionen gsub(), substr(), substring(), nchar() und strsplit()\n\ngsub() erlaubt es, Teile eines character-Vektors zu ersetzen. Sollen bspw. in der Variablenliste alle Namen, die mit “D101” beginnen, durch “D201” ersetzt werden, geht das mit gsub(pattern = \"D101\", replacement = \"D201\", x = varnamen). Hier ist es wichtig, die Stelligkeit zu beachten; gsub(pattern = \"D1\", replacement = \"D2\", x = varnamen) würde auch z.B. “D102” durch “D202” ersetzen. Möglich, aber nicht notwendig ist hier auch, die Ersetzung nur durchzuführen, wenn “D101” am Anfang des strings steht: gsub(pattern = \"^D101\", replacement = \"D201\", x = varnamen).\nsubstr() erlaubt es, bestimmte Teile eines character-Vektors “auszuschneiden”: wenn man bspw. nur die ersten 4 Zeichen ausschneiden will, geht das mit substr(x = varnamen, start = 1, stop = 4). Zeichenketten mit weniger als 4 Zeichen (hier etwa der Variablenname “sex”) werden dabei so beibehalten, wie sie waren.\nMöchte man von dem character-Vektor nur am Anfang bspw. das erste Zeichen entfernen und alle anderen beibehalten (egal, wie viele es sind), bietet sich die Funktion substring() an: substring(text = varnamen, first = 2)\nnchar() einem für jedes Element die Anzahl von Zeichen (Buchstaben und Ziffern): nchar(varnamen)\nstrsplit() teilt einen character-Vektor an einem definierten Zeichen\n\n\n\nDie Funktion paste()\nDie Funktion erlaubt es, character-Vektoren aus einzelnen Elementen “zusammenzubauen”. Soll beispielsweise an den Variablennamens-Vektor varnamen das Jahr der Erhebung mit angefügt werden, geht das mit folgendem Ausdruck: paste(varnamen, \"2012\", sep=\"_\"). An jeden Variablennamen wurde nun die Jahreszahl 2012 angefügt. Der Argument sep gibt dabei das Zeichen an, das als “Trenner” zweischen dem ursprünglichen Ausdruck und dem “Suffix” 2012 verwendet werden soll. paste() ist eine recht mächtige Funktion, so kann man bspw. auch an jeden Variablennamen die laufende Nummer anhängen, die er im character-Vektor einnimmt: paste(varnamen, 1:length(varnamen), sep=\"_\"). Es ist auch möglich, alle Elemente des Vektor zu einem einzigen großen String zusammenzubinden: paste(varnamen, collapse=\"_\"). Die wichtige, aber häufig Verwirrung stiftende Unterscheidung liegt hierbei zwischen den Separationsargumenten sep und collapse. sep definiert das Trennzeichen für die einzelnen Terme; collapse (ggf.) das Trennzeichen, mit dem die Ergebnisse zusammengefügt werden (sofern sie zusammengefügt werden sollen). Die Hilfeseite der paste-Funktion liefert einige anschauliche Beispiele, die die Unterscheidung zwischen beiden verdeutlichen.\n\n\nFunktionen aus eatTools\nIm Laufe der Datenaufbereitungsprozeduren am IQB wurden die obenstehenden Funktionen teils erweitert. Ohne Anspruch auf Vollständigkeit sollen weitere Möglichkeiten der Zeichenkettenmanipulation kurz genannt werden:\n\neatTools::crop() entfernt führende oder abschließende Leerzeichen (bzw. ein frei definiertes Zeichen) aus einem character-Vektor. Das ist bspw. dann sinnvoll, wenn in inakkurat aufbereiteten Datensätzen z.B. anstatt einer 1 der Wert 1 (also mit einem unbeabsichtrigten leerzeichen eingetragen wurde. Hier werden (nur der Anschaulichkeit zuliebe) alle führenden und abschließenden “D”s aus den Variablennamen entfernt: eatTools::crop(varnamen, char = \"D\")\neatTools::removeNumeric() entfernt alle Ziffern aus einem character-Vektor: eatTools::removeNumeric(varnamen)\neatTools::removeNonNumeric() entfernt alle Buchstaben aus einem character-Vektor und lässt nur die Ziffern übrig. Manche Elemente von varnamen sind hinterher leer. eatTools::removeNonNumeric(varnamen)\neatTools::removePattern() entfernt ein bestimmtes Muster aus einem character-Vektor: eatTools::removePattern(string = varnamen, pattern = \"id\")"
  },
  {
    "objectID": "docs/R_tutorials/R_ws1.html#logische-operatoren",
    "href": "docs/R_tutorials/R_ws1.html#logische-operatoren",
    "title": "R Workshop Einführung",
    "section": "4. Logische Operatoren",
    "text": "4. Logische Operatoren\nAllgemeines zu logischen Operatoren kann man auf der gleichnamigen Wikipediaseite finden: https://de.wikipedia.org/wiki/Logischer_Operator\nFür sämtliche Operatoren gibt es eine Entsprechung in R. Die Syntax ist dabei (weitgehend) äquivalent zu den angegeben Beispielen für C, C++, Java und PHP auf der Wikipediaseite. Der Wahrheitswert, der in R zurückgegeben wird, hat die Klasse logical und kann 2 Werte annehmen: TRUE oder FALSE. Der Wahrheitswert kann wiederum einem Objekt zugewiesen werden:\n\nistWahr &lt;- 4 == 5 \nclass(istWahr)\n\n[1] \"logical\"\n\nistWahr\n\n[1] FALSE\n\n\n\nLogische Operatoren ohne Verknüpfung\n\nist größer als: 4 &gt; 3\nist kleiner als: 4 &lt; 3\nist größer oder gleich: 4 &gt;= 3\nist kleiner oder gleich: 4 &lt;= 3\nist gleich: 4 == 3\nist ungleich: 4 != 3\n\n\n\nLogische Operatoren mit Verknüpfungen\n\nBedingung a UND Bedingung b sind erfüllt: 4 &gt; 3 & is.numeric(5)\nBedingung a ODER Bedingung b ist erfüllt: 4 &gt; 3 | is.numeric(5)\nENTWEDER Bedingung a ODER Bedingung b ist erfüllt: xor(4 &gt; 3, is.numeric(5)). Hier wird FALSE zurückgegeben, da beide Bedingungen erfüllt sind, und eben nicht nur entweder a oder b.\nBedingung b ist nicht erfüllt: !is.numeric(\"a\"). Hier wird TRUE zurückgegeben, denn es ist ja wahr, dass “a” nicht numerisch ist.\n\n\n\nArbeiten mit vektorwertigen logischen Verknüpfungen\nIn den oberen Beispielen wurden logische Abfragen immer nur für ein Objekt der Länge 1 durchgeführt. Man kann diese Funktionen aber auch auf Vektoren anwenden. Dazu folgendes hypothetisches Beispiel: ein großer Datensatz mit vielen Variablen soll in Mplus ausgewertet werden. In Mplus dürfen Variablennamen jedoch nur maximal 6 Zeichen haben. Gibt es also in dem Variablennamens-Vektor varnamen Variablennamen mit unerlaubter Länge? Um das zu prüfen, geht man in mehreren Schritten vor:\n\nZeige für jedes Element im Variablennamens-Vektor die Anzahl von Buchstaben an.\n\n\nanzahl &lt;- nchar(varnamen)\n\n\nPrüfe, für welche Variablennamen die zulässige Zeichenanzahl überschritten ist. Dazu wird ein logischer Vektor erzeugt, der den Wert TRUE annimmt, wenn die Zeichenanzahl maximal 6 beträgt, andernfalls FALSE.\n\n\nerlaubt &lt;- anzahl &lt;= 6\nerlaubt\n\n [1]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE\n[13] FALSE FALSE  TRUE  TRUE\n\n\n\nNun wird geprüft, ob diese Bedingung für alle Variablennamen erfüllt ist. Dazu können die Funktionen all() oder any() benutzt werden. all() fragt: Haben alle Elemente des Vektors erlaubt den Wahrheitswert TRUE? any() fragt: Gibt es irgendein Element in dem Vektors erlaubt, das den Wahrheitswert FALSE hat?\n\n\nall(erlaubt)\n\n[1] FALSE\n\nany(erlaubt == FALSE)\n\n[1] TRUE\n\n\n\nJa, einige Variablennamen haben eine größere Zeichenanzahl als 6. Man kann die Variablennamen auf die ersten 6 Zeichen reduzieren:\n\n\nvarnamen_neu &lt;- substr(varnamen, 1, 6)\n\n\nVariablennamen müssen jedoch stets einzigartig (unique) sein. Ist das jetzt noch der Fall? Dazu verwendet man die oben beschriebene Funktion duplicated() in Verbindung mit any:\n\n\nany(duplicated(varnamen_neu))\n\n[1] TRUE\n\n\nDer Wahrheitswert ist TRUE, es gibt also mindestens zwei Variablennamen, die jetzt identisch sind. An dieser Stelle könnte es passieren, dass man erstmal nicht weiter weiß. Eine Möglichkeit wäre, zu googlen: “r make unique”. So findet man eine Funktion namens make.unique, die es erlaubt, duplizierte Werte in character-Vektoren zu ersetzen, so dass sie einzigartig werden. Unglücklicherweise werden dadurch die Variablennamen wieder länger, als sie sein dürfen:\n\nvarnamen_neu2 &lt;- make.unique(varnamen_neu)\nany(nchar(varnamen_neu2)&gt;6)\n\n[1] TRUE\n\n\nTatsächlich gibt es für dieses Problem also keine einfache, “triviale” Lösung. Man könnte entweder vollständig willkürliche Namen vergeben, die dann aber keine Rückschlüsse auf die ursprüngliche Variablenbedeutung mehr zulassen, oder man experimentiert, beruhend auf folgenden Überlegungen: make.unique fügt an nicht-unique Variablennamen einen Punkt und eine laufende Nummer an, also zwei zusätzliche Zeichen. Also dürfte man nur die ersten 4 Zeichen der Variablennamen beibehalten:\n\nvarnamen_neu3 &lt;- make.unique(substr(varnamen, 1, 4))\nany(nchar(varnamen_neu3)&gt;6)\n\n[1] FALSE\n\nany(duplicated(varnamen_neu3))\n\n[1] FALSE\n\nvarnamen_neu3\n\n [1] \"idst\"   \"idcl\"   \"D101\"   \"D101.1\" \"D101.2\" \"D101.3\" \"D102\"   \"D103\"  \n [9] \"sex\"    \"M155\"   \"M156\"   \"M157\"   \"M157.1\" \"M157.2\" \"hisc\"   \"pari\"  \n\n\nHundertprotentig schön ist auch diese Variante nicht, weil nun auch von bereits einzigartigen Variablennamen nur die ersten vier Zeichen übrig behalten worden sind, obwohl es hier ja hätten sechs sein dürfen. Sofern eine solche Operation im Arbeitsalltag also häufiger gebraucht wird, wäre es günstig, sich dafür eine eigene Funktion zu schreiben, um diese Prozesse weniger umständlich zu gestalten. Dazu aber an anderer Stelle mehr."
  },
  {
    "objectID": "docs/R_tutorials/R_ws1.html#fehlende-werte-missing-values",
    "href": "docs/R_tutorials/R_ws1.html#fehlende-werte-missing-values",
    "title": "R Workshop Einführung",
    "section": "5. Fehlende Werte (missing values)",
    "text": "5. Fehlende Werte (missing values)\nFehlende Werte werden in R mit NA (not available) gekennzeichnet. Im Folgenden geht es nicht darum, wie in statistischen Analysen mit fehlenden Werten umgegangen werden kann, sondern wie man sie in R technisch behandelt. Dazu soll beispielhaft ein numerischer Vektor betrachtet werden, der fehlende Werte enthält:\n\nnumvek &lt;- rnorm(20, 0, 1)\nnumvek[c(3,6,9,19)] &lt;- NA\n\n\nDie häufigsten im Zusammenhang mit fehlenden Werten gebräuchlichen Funktionen sind:\n\nis.na() gibt einen Vektor der Klasse logical zurück, dessen Wert TRUE ist, wenn es sich um einen fehlenden Wert handelt: is.na(numvek). Wenn man lediglich wissen, ob es überhaupt irgendwelche fehlenden Werte gibt, kann man das mit any() verbinden: any(is.na(numvek)). Wenn man wissen will, an welcher Stelle die fehlenden Werte stehen, geht which(is.na(numvek))\nAchtung! Anders als man vielleicht vermuten würde, funktioniert which(numvek == NA) nicht!\nWenn ich nur die beobachteten Werte aus numvek extrahieren möchte, also alles ausschließen, was NA ist, geht das mit na.omit(numvek). Dieser Vektor ist mit nur noch 16 Elementen folglich kürzer als der ursprüngliche mit 20 Elementen: length(na.omit(numvek))\nMöchte man sich beispielsweise den Mittelwert eines Vektors anzeigen lassen, der fehlende Werte enthält, ist das Ergebnis ebenfalls NA: mean(numvek). Meist will man jedoch einfach das arithmetisches Mittel aller beobachteten Werte. Dazu könnte man einfach den Mittelwert unter Ausschluss der fehlenden Werte bestimmen: mean(na.omit(numvek)). Das ist dasselbe, wie wenn man in der Funktion mean() mit einem zusätzlichen Argument definiert, dass fehlende Werte vor der Berechnung ausgeschlossen werden sollen: mean(numvek, na.rm = TRUE). Man sieht wieder, dass verschiedene syntaktische Umsetzungen zu dem gewünschten Ergebnis führen können. Das logische Argument na.rm ist für viele Funktionen definiert, so etwa var(), sd(), lm(), glm(), etc.\n\n\n\nFehlende Werte in character-Vektoren\nHier gilt im Grunde dasselbe wie für numerische Vektoren. Auf ein paar Fallstricke soll hingewiesen werden:\n\ncharvek &lt;- c(\"France\", \"Belgium\", \"Poland\", NA, \"Denmark\", \"NA\", \"Austria\", \"\")\nwhich(is.na(charvek))\n\n[1] 4\n\n\nAuch in character-Vektoren müssen fehlende Werte ohne hochgestellte Anführungszeichen eingetragen werden; der sechste Wert \"NA\" wird nicht als fehlender Wert verstanden. Ebensowenig der achte Wert, der einfach ein leerer String ist. Letzteres ist insofern relevant, dass, wenn man etwa csv-Dateien mit R einliest, leere Zellen manchmal als leere Strings eingelesen werden, obwohl man sie eigentlich wie fehlende Werte behandelt wissen will. Um das \"NA\" und den leeren String in einen wirklichen fehlenden Wert umzuwandeln, kann beispielsweise die recode()-Funktion aus dem Paket car verwendet werden:\n\ncharvek_neu &lt;- car::recode(charvek, \"'NA'=NA; ''=NA\")\ncharvek_neu\n\n[1] \"France\"  \"Belgium\" \"Poland\"  NA        \"Denmark\" NA        \"Austria\"\n[8] NA"
  },
  {
    "objectID": "docs/R_tutorials/R_ws1.html#gut-zu-wissen",
    "href": "docs/R_tutorials/R_ws1.html#gut-zu-wissen",
    "title": "R Workshop Einführung",
    "section": "6. Gut zu wissen",
    "text": "6. Gut zu wissen\nDen Überblick über die vorhandenen Funktionen und Pakete zu behalten, ist nahezu unmöglich; allein auf CRAN gibt es tausende von R-Paketen. Aus unserer subjektiven Sicht sollen daher die wichtigsten Funktionen, die sich im Laufe des IQB-Lebens als unverzichtbar herausgestellt haben, hier kurz ohne Anspruch auf Vollständigkeit aufgelistet werden. Wo nötig, werden Links für weiterführende Literatur angegeben:"
  },
  {
    "objectID": "docs/R_tutorials/R_ws1.html#footnotes",
    "href": "docs/R_tutorials/R_ws1.html#footnotes",
    "title": "R Workshop Einführung",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Van Tay Media on Unsplash.↩︎"
  },
  {
    "objectID": "docs/R_tutorials/checkmate.html",
    "href": "docs/R_tutorials/checkmate.html",
    "title": "Using Checkmate",
    "section": "",
    "text": "With the checkmate package you can test, check and assert all kinds of arguments regarding type, length and much more. You can also write your own assert-functions.\n1"
  },
  {
    "objectID": "docs/R_tutorials/checkmate.html#setup",
    "href": "docs/R_tutorials/checkmate.html#setup",
    "title": "Using Checkmate",
    "section": "Setup",
    "text": "Setup\nInstall the package from CRAN with the following code. Then load it in your library.\n\ninstall.packages(\"checkmate\")\n\n\nlibrary(checkmate)"
  },
  {
    "objectID": "docs/R_tutorials/checkmate.html#different-outputs",
    "href": "docs/R_tutorials/checkmate.html#different-outputs",
    "title": "Using Checkmate",
    "section": "Different Outputs",
    "text": "Different Outputs\nThere are three main functions that we use: test, check and assert, which do similar things but produce different outputs. All functions have two ways to write them: test_numeric() with an underscore and testNumeric() with a capital Letter, but they both work the same. For simplicity we’ll just use one option.\nTo show the differences in outputs we check arguments for numeric input, as an example. See below to see checks for different types or attributes.\nTest\nTest-functions test whether an argument has certain attributes and gives you TRUE or FALSE output.\n\ntest_numeric(c(6:1, 4))\n\n[1] TRUE\n\ntest_numeric(\"hallo\") \n\n[1] FALSE\n\n\nCheck\nCheck-functions check whether an argument has certain attributes and gives you TRUE or a string containing an error message as an output. In the string you can see what kind of argument you should have given, and what you did wrong.\n\ncheck_numeric(c(6:1, 4))\n\n[1] TRUE\n\ncheck_numeric(\"hallo\") \n\n[1] \"Must be of type 'numeric', not 'character'\"\n\n\nAssert\nAssert-functions assert whether an argument has certain attributes and throw an error message if you it doesn’t. When you did everything correct, it doesn’t create an output. The error message contains the string from the check-functions.\n\nassert_numeric(c(6:1, 4))\nassert_numeric(\"hallo\")\n\nError: Assertion on '\"hallo\"' failed: Must be of type 'numeric', not 'character'.\n\n\nIf you save an assert_numeric() object into a variable x, it will contain the original object that you asserted.\n\nx &lt;- assert_numeric(c(6:1, 4))\nx\n\n[1] 6 5 4 3 2 1 4"
  },
  {
    "objectID": "docs/R_tutorials/checkmate.html#checking-for-type",
    "href": "docs/R_tutorials/checkmate.html#checking-for-type",
    "title": "Using Checkmate",
    "section": "Checking for Type",
    "text": "Checking for Type\nWith lsf.str() you can see all functions of the package.\n\nlsf.str(\"package:checkmate\")\n\nYou can check for specific types of arguments e.g. numeric, number, integer, double, character, string, logical, flag, missing, or data structure e.g. list, data_frame, array and so on. You can also look for attributes e.g. true, subset, named or atomic, and much more.\nDepending on what kind of output you want, you choose your function.\n\ncheck_list(list())\n\n[1] TRUE\n\ncheck_list(1:9)\n\n[1] \"Must be of type 'list', not 'integer'\"\n\n\nIf you are looking for a specific function you can use:\n\nls(\"package:checkmate\", pattern = \"atomic\") \n\n[1] \"assert_atomic\"        \"assert_atomic_vector\" \"check_atomic\"        \n[4] \"check_atomic_vector\"  \"expect_atomic\"        \"expect_atomic_vector\"\n[7] \"test_atomic\"          \"test_atomic_vector\"  \n\n\n\nChecking for Type: Data Frames\nIf you want to check the types of elements of a more complex data structure like a list or a data frame, you have to look at the arguments of the functions. Both have the argument types.\nFirst we create an example data frame with rows and columns named. It has numeric and character elements.\n\ndf &lt;- data.frame(klein = 1:3, mittel = 4:6, groß = c(\"7\", \"8\", \"9\"), row.names = c(\"A\", \"B\", \"C\"))\ndf\n\n  klein mittel groß\nA     1      4    7\nB     2      5    8\nC     3      6    9\n\n\nNow we can check for the types of the elements using the types argument. You can look at the whole data frame with df, at single columns using df[1] or df[klein] or at single rows using df[1,]. The error message will tell you the first element that has a type you didn’t check for.\n\n# checking the whole data frame\ncheck_data_frame(df, types = c(\"numeric\", \"character\"))\n\n[1] TRUE\n\ncheck_data_frame(df, types = \"numeric\")\n\n[1] \"May only contain the following types: {numeric}, but element 3 has type 'character'\"\n\n# checking individual columns\ncheck_data_frame(df[1], types = \"numeric\")\n\n[1] TRUE\n\ncheck_data_frame(df[\"klein\"], types = \"numeric\")\n\n[1] TRUE\n\ncheck_data_frame(df[3], types = \"numeric\")\n\n[1] \"May only contain the following types: {numeric}, but element 1 has type 'character'\"\n\n# checking for individual rows\ndf[1,]\n\n  klein mittel groß\nA     1      4    7\n\ncheck_data_frame(df[1,], types = \"numeric\")\n\n[1] \"May only contain the following types: {numeric}, but element 3 has type 'character'\"\n\n\nYou can also check the type of individual elements with df[1,1] or just the content of the columns by loosing the attributes of the data frame with df$klein or df[,1]. In this example they all have type integer. Now check_data_frame() doesn’t work anymore, because the data is no longer a data frame. You can use the normal checks from above.\n\ncheck_data_frame(df$klein, types = \"numeric\")\n\n[1] \"Must be of type 'data.frame', not 'integer'\"\n\ncheck_integer(df$klein)\n\n[1] TRUE\n\ncheck_numeric(df[,1])\n\n[1] TRUE\n\ncheck_double(df[1,1])\n\n[1] \"Must be of type 'double', not 'integer'\"\n\n\n\n\nChecking for Type: Lists\nLists work the same way. We create an example list a, with named elements of different types.\n\na &lt;- list(zahlen = 1:9, mon = month.abb, creator = \"IQB\")\nassert_list(a, types = c(\"numeric\", \"character\"))\nassert_character(a$mon)"
  },
  {
    "objectID": "docs/R_tutorials/checkmate.html#checking-for-length",
    "href": "docs/R_tutorials/checkmate.html#checking-for-length",
    "title": "Using Checkmate",
    "section": "Checking for Length",
    "text": "Checking for Length\nYou can check if an argument is scalar, but you cannot check for arbitrary lengths this way.\n\ncheck_scalar(1)\n\n[1] TRUE\n\ncheck_scalar(1:5)\n\n[1] \"Must have length 1\"\n\nls(\"package:checkmate\", pattern = \"length\")\n\ncharacter(0)\n\n\nTo check for arbitrary length of an argument, you have to use the len argument from the test, check or assert functions.\n\ncheck_character(month.abb, len = 12)\n\n[1] TRUE\n\ncheck_character(month.abb, len = 11)\n\n[1] \"Must have length 11, but has length 12\"\n\n\nThere are some other attributes you can check like this, e.g. min.len, max.len, unique or the length of elements in character vectors using n.chars, min.chars or max.chars.\n\ncheck_character(month.abb, n.chars = 3, min.chars = 2)\n\n[1] TRUE\n\ncheck_character(month.abb, n.chars = 2)\n\n[1] \"All elements must have exactly 2 characters, but element 1 has 3 chararacters\"\n\ncheck_character(month.abb, n.chars = 3, max.chars = 2)\n\n[1] \"All elements must have at most 2 characters, but element 1 has 3 characters\"\n\n\nFor more info what arguments you can check, type ?check_character in the console.\n\n?check_character\n\nYou can also check the lengths of lists or the length of columns/rows of a data frame in a similar way by using our example objects from above.\n\nassert_list(a, len = 3, min.len = 2, max.len = 3)\nassert_data_frame(df, min.cols = 1, max.cols = 3, ncols = 3)"
  },
  {
    "objectID": "docs/R_tutorials/checkmate.html#checking-names-via-subset",
    "href": "docs/R_tutorials/checkmate.html#checking-names-via-subset",
    "title": "Using Checkmate",
    "section": "Checking Names via Subset",
    "text": "Checking Names via Subset\nYou cannot check the names of complex objects directly. With the list or data_frame functions you can only check if the objects is named at all, or if the names are unique via the arguments names for lists and col.names or `row.names for data frames. Again using our example objects.\n\n# a &lt;- list(zahlen = 1:9, mon = month.abb, creator = \"IQB\")\n# df &lt;- data.frame(klein = 1:3, mittel = 4:6, groß = c(\"7\", \"8\", \"9\"), row.names = c(\"A\", \"B\", \"C\"))\n\nassert_list(a, names = \"named\")\nassert_data_frame(df, col.names = \"unique\")\n\nYou can check for specific names by using the subset functions. You can check whether the object give the argument choices contains x. If x is not a subset of choices you’ll get an error message.\n\n# lists\ncheck_subset(x = \"mon\", choices = names(a))\n\n[1] TRUE\n\n# data frames\ncheck_subset(c(\"klein\", \"mittel\", \"groß\", \"größer\"), choices = colnames(df))\n\n[1] \"Must be a subset of {'klein','mittel','groß'}, but has additional elements {'größer'}\"\n\n\nYou can also check for unique values or missings in a similar way. For more info see the help functions.\n\n?assert_list\n?assert_data_frame"
  },
  {
    "objectID": "docs/R_tutorials/checkmate.html#footnotes",
    "href": "docs/R_tutorials/checkmate.html#footnotes",
    "title": "Using Checkmate",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Felix Mittermeier on Unsplash↩︎"
  },
  {
    "objectID": "docs/git/github_pullrequests.html",
    "href": "docs/git/github_pullrequests.html",
    "title": "Pull requests with Github",
    "section": "",
    "text": "When people collaboratively develop software (R packages) and use Github as a repository, colleagues can review software parts before they are included in an updated package version.\n1"
  },
  {
    "objectID": "docs/git/github_pullrequests.html#recommended-workflow",
    "href": "docs/git/github_pullrequests.html#recommended-workflow",
    "title": "Pull requests with Github",
    "section": "Recommended Workflow",
    "text": "Recommended Workflow\n\nPull all changes from the relevant branch. Normally, this will be the branch main, but it might also happen that you want to extend on another branch.\nCreate and checkout (change onto the branch) on a new branch. By default, this will create a new branch from main, but you can also create a new branch from any other branch, if you want to extend on it.\nMake changes in your local repository.\nCommit them as often as possible. The more you commit, the more of you work gets saved regularly.\nIf you want to upload your changes, Push.\nRepeat 3 - 5 until you are done.\n\n\nInitiating a review\nOnce you are content with your changes and you want to finalize them, you can initiate a review:\n\nChange to the the Github page of the package (for example, eatTools repository) and start the pull request via “Compare & pull request”. This will open a new page, where you can customize your pull request.\nChoose your favorite reviewer under “Reviewer”. You can ask multiple people.\nEnter a comment for the request, specifying what you want the reviewer(s) to look for especially.\nClick on “create pull request” to start the request.\n\n\n\nReview Process\n\nNow the review process begins: The person that takes over the review assigns herself on the right side of the pull request page. Keep in mind our Code Conventions.\nThe reviewer can request changes, either general ones or specific ones by adding comments to specific lines of code.\nIn the end, the reviewer delivers their final verdict: approve or request changes.\nNow it’s the authors turn again: the author has to address the comments of the reviewer and make requested changes, or discuss why certain requested changes should not be made.\nThe changes can either be made on the branch the pull request was initiated on or on a new branch that branches out from this branch. If many changes are made, it might be easier to work on a separate branch and initiate a new pull request to merge it onto the parent branch (where the first pull request was made) to make clearer which new changes have been made.\nReiterate until the author and reviewer have reached an agreement.\nIf both are satisfied. On the GitHub Pull-request page, select “merge pull request into main” (or any other branch you want to and can merge on) at the bottom.\nFinally, the review branch can be deleted. Choose “delete” on the Github homepage. Then delete the local branch (i.e. in GitKraken) in the same way if necessary"
  },
  {
    "objectID": "docs/git/github_pullrequests.html#please-note",
    "href": "docs/git/github_pullrequests.html#please-note",
    "title": "Pull requests with Github",
    "section": "Please note",
    "text": "Please note\nAs long as the master/main branch and the new branch are not merged again, there are two “parallel” branches. The background to this is that - as long as developers are working in the new branch - users can always download the latest working version (i.e. the master branch) of the package. As a developer, you always have to check and be conscious about on which branch you are currently working on."
  },
  {
    "objectID": "docs/git/github_pullrequests.html#git-workflow-im-terminal-nh",
    "href": "docs/git/github_pullrequests.html#git-workflow-im-terminal-nh",
    "title": "Pull requests with Github",
    "section": "Git-Workflow im Terminal (NH)",
    "text": "Git-Workflow im Terminal (NH)\n\nGegebenenfalls: Auf den mainbranch wechseln: git checkout main\nVerifizieren, dass man auf dem richtigen branch ist: git status\nOnlinebranch lokal herunterladen: git pull\nGegebenenfalls: Neuen branch “branch_2” erstellen, und direkt darauf wechseln: git checkout -b branch_2\n(Alle) Änderungen stagen: git add .\nGestagte Änderungen commiten (mit aussagekräftiger Commitmessage): git commit -m \"implemented new function\"\nCommits hochladen: git push"
  },
  {
    "objectID": "docs/git/github_pullrequests.html#footnotes",
    "href": "docs/git/github_pullrequests.html#footnotes",
    "title": "Pull requests with Github",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Roman Synkevych on Unsplash.↩︎"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#zu-diesen-folien",
    "href": "docs/git/github_workshop/github_intro_slides.html#zu-diesen-folien",
    "title": "Einführung in Github",
    "section": "Zu diesen Folien",
    "text": "Zu diesen Folien\nHTML-Folien können durch tippen von e in PDF umgewandelt werden, und dann mit Drucken aus dem Browser abgespeichert werden, falls ihr darin kommentieren wollt."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#section",
    "href": "docs/git/github_workshop/github_intro_slides.html#section",
    "title": "Einführung in Github",
    "section": "",
    "text": "Roadmap\n\nMotivation\nWorkflow: Alleine\nWorkflow: Kollaborativ"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#git",
    "href": "docs/git/github_workshop/github_intro_slides.html#git",
    "title": "Einführung in Github",
    "section": "Git",
    "text": "Git\n\n\n\nVersion Control System\nEntwickelt von Linus Torvalds\nErlaubt das Tracken von (Plain Text) files:\n\nCode\nPräsentationen\nManuskripte\nWebseiten\n…"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#github",
    "href": "docs/git/github_workshop/github_intro_slides.html#github",
    "title": "Einführung in Github",
    "section": "GitHub",
    "text": "GitHub\n\n\n\nOnlinedienst für Git-Repositories\n“Soziales Netzwerk” für Git-Nutzende und Entwickler*innen\nGehört Microsoft.\nOpen Source Alternative: GitLab"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#section-1",
    "href": "docs/git/github_workshop/github_intro_slides.html#section-1",
    "title": "Einführung in Github",
    "section": "",
    "text": "Vor Git: Rechner stürzt ab."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#section-2",
    "href": "docs/git/github_workshop/github_intro_slides.html#section-2",
    "title": "Einführung in Github",
    "section": "",
    "text": "Mit Git: Alles liegt online."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#vor-git-wie-dokumentiert-man-das-nachvollziehbar",
    "href": "docs/git/github_workshop/github_intro_slides.html#vor-git-wie-dokumentiert-man-das-nachvollziehbar",
    "title": "Einführung in Github",
    "section": "Vor Git: Wie dokumentiert man das nachvollziehbar?",
    "text": "Vor Git: Wie dokumentiert man das nachvollziehbar?"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#mit-git-verzahnung-von-dokumentation-diskussion-und-code",
    "href": "docs/git/github_workshop/github_intro_slides.html#mit-git-verzahnung-von-dokumentation-diskussion-und-code",
    "title": "Einführung in Github",
    "section": "Mit Git: Verzahnung von Dokumentation, Diskussion und Code",
    "text": "Mit Git: Verzahnung von Dokumentation, Diskussion und Code"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#vor-git-wer-hat-was-wann-warum-geändert",
    "href": "docs/git/github_workshop/github_intro_slides.html#vor-git-wer-hat-was-wann-warum-geändert",
    "title": "Einführung in Github",
    "section": "Vor Git: Wer hat was, wann, warum geändert?",
    "text": "Vor Git: Wer hat was, wann, warum geändert?"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#mit-git-version-control",
    "href": "docs/git/github_workshop/github_intro_slides.html#mit-git-version-control",
    "title": "Einführung in Github",
    "section": "Mit Git: Version Control",
    "text": "Mit Git: Version Control"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#vor-git-dateibenennung",
    "href": "docs/git/github_workshop/github_intro_slides.html#vor-git-dateibenennung",
    "title": "Einführung in Github",
    "section": "Vor Git: Dateibenennung",
    "text": "Vor Git: Dateibenennung\n\n\n\nÜberschreiben von Datein.\nMit der falschen final-v10_commented_NH_03.docx weiterarbeiten.\nEtwas in Datei X ändern, aber die Änderung in allen abhängingen Datein vergessen (hier hilft uns Quarto auch ungemein)."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#mit-git-version-control---wiederherstellung-jedes-projektstands",
    "href": "docs/git/github_workshop/github_intro_slides.html#mit-git-version-control---wiederherstellung-jedes-projektstands",
    "title": "Einführung in Github",
    "section": "Mit Git: Version Control - Wiederherstellung jedes Projektstands",
    "text": "Mit Git: Version Control - Wiederherstellung jedes Projektstands"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#vor-git-kollaboration-über-email",
    "href": "docs/git/github_workshop/github_intro_slides.html#vor-git-kollaboration-über-email",
    "title": "Einführung in Github",
    "section": "Vor Git: Kollaboration über Email",
    "text": "Vor Git: Kollaboration über Email\nBeim Hin-und Herschicken von Skripten, Texten etc. kommt eventuell mal etwas durcheinander. Und wenn man parallel an einem Skript arbeiten will wird es sehr abspracheintensiv …"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#mit-git-branches",
    "href": "docs/git/github_workshop/github_intro_slides.html#mit-git-branches",
    "title": "Einführung in Github",
    "section": "Mit Git: Branches",
    "text": "Mit Git: Branches"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#mit-git-reviews",
    "href": "docs/git/github_workshop/github_intro_slides.html#mit-git-reviews",
    "title": "Einführung in Github",
    "section": "Mit Git: Reviews",
    "text": "Mit Git: Reviews"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#open-source-kollaboration",
    "href": "docs/git/github_workshop/github_intro_slides.html#open-source-kollaboration",
    "title": "Einführung in Github",
    "section": "Open Source Kollaboration",
    "text": "Open Source Kollaboration"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#section-3",
    "href": "docs/git/github_workshop/github_intro_slides.html#section-3",
    "title": "Einführung in Github",
    "section": "",
    "text": "Science"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#workflow",
    "href": "docs/git/github_workshop/github_intro_slides.html#workflow",
    "title": "Einführung in Github",
    "section": "Workflow",
    "text": "Workflow"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#editoren",
    "href": "docs/git/github_workshop/github_intro_slides.html#editoren",
    "title": "Einführung in Github",
    "section": "Editoren",
    "text": "Editoren\n\ndirekt auf GitHub\nTerminal\nGitHub Desktop\nRStudio\nViele mehr …"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#terminal",
    "href": "docs/git/github_workshop/github_intro_slides.html#terminal",
    "title": "Einführung in Github",
    "section": "Terminal",
    "text": "Terminal\n\nAnsonsten Windows Powershell/Linux Terminal öffnen, Pfad setzen (z.B. cd C:\\Users\\hafiznij\\Documents\\GitHub\\IQB-Methods) und dann von dort aus arbeiten."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#visuelle-editoren",
    "href": "docs/git/github_workshop/github_intro_slides.html#visuelle-editoren",
    "title": "Einführung in Github",
    "section": "Visuelle Editoren",
    "text": "Visuelle Editoren\n\n\nGithub Desktop\n\n\nRStudio Integration"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#rstudio-setup",
    "href": "docs/git/github_workshop/github_intro_slides.html#rstudio-setup",
    "title": "Einführung in Github",
    "section": "RStudio Setup",
    "text": "RStudio Setup\nTools - Global Options\n\n\n\n\nDiese Integration macht am meisten in der Verbindung mit einem RStudio-Projekt Sinn."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#section-4",
    "href": "docs/git/github_workshop/github_intro_slides.html#section-4",
    "title": "Einführung in Github",
    "section": "",
    "text": "Erste Schritte."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#konfigurieren-von-git",
    "href": "docs/git/github_workshop/github_intro_slides.html#konfigurieren-von-git",
    "title": "Einführung in Github",
    "section": "Konfigurieren von Git",
    "text": "Konfigurieren von Git\nEinmalig, in einem Terminal (z.B. das in RStudio, oder Windows Powershell):\ngit config --global user.name 'Your Name'\ngit config --global user.email 'your@email.com'\n\n\n\n\n\n\nÜbung\n\n\nTu das bitte einmal für deinen GitHub-Username und deine GitHub-email. Checke dann noch einmal ob das geklappt hat:\ngit config --global user.name\ngit config --global user.email"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#eigenes-repository-erstellen",
    "href": "docs/git/github_workshop/github_intro_slides.html#eigenes-repository-erstellen",
    "title": "Einführung in Github",
    "section": "Eigenes Repository erstellen",
    "text": "Eigenes Repository erstellen"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#eigenes-repository-erstellen-1",
    "href": "docs/git/github_workshop/github_intro_slides.html#eigenes-repository-erstellen-1",
    "title": "Einführung in Github",
    "section": "Eigenes Repository erstellen",
    "text": "Eigenes Repository erstellen\n\n\n\n\n\n\n\n\n\n\nÜbung\n\n\nErstelle dein erstes eigenes Repository."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#cloneerster-pull",
    "href": "docs/git/github_workshop/github_intro_slides.html#cloneerster-pull",
    "title": "Einführung in Github",
    "section": "Clone/Erster Pull",
    "text": "Clone/Erster Pull"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#sec-clone",
    "href": "docs/git/github_workshop/github_intro_slides.html#sec-clone",
    "title": "Einführung in Github",
    "section": "Clone",
    "text": "Clone\ngit clone url\n“Herunterladen” des Repositories auf den eigenen Rechner.\n\n\n\n\nIn RStudio:\nNew Project - Version Control - Git\nDas hat den Vorteil, dass direkt ein RStudio-Projekt und eine R-spezifische .gitignore Datei erstellt wird."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#clone",
    "href": "docs/git/github_workshop/github_intro_slides.html#clone",
    "title": "Einführung in Github",
    "section": "Clone",
    "text": "Clone\n\n\n\n\n\n\nÜbung\n\n\nClone das gerade erstellte Repository. Wenn du nicht RStudio dafür nutzt, erstelle außerdem ein RStudio-Projekt in dem geklonten Ordner (File - New Project - Existing Directory), sowie eine .gitignore Datei mit folgendem Inhalt:\n.Rproj.user\n.Rhistory\n.RData\n.Ruserdata\n\n\n\n\n\n\n\n\n\nWichtig\n\n\nArbeiten auf Netzlaufwerk kann zu Problemen mit Git führen! Deswegen wirklich immer lokal auf dem eigenen Rechner arbeiten."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#section-5",
    "href": "docs/git/github_workshop/github_intro_slides.html#section-5",
    "title": "Einführung in Github",
    "section": "",
    "text": "Exkurs: Fork\nRepository online kopieren. An diesem kann weitergearbeitet werden, als ob es ein eigenes Repository wäre."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#lokales-arbeiten",
    "href": "docs/git/github_workshop/github_intro_slides.html#lokales-arbeiten",
    "title": "Einführung in Github",
    "section": "Lokales Arbeiten",
    "text": "Lokales Arbeiten"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#lokales-arbeiten-1",
    "href": "docs/git/github_workshop/github_intro_slides.html#lokales-arbeiten-1",
    "title": "Einführung in Github",
    "section": "Lokales Arbeiten",
    "text": "Lokales Arbeiten\nÄnderungen im Repository werden lokal auf dem eigenen Rechner vorgenommen.\n\n\n\n\n\n\nÜbung\n\n\nErstelle eine .txt Datei in deinem lokalen Repository-Ordner. Schreibe in die Datei Hello World! und speichere sie ab."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#stage",
    "href": "docs/git/github_workshop/github_intro_slides.html#stage",
    "title": "Einführung in Github",
    "section": "Stage",
    "text": "Stage"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#stage-1",
    "href": "docs/git/github_workshop/github_intro_slides.html#stage-1",
    "title": "Einführung in Github",
    "section": "Stage",
    "text": "Stage\ngit add filename\ngit add .\nAuswählen der Datein, die zum Commit hinzugefügt werden sollen.\n\n\n\n\n\n\n\n\n\n\nÜbung\n\n\nStage deine gerade bearbeitete Datei, sowie das erstellte RStudio-Projekt und die .gitignore Datei. Ganz sauber wäre es, erst einmal nur die .txt Datei zu stagen, und dann die anderen Datein, um daraus insgesamt zwei Commits zu machen."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#commit",
    "href": "docs/git/github_workshop/github_intro_slides.html#commit",
    "title": "Einführung in Github",
    "section": "Commit",
    "text": "Commit"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#commit-1",
    "href": "docs/git/github_workshop/github_intro_slides.html#commit-1",
    "title": "Einführung in Github",
    "section": "Commit",
    "text": "Commit\ngit commit -m \"useful commit message\"\nSpeichern der Änderungen, mit kurzer Beschreibung was gemacht wurde (Commit Message)."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#section-6",
    "href": "docs/git/github_workshop/github_intro_slides.html#section-6",
    "title": "Einführung in Github",
    "section": "",
    "text": "Übung\n\n\nCommitte deine gerade gestagte Datei mit einer kurzen, prägnanten Commit Message. Wenn du Zwei Commits daraus machen willst, committe erst nur die gestagte .txt Datei, und stage und committe danach die anderen Datein."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#push",
    "href": "docs/git/github_workshop/github_intro_slides.html#push",
    "title": "Einführung in Github",
    "section": "Push",
    "text": "Push"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#push-1",
    "href": "docs/git/github_workshop/github_intro_slides.html#push-1",
    "title": "Einführung in Github",
    "section": "Push",
    "text": "Push\ngit push\nHochladen der Commits in das Online-Repository.\n\n\n\n\n\n\n\n\n\n\nÜbung\n\n\nPushe deinen Commits. Schaue dann im Online-Repository nach, ob die geänderte Datei dort auch erscheint."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#pull",
    "href": "docs/git/github_workshop/github_intro_slides.html#pull",
    "title": "Einführung in Github",
    "section": "Pull",
    "text": "Pull"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#pull-1",
    "href": "docs/git/github_workshop/github_intro_slides.html#pull-1",
    "title": "Einführung in Github",
    "section": "Pull",
    "text": "Pull\ngit pull\nDamit laden wir die neuesten Änderungen aus dem Online-Repository herunter. Vor allem beim kollaborativen Arbeiten sollte das gemacht werden, bevor man mit der eigenen Arbeit beginnt."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#gitignore",
    "href": "docs/git/github_workshop/github_intro_slides.html#gitignore",
    "title": "Einführung in Github",
    "section": ".gitignore",
    "text": ".gitignore\nDie .gitignore Datei wird im Repository-Ordner erstellt und enthält Datein, die nicht getrackt werden sollen (z.B. große Datensätze, Hilfsdatein …).\n.Rproj.user\n.Rhistory\n.RData\n.Ruserdata\n\n\n\n\n\n\nTipp\n\n\nNach Möglichkeit wollen wir vor allem die plain-Text Datein tracken. Wenn wir z.B. mit Quarto arbeiten, wollen wir die .qmd Datein tracken, aber nicht unbedingt die .html Datein, die darus erzeugt werden."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#section-7",
    "href": "docs/git/github_workshop/github_intro_slides.html#section-7",
    "title": "Einführung in Github",
    "section": "",
    "text": "Kollaboratives Arbeiten"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#branches",
    "href": "docs/git/github_workshop/github_intro_slides.html#branches",
    "title": "Einführung in Github",
    "section": "Branches",
    "text": "Branches"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#branches-1",
    "href": "docs/git/github_workshop/github_intro_slides.html#branches-1",
    "title": "Einführung in Github",
    "section": "Branches",
    "text": "Branches\ngit checkout -b new_branch\n\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\nVergiss nicht, vor der Erstellung zu pullen, damit die neuste Projekt-Version für Branch genutzt wird."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#branches-2",
    "href": "docs/git/github_workshop/github_intro_slides.html#branches-2",
    "title": "Einführung in Github",
    "section": "Branches",
    "text": "Branches"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#pull-requestsmerge",
    "href": "docs/git/github_workshop/github_intro_slides.html#pull-requestsmerge",
    "title": "Einführung in Github",
    "section": "Pull Requests/Merge",
    "text": "Pull Requests/Merge"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#pull-requests",
    "href": "docs/git/github_workshop/github_intro_slides.html#pull-requests",
    "title": "Einführung in Github",
    "section": "Pull Requests",
    "text": "Pull Requests"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#pull-requests-1",
    "href": "docs/git/github_workshop/github_intro_slides.html#pull-requests-1",
    "title": "Einführung in Github",
    "section": "Pull Requests",
    "text": "Pull Requests"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#reviewer-assignees-labels",
    "href": "docs/git/github_workshop/github_intro_slides.html#reviewer-assignees-labels",
    "title": "Einführung in Github",
    "section": "Reviewer, Assignees, Labels",
    "text": "Reviewer, Assignees, Labels"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#reviews",
    "href": "docs/git/github_workshop/github_intro_slides.html#reviews",
    "title": "Einführung in Github",
    "section": "Reviews",
    "text": "Reviews\nWenn eine Person als Reviewer angefragt wurde, sollte man mit dem Mergen warten, bis das Review abgeschlossen ist."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#reviews-1",
    "href": "docs/git/github_workshop/github_intro_slides.html#reviews-1",
    "title": "Einführung in Github",
    "section": "Reviews",
    "text": "Reviews"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#reviews-2",
    "href": "docs/git/github_workshop/github_intro_slides.html#reviews-2",
    "title": "Einführung in Github",
    "section": "Reviews",
    "text": "Reviews"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#review-änderungen-einarbeiten",
    "href": "docs/git/github_workshop/github_intro_slides.html#review-änderungen-einarbeiten",
    "title": "Einführung in Github",
    "section": "Review: Änderungen einarbeiten",
    "text": "Review: Änderungen einarbeiten\nDie verlangten Änderungen können direkt auf dem Branch, auf dem die Pull-Request erstellt wurde, vorgenommen werden. Dann committet und pusht man ganz normal, und die Pull-Request wird automatisch geupdated.\nAlternativ kann man einen neuen Branch my_branch_2 vom aktuellen Branch my_branch_1 abzweigen:\ngit checkout -b my_branch_2 my_branch_1\n… und dann eine neue Pull-Request erstellen."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#issues",
    "href": "docs/git/github_workshop/github_intro_slides.html#issues",
    "title": "Einführung in Github",
    "section": "Issues",
    "text": "Issues"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#verlinken-von-issues-und-pull-requests",
    "href": "docs/git/github_workshop/github_intro_slides.html#verlinken-von-issues-und-pull-requests",
    "title": "Einführung in Github",
    "section": "Verlinken von Issues und Pull Requests",
    "text": "Verlinken von Issues und Pull Requests\nJeder Issue und jede Pull-Request hat eine ID. Diese kann genutzt werden, um alles untereinander zu verlinken. Z.B. können Issue-IDs in Commit-Messages vermerkt werden, um automatisch Issues zu schließen:\ncloses #34"
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#merge",
    "href": "docs/git/github_workshop/github_intro_slides.html#merge",
    "title": "Einführung in Github",
    "section": "Merge",
    "text": "Merge\n\n\nDas ist einfach der Prozess, wenn ein Branch in einen anderen überführt wird. Meistens wird das nach einer angenommenen Pull-Request gemacht, geht aber auch völlig ohne."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#mehrere-leute-empfehlungen",
    "href": "docs/git/github_workshop/github_intro_slides.html#mehrere-leute-empfehlungen",
    "title": "Einführung in Github",
    "section": "Mehrere Leute: Empfehlungen",
    "text": "Mehrere Leute: Empfehlungen\n\nJede*r arbeitet auf eigenen Branches.\nRegelmäßiges mergen: Entweder in main, oder von main pullen und dann in den eigenen Branch mergen:\n\ngit checkout my_branch    # wechseln auf eigenen branch\ngit fetch origin          # lokal updaten \ngit merge origin/main     # mergen von main in eigenen branch\n\nReviews sollten möglichst zügig bearbeitet werden, da oft mit dem Review weitergearbeitet werden muss.\nGemergte Branches löschen, um Ordnung zu halten (lokal und online)."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#übung-kollaboratives-arbeiten",
    "href": "docs/git/github_workshop/github_intro_slides.html#übung-kollaboratives-arbeiten",
    "title": "Einführung in Github",
    "section": "Übung: Kollaboratives Arbeiten",
    "text": "Übung: Kollaboratives Arbeiten\n\n\n\n\n\n\nÜbung\n\n\nEinige dich mit der Person neben dir, wer wen zum zu Beginn erstellten Repository einlädt. Tut das dann, sodass ihr eines eurer Repositories zu zweit oder zu dritt bearbeiten könnt.\n\n\n\n\n\n\n\n\n\nTipp\n\n\nGehe oben in der Kopfzeile des Repos auf Settings und dann in der Seitenleiste links auf Collaborators and teams. Hier kannst du jetzt den GitHub-Username einer Person zum Repository hinzufügen."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#übung-clonen",
    "href": "docs/git/github_workshop/github_intro_slides.html#übung-clonen",
    "title": "Einführung in Github",
    "section": "Übung: Clonen",
    "text": "Übung: Clonen\n\n\n\n\n\n\nÜbung\n\n\nClone das Repository (wenn noch nicht geschehen)."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#übung-issues",
    "href": "docs/git/github_workshop/github_intro_slides.html#übung-issues",
    "title": "Einführung in Github",
    "section": "Übung: Issues",
    "text": "Übung: Issues\n\n\n\n\n\n\nÜbung 1\n\n\nErstellt euch gegenseitig einen Issue, den die andere Person dann bearbeiten soll. Das kann so etwas sein wie “Add two numbers” o.ä. Wichtig ist, dass aus der Beschreibung klar wird, was getan werden soll. Assignt die andere Person zu diesem Issue.\n\n\n\n\n\n\n\n\n\nÜbung 2\n\n\nErstelle einen eigenen Branch, auf dem du den dir zugewiesenen Issue in der nächsten Übung bearbeiten wirst."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#übung-issues-1",
    "href": "docs/git/github_workshop/github_intro_slides.html#übung-issues-1",
    "title": "Einführung in Github",
    "section": "Übung: Issues",
    "text": "Übung: Issues\n\n\n\n\n\n\nÜbung 1\n\n\nBearbeite jetzt den dir assignten Issue ersteinmal in einer neuen R-Datei. Erstellt euch also eine neue R-Datei im Repository Ordner und löst den Issue darin.\n\n\n\n\n\n\n\n\n\nÜbung 2\n\n\nJetzt kommt der spannende Part: stage, committe und pushe deine Änderungen.\n\nWenn du in die Commit-Message closes #Issuenumber schreibst, wird der Issue automatisch geschlossen, sobald die Pull-Request gemerged wird."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#übung-pull-requests",
    "href": "docs/git/github_workshop/github_intro_slides.html#übung-pull-requests",
    "title": "Einführung in Github",
    "section": "Übung: Pull-Requests",
    "text": "Übung: Pull-Requests\n\n\n\n\n\n\nÜbung\n\n\nErstelle eine Pull-Request, und wähle die andere Person als Reviewer."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#übung-review",
    "href": "docs/git/github_workshop/github_intro_slides.html#übung-review",
    "title": "Einführung in Github",
    "section": "Übung: Review",
    "text": "Übung: Review\n\n\n\n\n\n\nÜbung 1\n\n\nReviewe dann die andere, dir assignte Pull-Request. Verlange mind. eine kleine Änderung.\n\n\n\n\n\n\n\n\n\nÜbung 2\n\n\nArbeite die Änderung, die von dir verlangt wurde, ein und pushe erneut. Nutze dafür einfach den selben Branch, den du vorher für deine Pull-Request verwendet hast. Dadurch wird sie automatisch geupdated. Verlange ein erneutes Review.\n\n\n\n\n\n\n\n\n\nÜbung 3\n\n\nReviewe die Pull-Request der anderen Person erneut. Approve diesmal."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#übung-merge",
    "href": "docs/git/github_workshop/github_intro_slides.html#übung-merge",
    "title": "Einführung in Github",
    "section": "Übung: Merge",
    "text": "Übung: Merge\n\n\n\n\n\n\nÜbung 1\n\n\nMerge deine Pull-Request.\n\n\n\n\n\n\n\n\n\nÜbung 2\n\n\nMist! Dein Reviewer meldet dir zurück, dass es einen Fehler beim Review gab, und das Review bitte rückgängig gemacht werden soll.\nBrowse das Repository zu dem Commit, der vor dem ersten Review deiner Datei gemacht wurde und schaue in deiner R-Datei nach, was davor drin stand. Theoretisch ließe sich das auch alles über Git-Befehle wiederherstellen, das Browsen reicht uns jetzt aber erst einmal für diese Übung."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#merge-conflicts",
    "href": "docs/git/github_workshop/github_intro_slides.html#merge-conflicts",
    "title": "Einführung in Github",
    "section": "Merge-Conflicts",
    "text": "Merge-Conflicts\n\n\n\n“Git-Magie” funktioniert wirklich gut.\nManchmal weiß Git aber nicht, welche von zwei Änderungen aktueller ist: Merge-Conflicts.\nDiese müssen manuell gelöst werden."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#merge-conflicts-lösen",
    "href": "docs/git/github_workshop/github_intro_slides.html#merge-conflicts-lösen",
    "title": "Einführung in Github",
    "section": "Merge-Conflicts lösen",
    "text": "Merge-Conflicts lösen\n\n\nKlick auf Resolve conflicts.\nDas öffnet, unabhängig vom Editor (z.B. GitHub online, VS Code), einen Texteditor, indem die Datei so bearbeiten werden kann, wie sie am Ende aussehen soll.\nKonflikte sind mit &lt;&lt;&lt;&lt;&lt;&lt;&lt;, ======= und &gt;&gt;&gt;&gt;&gt;&gt;&gt; markiert. Wir können uns entscheiden, welche Änderungen wir behalten wollen.\nDie Konflikt-Marker müssen ebenfalls gelöscht werden, sodass die Datei am Ende genauso aussieht, wie sie auch committet werden soll.\nWenn fertig, klick auf Mark as resolved.\nCommitten & Mergen.\n\n\n\n\nEine ausführliche Dokumentation findet sich in den GitHub Docs."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#tipps-zum-vermeiden-von-merge-conflicts",
    "href": "docs/git/github_workshop/github_intro_slides.html#tipps-zum-vermeiden-von-merge-conflicts",
    "title": "Einführung in Github",
    "section": "Tipps zum Vermeiden von Merge-Conflicts",
    "text": "Tipps zum Vermeiden von Merge-Conflicts\n\nAbsprachen treffen, wer was bearbeitet. Am einfachsten geht das über den Assign-Button bei Issues und Pull-Requests.\nRegelmaßiges Pullen, um auf dem neusten Stand zu bleiben.\nRegelmäßiges Mergen in den Hauptbranch (z.B. main, oder ein development-Branch), damit die einzelnen Branches nicht zu sehr divergieren."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#übung-10",
    "href": "docs/git/github_workshop/github_intro_slides.html#übung-10",
    "title": "Einführung in Github",
    "section": "Übung",
    "text": "Übung\n\n\n\n\n\n\nÜbung 1\n\n\nPullt die Änderungen von main, damit ihr beide auf dem aktuellen Stand seid. Erstellt dann jeweils einen neuen Branch, auf dem ihr jetzt in der gleichen Datei in der gleichen Zeile Änderungen vornehmt. Das wird hoffentlich einen Merge-Conflict erzeugen.\n\n\n\n\n\n\n\n\n\nÜbung 2\n\n\nPusht eure Änderungen, und einigt euch, wer zuerst mergt. Diese Person bekommt noch keinen Merge-Conflict. Sobald gemergt wurde, kann die andere Person mergen. Das wird einen Merge-Conflict erzeugen. Löse ihn!\n\n\n\nWenn ihr wollt, könnt ihr danach nochmal tauschen, sodass die andere Person den Merge-Conflict lösen muss."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#section-8",
    "href": "docs/git/github_workshop/github_intro_slides.html#section-8",
    "title": "Einführung in Github",
    "section": "",
    "text": "Wichtig\n\n\nDenkt daran, dass alles was ihr in GitHub hochladet, auch im Internet landet. Zwar kann man Repositories auf privat stellen, aber Daten oder ähnliches, wie konkrete BT-Ergebnisse oder -Kapitel, die noch nicht veröffentlich wurden, sollte eher auf den Laufwerken belassen."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#workflow-empfehlungen",
    "href": "docs/git/github_workshop/github_intro_slides.html#workflow-empfehlungen",
    "title": "Einführung in Github",
    "section": "Workflow Empfehlungen",
    "text": "Workflow Empfehlungen\n\nPullen zu Beginn nicht vergessen, vor allem wenn man neue Branches erstellt.\nLieber eher kleinere Pull-Requests machen. Leichter zu reviewen, einfacher zu mergen und man bleibt enger an der aktuellen Entwicklung dran.\nMain in den eigenen Branch reinmergen, falls man da länger drauf arbeitet. Das erspart später ausufernede Merge-Conflicts.\nMöglichst viele thematisch abgetrennte Einheiten committen."
  },
  {
    "objectID": "docs/git/github_workshop/github_intro_slides.html#bildquellen",
    "href": "docs/git/github_workshop/github_intro_slides.html#bildquellen",
    "title": "Einführung in Github",
    "section": "Bildquellen",
    "text": "Bildquellen\n\n\nGitHub: Foto von Roman Synkevych auf Unsplash\nPC: Foto von Julia Joppien auf Unsplash\nWolke: Foto von Arteum.ro auf Unsplash\nTorvalds: https://commons.wikimedia.org/wiki/File:LinuxCon_Europe_Linus_Torvalds_03_(cropped).jpg\nGitHub Logo: Von GitHub - https://github.com/logos, CC BY 4.0, Link\nFoto von Viktor Forgacs auf Unsplash\nOpen: Foto von Viktor Forgacs auf Unsplash\nBabyfeet: Foto von Omar Lopez auf Unsplash\nFork: Foto von Ursula Gamez auf Unsplash\nCommit message: https://raw.githubusercontent.com/denitdao/o-rly-collection/refs/heads/main/public/book_covers/useless-git-commit-message.jpg\nAnts: Foto von Christian Holzinger auf Unsplash\nrivers: Foto von Muhil Mohan auf Unsplash\nMagic Tree: Foto von Meritt Thomas auf Unsplash"
  },
  {
    "objectID": "docs/statisticalQuestions.html",
    "href": "docs/statisticalQuestions.html",
    "title": "Statistical Questions",
    "section": "",
    "text": "Welcome to our questions learn page. Here you can find articles about common questions regarding statistics or our IQB internal eat-packages."
  },
  {
    "objectID": "docs/statisticalQuestions.html#articles-and-workshops",
    "href": "docs/statisticalQuestions.html#articles-and-workshops",
    "title": "Statistical Questions",
    "section": "Articles and Workshops",
    "text": "Articles and Workshops"
  },
  {
    "objectID": "docs/FAQ/FAQ3_Mehrebenenmodelle.html",
    "href": "docs/FAQ/FAQ3_Mehrebenenmodelle.html",
    "title": "Frage 3: Gesamt- vs. Gruppenmittelwert in Mehrebenenmodellen",
    "section": "",
    "text": "Wenn in Mehrebenenmodellen Interaktionen geschätzt werden, hängt die Schätzung des Intercepts wie auch die der Haupteffekte von der gewählten Skala der Prädiktoren ab. Die Haupteffekte repräsentieren den Effekt eines Prädiktors an der Stelle, an der die anderen Prädiktoren null sind. Da die Null oftmals kein natürlicher Wert von Prädiktoren ist (z. B. ist die Interpretation eines Effekts an der Stelle Klassengröße = 0 i. d. R. nicht sehr sinnvoll), wird das Zentrieren der Prädiktoren empfohlen. Hier kommen zwei Varianten in Frage: Zentrierung am Gruppenmittelwert und Zentrierung am Gesamtmittelwert. Für einen Prädiktor \\(X\\), der an Individuum \\(i\\) (\\(\\forall i \\in \\{1,…,i,…,n\\}\\)) in Gruppe \\(j\\) (\\(\\forall j \\in \\{1,…,j,…,J\\}\\)) erhoben wird, bedeutet eine Zentrierung am Gesamtmittelwert, dass man von diesem individuellen Wert \\(x_{ij}\\) den Gesamtmittelwert \\(M_X\\) abzieht, gemäß: \\(X_{ij}-M_X\\). Eine Zentrierung am Gruppenmittelwert bedeutet, dass man vom individuellen Wert \\(x_{ij}\\) den Mittelwert der jeweiligen Gruppe abzieht, gemäß: \\(X_{ij}-M_{X_j}\\) Hier eine grafische Darstellung dieser Zentrierungsmöglichkeiten eines Prädiktors:\nHier ist derselbe Prädiktor in seinen drei Zentrierungsformen in Relation zu einem Outcome abgebildet:\nWenn man nun eine einfache lineare Regression eines Outcomes auf den Prädiktor rechnet, kann man die Haupteffekte (Slopes) des unzentrierten Prädiktors und des Grand-Mean-zentrierten Prädiktors genau gleich interpretieren: Der Regressionskoeffizient beschreibt die Veränderung des Outcomes, wenn der Prädiktor um eine Einheit ansteigt. Dies gilt nicht für den Group-Mean-zentrierten Prädiktor: Dieser repräsentiert die erwartete Veränderung des Outcomes bei Zunahme des Prädiktors um eine durchschnittliche Einheit innerhalb der Gruppen."
  },
  {
    "objectID": "docs/FAQ/FAQ3_Mehrebenenmodelle.html#section",
    "href": "docs/FAQ/FAQ3_Mehrebenenmodelle.html#section",
    "title": "Frage 3: Gesamt- vs. Gruppenmittelwert in Mehrebenenmodellen",
    "section": "",
    "text": "Weitere Fragen und/oder deren Antworten können abgelegt und eingesehen werden unter: t:/SIG/SIG Methoden/Liste methodischer Fragen.docx"
  },
  {
    "objectID": "docs/FAQ/FAQ1_Imputationen.html",
    "href": "docs/FAQ/FAQ1_Imputationen.html",
    "title": "Frage 1: \\(R^2\\) richtig poolen",
    "section": "",
    "text": "Die von Harel (2009) vorgeschlagene Methode beinhaltet mehrere Schritte:\n1. Die Quadratwurzel aus \\(R^2\\) ziehen\n2. eine Fisher z-Transformation durchführen, damit der Wertebereich auf alle reellen Zahlen ausgeweitet wird\n3. Rubins Regeln für metrische Variablen anwenden\n4. mit einer inversen z-Transformation den Wert wieder zurückrechnen und quadrieren\nHarel, O. (2009). The estimation of R2 and adjusted R2 in incomplete data sets using multiple imputation. Journal of Applied Statistics, 36(10), 1109-1118."
  },
  {
    "objectID": "docs/FAQ/FAQ1_Imputationen.html#section",
    "href": "docs/FAQ/FAQ1_Imputationen.html#section",
    "title": "Frage 1: \\(R^2\\) richtig poolen",
    "section": "",
    "text": "Weitere Fragen und/oder deren Antworten können abgelegt und eingesehen werden unter: t:/SIG/SIG Methoden/Liste methodischer Fragen.docx"
  },
  {
    "objectID": "docs/beginners.html",
    "href": "docs/beginners.html",
    "title": "Beginners",
    "section": "",
    "text": "1\nWelcome to our beginners learn page. Here you can find material, links and articles to start you R journey."
  },
  {
    "objectID": "docs/beginners.html#r-introduction",
    "href": "docs/beginners.html#r-introduction",
    "title": "Beginners",
    "section": "R Introduction",
    "text": "R Introduction\nAn introduction to R with hands on examples and exercises can be found in Introduction to R.\nThere is also this Cheat Sheet: Base R to get an Overview for all basic functions in R."
  },
  {
    "objectID": "docs/beginners.html#articles-and-workshops",
    "href": "docs/beginners.html#articles-and-workshops",
    "title": "Beginners",
    "section": "Articles and Workshops",
    "text": "Articles and Workshops"
  },
  {
    "objectID": "docs/beginners.html#footnotes",
    "href": "docs/beginners.html#footnotes",
    "title": "Beginners",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Austin D on Unsplash.↩︎"
  },
  {
    "objectID": "docs/r_sig/23_07_31_apply/index.html",
    "href": "docs/r_sig/23_07_31_apply/index.html",
    "title": "The apply family",
    "section": "",
    "text": "1\nI can highly recommend the according chapter in R for Data Science in case you want to dive deeper."
  },
  {
    "objectID": "docs/r_sig/23_07_31_apply/index.html#for-loops",
    "href": "docs/r_sig/23_07_31_apply/index.html#for-loops",
    "title": "The apply family",
    "section": "For-loops",
    "text": "For-loops\nIn the last SIG we talked about for-loops.\nWhile for is definitely the most flexible of the looping options, we suggest you avoid it wherever you can, for the following two reasons:\n\n\nIt is not very expressive, i.e. takes a lot of code to do what you want.\n\n\nIt permits you to write horrible code.\n\n\nLet’s consider this example:\n\nexample_list &lt;- list(\n  \"vec_1\" = c(1:10),\n  \"vec_2\" = c(100:400),\n  \"vec_3\" = c(80:97, NA)\n)\nstr(example_list)\n\nList of 3\n $ vec_1: int [1:10] 1 2 3 4 5 6 7 8 9 10\n $ vec_2: int [1:301] 100 101 102 103 104 105 106 107 108 109 ...\n $ vec_3: int [1:19] 80 81 82 83 84 85 86 87 88 89 ...\n\n\nHere we have a list consisting of three vectors. Our goal is to sum them an output the result into a new vector. We could use a for-loop to do that:\n\nvec_sum &lt;- c()\nfor(i in 1: length(example_list)){\n  vec_sum[i] &lt;- sum(example_list[[i]], na.rm = TRUE)\n}\nvec_sum\n\n[1]    55 75250  1593\n\n\nOkay, that doesn’t look that complicated. But still, we need to define an empty vector at the beginning so we can save our sums, we need to iterate from 1:length(example_list), and manually select the \\(i^{th}\\) from the input list. That is not very expressive, and can be solved a lot easier. Enter, the apply-family:"
  },
  {
    "objectID": "docs/r_sig/23_07_31_apply/index.html#the-apply-family",
    "href": "docs/r_sig/23_07_31_apply/index.html#the-apply-family",
    "title": "The apply family",
    "section": "The apply-family",
    "text": "The apply-family\nThe apply-functions apply a function to a vector, list, matrix … and also always return a vector, list matrix …, depending on the specific function. Let’s rewrite our for-loop with sapply():\n\nvec_sum &lt;- sapply(example_list, sum)\nvec_sum\n\nvec_1 vec_2 vec_3 \n   55 75250    NA \n\n\nA lot less code and easier to understand! We just go over every list element and calculate its sum.\nIf we want to add another function argument, we can do that as well:\n\nvec_sum &lt;- sapply(example_list, sum, na.rm = TRUE)\nvec_sum\n\nvec_1 vec_2 vec_3 \n   55 75250  1593 \n\n\nWe can also define our own function:\n\nvec_sum &lt;- sapply(example_list, function(x){\n  res_sum &lt;- sum(x, na.rm = TRUE)\n  print(res_sum)\n  return(res_sum)\n})\n\n[1] 55\n[1] 75250\n[1] 1593\n\n\nHere we calculate the sum of object x, and then print it.\nFinally, which makes for even nicer code, we can define the function externally, to give it a concise name:\n\nprint_sum &lt;- function(vec){\n  res_sum &lt;- sum(vec, na.rm = TRUE)\n  print(res_sum)\n  return(res_sum)\n}\n\nvec_sum &lt;- sapply(example_list, print_sum)\n\n[1] 55\n[1] 75250\n[1] 1593\n\nvec_sum\n\nvec_1 vec_2 vec_3 \n   55 75250  1593 \n\n\nDepending of the output we want, we can choose different apply-functions:\n\nsapply()\nsapply() simplifies the result, so, e.g., it will return a vector if possible:\n\nsapply(example_list, print_sum)\n\n[1] 55\n[1] 75250\n[1] 1593\n\n\nvec_1 vec_2 vec_3 \n   55 75250  1593 \n\n\n\n\nvapply()\nSimilar to sapply(), but we can pre-specify a return value, so it might be safer to use:\n\nvapply(example_list, print_sum, integer(1))\n\n[1] 55\n[1] 75250\n[1] 1593\n\n\nvec_1 vec_2 vec_3 \n   55 75250  1593 \n\n\nBecause the result is an integer vector, we don’t get an error, but if we write this:\n\nvapply(example_list, print_sum, character(1))\n\n[1] 55\n\n\nError in vapply(example_list, print_sum, character(1)): values must be type 'character',\n but FUN(X[[1]]) result is type 'integer'\n\n\nThe function returns an error, because its output is an integer, and not a character vector.\n\n\nlapply()\nReturns a list:\n\nlapply(example_list, print_sum)\n\n[1] 55\n[1] 75250\n[1] 1593\n\n\n$vec_1\n[1] 55\n\n$vec_2\n[1] 75250\n\n$vec_3\n[1] 1593\n\n\n\n\n\n\n\n\nExercises\n\n\n\nWork with the iris data.frame (it is already included in Base R):\n\nExercise 1\nWrite a for-loop to determine the median of each column, if it is numeric. If not, return the column class with class(). Save the results in a character vector, so every element should be converted to character before saving it in the vector.\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\nvec_median &lt;- c()\nfor(i in 1:ncol(iris)){\n  if(is.numeric(iris[, i])){\n    vec_median[i] &lt;- as.character(median(iris[, i], na.rm = TRUE))\n  } else{\n    vec_median[i] &lt;- class(iris[, i])\n  }\n}\n\nvec_median\n\n[1] \"5.8\"    \"3\"      \"4.35\"   \"1.3\"    \"factor\"\n\n\n\n\n\n\n\nExercise 2\n\nDefine the body of the for loop as its own function. This function should take a vector, and, if this vector is numeric, output the median as a character, otherwise the class of the vector.\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\ncheck_median &lt;- function(vec){\n  if(is.numeric(vec)){\n    result &lt;- median(vec, na.rm = TRUE)\n  } else{\n    result &lt;- class(vec)\n  }\n  ## Convert to character, so our function always returns the correct type\n  result &lt;- as.character(result)\n  return(result)\n}\n\n## Check it:\ncheck_median(c(100, 1000))\n\n[1] \"550\"\n\ncheck_median(c(\"a\", \"b\"))\n\n[1] \"character\"\n\n\n\n\n\n\nUse it in the for-loop.\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\nvec_median &lt;- c()\nfor(i in 1:ncol(iris)){\n  vec_median[i] &lt;- check_median(iris[, i])\n}\n\nvec_median\n\n[1] \"5.8\"    \"3\"      \"4.35\"   \"1.3\"    \"factor\"\n\n\n\n\n\n\n\nExercise 3\nRewrite the for-loop from Exercise 1 with functions from the apply-family, so it returns the following objects. Define the function that gets applied on every input element externally, so we have cleaner code.\n\nA vector.\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\nsapply(iris, check_median)\n\nSepal.Length  Sepal.Width Petal.Length  Petal.Width      Species \n       \"5.8\"          \"3\"       \"4.35\"        \"1.3\"     \"factor\" \n\n\nOr, even better:\n\nvapply(iris, check_median, character(1))\n\nSepal.Length  Sepal.Width Petal.Length  Petal.Width      Species \n       \"5.8\"          \"3\"       \"4.35\"        \"1.3\"     \"factor\" \n\n\nWow, that’s pretty nice, we condensed our function to half a line by defining the function somewhere else, and not using a for-loop!\n\n\n\n\nA list.\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\nlapply(iris, check_median)\n\n$Sepal.Length\n[1] \"5.8\"\n\n$Sepal.Width\n[1] \"3\"\n\n$Petal.Length\n[1] \"4.35\"\n\n$Petal.Width\n[1] \"1.3\"\n\n$Species\n[1] \"factor\""
  },
  {
    "objectID": "docs/r_sig/23_07_31_apply/index.html#exercise-2",
    "href": "docs/r_sig/23_07_31_apply/index.html#exercise-2",
    "title": "The apply family",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nDefine the body of the for loop as its own function. This function should take a vector, and, if this vector is numeric, output the median as a character, otherwise the class of the vector.\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\ncheck_median &lt;- function(vec){\n  if(is.numeric(vec)){\n    result &lt;- median(vec, na.rm = TRUE)\n  } else{\n    result &lt;- class(vec)\n  }\n  ## Convert to character, so our function always returns the correct type\n  result &lt;- as.character(result)\n  return(result)\n}\n\n## Check it:\ncheck_median(c(100, 1000))\n\n[1] \"550\"\n\ncheck_median(c(\"a\", \"b\"))\n\n[1] \"character\"\n\n\n\n\n\n\nUse it in the for-loop.\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\nvec_median &lt;- c()\nfor(i in 1:ncol(iris)){\n  vec_median[i] &lt;- check_median(iris[, i])\n}\n\nvec_median\n\n[1] \"5.8\"    \"3\"      \"4.35\"   \"1.3\"    \"factor\""
  },
  {
    "objectID": "docs/r_sig/23_07_31_apply/index.html#exercise-3",
    "href": "docs/r_sig/23_07_31_apply/index.html#exercise-3",
    "title": "The apply family",
    "section": "Exercise 3",
    "text": "Exercise 3\nRewrite the for-loop from Exercise 1 with functions from the apply-family, so it returns the following objects. Define the function that gets applied on every input element externally, so we have cleaner code.\n\nA vector.\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\nsapply(iris, check_median)\n\nSepal.Length  Sepal.Width Petal.Length  Petal.Width      Species \n       \"5.8\"          \"3\"       \"4.35\"        \"1.3\"     \"factor\" \n\n\nOr, even better:\n\nvapply(iris, check_median, character(1))\n\nSepal.Length  Sepal.Width Petal.Length  Petal.Width      Species \n       \"5.8\"          \"3\"       \"4.35\"        \"1.3\"     \"factor\" \n\n\nWow, that’s pretty nice, we condensed our function to half a line by defining the function somewhere else, and not using a for-loop!\n\n\n\n\nA list.\n\n\n\n\n\n\n\nCaution\n\n\n\n\n\n\nlapply(iris, check_median)\n\n$Sepal.Length\n[1] \"5.8\"\n\n$Sepal.Width\n[1] \"3\"\n\n$Petal.Length\n[1] \"4.35\"\n\n$Petal.Width\n[1] \"1.3\"\n\n$Species\n[1] \"factor\""
  },
  {
    "objectID": "docs/r_sig/23_07_31_apply/index.html#footnotes",
    "href": "docs/r_sig/23_07_31_apply/index.html#footnotes",
    "title": "The apply family",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Kier in Sight Archives on Unsplash.↩︎"
  },
  {
    "objectID": "docs/r_sig/23_12_18_case_when/index.html",
    "href": "docs/r_sig/23_12_18_case_when/index.html",
    "title": "Case_when() function",
    "section": "",
    "text": "1\nThe case_when() function from the dplyr package of the tidyverse is a useful function for combining multiple ifelse() statements."
  },
  {
    "objectID": "docs/r_sig/23_12_18_case_when/index.html#how-to-use-it",
    "href": "docs/r_sig/23_12_18_case_when/index.html#how-to-use-it",
    "title": "Case_when() function",
    "section": "How to use it",
    "text": "How to use it\nLet’s take a look at a little example. Let’s consider a very simple data frame containing only a column of different countries:\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\ndf &lt;- data.frame(country = c(rep(\"Deu\", 4), \"Mexico\", \"Peru\", \"Ghana\", \"China\", \"Spanien\"))\n\nNow, let’s suppose we want to add a second column containing the continent of the country. We can either use nested ifelse() statements, which makes the coed quite hard to read:\n\ndf$continent &lt;- ifelse(df$country %in% c(\"Deu\", \"Spanien\"), \n                       yes = \"Europe\", \n                       no = ifelse(\n                         df$country == \"Mexico\" | df$country == \"Peru\", \n                         yes = \"America\",\n                         no = ifelse(\n                           df$country == \"Ghana\", \n                           yes = \"Africa\",\n                           no = \"Asia\"\n                       )\n                       ))\n\ndf\n\n  country continent\n1     Deu    Europe\n2     Deu    Europe\n3     Deu    Europe\n4     Deu    Europe\n5  Mexico   America\n6    Peru   America\n7   Ghana    Africa\n8   China      Asia\n9 Spanien    Europe\n\n\ncase_when() has a slightly different syntax, but is not nested, which makes it easier to read. Condition and output are separated by ~. So if the condition on the left side is met in a row, the function returns the value on the right side of ~:\n\ndf_2 &lt;- df %&gt;%\n  mutate(continent = case_when(country %in% c(\"Deu\", \"Spanien\") ~ \"Europe\", \n                               country %in% c(\"Mexico\", \"Peru\") ~ \"America\",\n                               country == \"Ghana\" ~ \"Africa\", \n                               TRUE ~ \"Another continent\"\n                                 )\n         )\ndf_2\n\n  country         continent\n1     Deu            Europe\n2     Deu            Europe\n3     Deu            Europe\n4     Deu            Europe\n5  Mexico           America\n6    Peru           America\n7   Ghana            Africa\n8   China Another continent\n9 Spanien            Europe\n\n\nWe wrap this statement into a mutate function to automatically create the new column continent from the output of case_when. The TRUE in the last row catches all conditions we haven’t dealt with further above. So all rows which haven’t met any of the above conditions will get the label “Another continent”."
  },
  {
    "objectID": "docs/r_sig/23_12_18_case_when/index.html#evaluation-order",
    "href": "docs/r_sig/23_12_18_case_when/index.html#evaluation-order",
    "title": "Case_when() function",
    "section": "Evaluation order",
    "text": "Evaluation order\ncase_when() goes from the top to the bottom. So if a row has met a statement, it is not considered further down. That’s why it makes sense to go from the most specific statements to the less specific ones. Otherwise the least specific ones might overwrite everything in the beginning:\n\ndf_3 &lt;- df %&gt;%\n  mutate(continent = case_when(country %in% c(df$country) ~ \"Other country\", \n                               country %in% c(\"Mexico\", \"Peru\") ~ \"America\",\n                               country == \"Ghana\" ~ \"Africa\", \n                               TRUE ~ \"Another continent\"\n                                 )\n         )\n\ndf_3  \n\n  country     continent\n1     Deu Other country\n2     Deu Other country\n3     Deu Other country\n4     Deu Other country\n5  Mexico Other country\n6    Peru Other country\n7   Ghana Other country\n8   China Other country\n9 Spanien Other country\n\n\nBecause our first statement already covers all rows, the rest is obsolete. This top-down working also makes the TRUE condition in our last line possible, because only those rows that haven’t been used yet will come this far, and all of them are caught (because TRUE always is true)."
  },
  {
    "objectID": "docs/r_sig/23_12_18_case_when/index.html#footnotes",
    "href": "docs/r_sig/23_12_18_case_when/index.html#footnotes",
    "title": "Case_when() function",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Sky Replacement Pack on Unsplash.↩︎"
  },
  {
    "objectID": "docs/r_sig/24_07_15_quarto_1/index.html",
    "href": "docs/r_sig/24_07_15_quarto_1/index.html",
    "title": "Reproducible manuscripts with Quarto",
    "section": "",
    "text": "1"
  },
  {
    "objectID": "docs/r_sig/24_07_15_quarto_1/index.html#yaml-header",
    "href": "docs/r_sig/24_07_15_quarto_1/index.html#yaml-header",
    "title": "Reproducible manuscripts with Quarto",
    "section": "YAML header",
    "text": "YAML header\nQuarto documents have the ending .qmd.\nThe YAML header, which begins on the top of the document with ---, and also ends with ---, contains global options for the document:\n---\ntitle: \"Reproducible manuscripts with Quarto\"\ndescription: \"R-SIG 15.07.2024\"\nauthor: \n  - name: Nicklas Hafiz\n  - affiliation: PhD student at the IQB, Methods team\ncategories: [R, quarto]\ndate: 07-15-2024\nbibliography: references.bib\ncsl: apa7.csl\nformat: pdf\n---\nAn overview of possible YAML-fields can be found here.\nNote the format field, which lets us quickly convert our document between pdf, word and html, and also lets us use one of many templates."
  },
  {
    "objectID": "docs/r_sig/24_07_15_quarto_1/index.html#markdown-text",
    "href": "docs/r_sig/24_07_15_quarto_1/index.html#markdown-text",
    "title": "Reproducible manuscripts with Quarto",
    "section": "Markdown text",
    "text": "Markdown text\nThe body of the document is written in markdown language. Some expressions:\n\n# for headers. Add as many # as you like for subheaders.\n**bold**: bold\n*italic*: italic\n``code\\\nLists: - for bullet points, 1. for numbered lists (beware: the line above the list has to be empty)\nLinebreaks: Two spaces at the end of a line.\nLinks: [text](url)"
  },
  {
    "objectID": "docs/r_sig/24_07_15_quarto_1/index.html#code-chunks",
    "href": "docs/r_sig/24_07_15_quarto_1/index.html#code-chunks",
    "title": "Reproducible manuscripts with Quarto",
    "section": "Code chunks",
    "text": "Code chunks\nWe can run code in different languages (like R, Julia, Python …) directly from our Quarto-file. In RStudio you can press Strg-Alt-i to insert a new r code chunk.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nathletes &lt;- readRDS(file = here::here(\"raw_data\", \"athletes.rds\"))\nhead(athletes)\n\n  NOC     ID                  Name Sex Age Height Weight        Team\n1 AFG 132181           Najam Yahya   M  NA     NA     NA Afghanistan\n2 AFG  87371 Ahmad Jahan Nuristani   M  NA     NA     NA Afghanistan\n3 AFG  44977     Mohammad Halilula   M  28    163     57 Afghanistan\n4 AFG    502     Ahmad Shah Abouwi   M  NA     NA     NA Afghanistan\n5 AFG 109153    Shakar Khan Shakar   M  24     NA     74 Afghanistan\n6 AFG  29626  Sultan Mohammad Dost   M  28    168     73 Afghanistan\n        Games Year Season      City     Sport\n1 1956 Summer 1956 Summer Melbourne    Hockey\n2 1948 Summer 1948 Summer    London    Hockey\n3 1980 Summer 1980 Summer    Moskva Wrestling\n4 1956 Summer 1956 Summer Melbourne    Hockey\n5 1964 Summer 1964 Summer     Tokyo Wrestling\n6 1960 Summer 1960 Summer      Roma Wrestling\n                                    Event Medal      Region\n1                     Hockey Men's Hockey  &lt;NA&gt; Afghanistan\n2                     Hockey Men's Hockey  &lt;NA&gt; Afghanistan\n3 Wrestling Men's Bantamweight, Freestyle  &lt;NA&gt; Afghanistan\n4                     Hockey Men's Hockey  &lt;NA&gt; Afghanistan\n5 Wrestling Men's Welterweight, Freestyle  &lt;NA&gt; Afghanistan\n6 Wrestling Men's Welterweight, Freestyle  &lt;NA&gt; Afghanistan\n\n\nWe can tweak the code execution via different execution options, which are written on top of the chunk:\n#| echo: false\n#| message: false\n\nlibrary(tidyverse)\nathletes &lt;- readRDS(file = here::here(  \"raw_data\", \"athletes.rds\"))\nhead(athletes)\nbecomes:\n\n\n  NOC     ID                  Name Sex Age Height Weight        Team\n1 AFG 132181           Najam Yahya   M  NA     NA     NA Afghanistan\n2 AFG  87371 Ahmad Jahan Nuristani   M  NA     NA     NA Afghanistan\n3 AFG  44977     Mohammad Halilula   M  28    163     57 Afghanistan\n4 AFG    502     Ahmad Shah Abouwi   M  NA     NA     NA Afghanistan\n5 AFG 109153    Shakar Khan Shakar   M  24     NA     74 Afghanistan\n6 AFG  29626  Sultan Mohammad Dost   M  28    168     73 Afghanistan\n        Games Year Season      City     Sport\n1 1956 Summer 1956 Summer Melbourne    Hockey\n2 1948 Summer 1948 Summer    London    Hockey\n3 1980 Summer 1980 Summer    Moskva Wrestling\n4 1956 Summer 1956 Summer Melbourne    Hockey\n5 1964 Summer 1964 Summer     Tokyo Wrestling\n6 1960 Summer 1960 Summer      Roma Wrestling\n                                    Event Medal      Region\n1                     Hockey Men's Hockey  &lt;NA&gt; Afghanistan\n2                     Hockey Men's Hockey  &lt;NA&gt; Afghanistan\n3 Wrestling Men's Bantamweight, Freestyle  &lt;NA&gt; Afghanistan\n4                     Hockey Men's Hockey  &lt;NA&gt; Afghanistan\n5 Wrestling Men's Welterweight, Freestyle  &lt;NA&gt; Afghanistan\n6 Wrestling Men's Welterweight, Freestyle  &lt;NA&gt; Afghanistan\n\n\nWe can also define global execution options for the whole ´.qmd´ file in the YAML header:\n---\ntitle: \"Reproducible manuscripts with Quarto\"\ndescription: \"R-SIG 15.07.2024\"\nauthor: \n  - name: Nicklas Hafiz\n  - affiliation: PhD student at the IQB, Methods team\ncategories: [R, quarto]\ndate: 07-15-2024\nbibliography: references.bib\ncsl: apa7.csl\nformat: pdf\nexecute:\n  echo: false\n  warning: false\n  message: false\n---"
  },
  {
    "objectID": "docs/r_sig/24_07_15_quarto_1/index.html#tables",
    "href": "docs/r_sig/24_07_15_quarto_1/index.html#tables",
    "title": "Reproducible manuscripts with Quarto",
    "section": "Tables",
    "text": "Tables\nTables can be a bit tricky. The great thing is: once you have styled them, they get updated automatically if some data changes. Also, there are a lot of different packages for building tables in markdown, here are some options:\n\nMarkdown\nFor some simple tables, the normal markdown syntax might be enough, see here.\n| Column 1 | Column 2 | Column 3 |\n|----------|----------|----------|\n| A1       | B1       | C1       |\n| A2       | B2       | C2       |\n\n\n\nColumn 1\nColumn 2\nColumn 3\n\n\n\n\nA1\nB1\nC1\n\n\nA2\nB2\nC2\n\n\n\n\n\nKable\nWith knitr::kable() you can build tables programmatically from code chunks:\n\njudo_athletes_ger &lt;- athletes %&gt;%\n  filter(Sport == \"Judo\", Region == \"Germany\", !is.na(Medal)) %&gt;%\n  select(Year, Name, Sex, Age, Height, Weight, Region, Medal) %&gt;%\n  arrange(Year, Sex)\n\nknitr::kable(judo_athletes_ger)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYear\nName\nSex\nAge\nHeight\nWeight\nRegion\nMedal\n\n\n\n\n1964\nWolfgang Hofmann\nM\n23\n177\n80\nGermany\nSilver\n\n\n1964\nKlaus Glahn\nM\n22\n187\n101\nGermany\nBronze\n\n\n1972\nPaul Barth\nM\n26\n181\n90\nGermany\nBronze\n\n\n1972\nKlaus Glahn\nM\n30\n187\n101\nGermany\nSilver\n\n\n1972\nDietmar Htger\nM\n25\n172\n70\nGermany\nBronze\n\n\n1976\nGnther Neureuther\nM\n20\n186\n95\nGermany\nSilver\n\n\n1980\nDetlef Ultsch\nM\n24\n170\n80\nGermany\nBronze\n\n\n1980\nDietmar Lorenz\nM\n30\n180\n93\nGermany\nGold\n\n\n1980\nHarald Heinke\nM\n25\n178\n78\nGermany\nBronze\n\n\n1980\nDietmar Lorenz\nM\n30\n180\n93\nGermany\nBronze\n\n\n1980\nKarl-Heinz Lehmann\nM\n23\n169\n71\nGermany\nBronze\n\n\n1984\nFrank Wieneke\nM\n22\n179\n78\nGermany\nGold\n\n\n1984\nArthur Schnabel\nM\n35\n182\n104\nGermany\nBronze\n\n\n1984\nGnther Neureuther\nM\n28\n186\n95\nGermany\nBronze\n\n\n1988\nFrank Wieneke\nM\n26\n179\n78\nGermany\nSilver\n\n\n1988\nMarcus “Marc” Meiling\nM\n26\n194\n95\nGermany\nSilver\n\n\n1988\nHenry Sthr\nM\n28\n194\n120\nGermany\nSilver\n\n\n1988\nSven Loll\nM\n24\n182\n71\nGermany\nSilver\n\n\n1988\nTorsten Brcht (Oehmigen-)\nM\n24\n178\n78\nGermany\nBronze\n\n\n1992\nRichard Trautmann\nM\n23\n168\n65\nGermany\nBronze\n\n\n1992\nUdo Gnther Quellmalz\nM\n25\n175\n65\nGermany\nBronze\n\n\n1996\nJohanna Hagn\nF\n23\n168\nNA\nGermany\nBronze\n\n\n1996\nUdo Gnther Quellmalz\nM\n29\n175\n65\nGermany\nGold\n\n\n1996\nFrank Mller\nM\n25\n189\n125\nGermany\nBronze\n\n\n1996\nRichard Trautmann\nM\n27\n168\n65\nGermany\nBronze\n\n\n1996\nMarko Spittka\nM\n25\n179\n88\nGermany\nBronze\n\n\n2000\nAnna-Maria Gradante\nF\n23\n154\n48\nGermany\nBronze\n\n\n2004\nYvonne Bnisch\nF\n23\n168\n61\nGermany\nGold\n\n\n2004\nJulia Matijass\nF\n30\n161\n48\nGermany\nBronze\n\n\n2004\nAnnett Bhm\nF\n24\n179\n83\nGermany\nBronze\n\n\n2004\nMichael Jurack\nM\n25\n190\n100\nGermany\nBronze\n\n\n2008\nOle Bischof\nM\n28\n180\n81\nGermany\nGold\n\n\n2012\nKerstin Thiele\nF\n25\n168\n70\nGermany\nSilver\n\n\n2012\nDimitri Peters\nM\n28\n188\n100\nGermany\nBronze\n\n\n2012\nOle Bischof\nM\n32\n180\n81\nGermany\nSilver\n\n\n2012\nAndreas Tlzer\nM\n32\n192\n131\nGermany\nBronze\n\n\n2016\nLaura Vargas Koch\nF\n26\n173\n70\nGermany\nBronze\n\n\n\n\n\nTo get more styling options, mainly for HTML table output, you can use kableExtra.\n\n\nAPA tables\nFor APA tables, I’ve found the rempsyc package which helps in building APA tables, but there are other options like flextable or gt as well:\n#| label: tbl-judo\n#| tbl-cap: Table with penguins species flipper length.\n\nlibrary(rempsyc)\n\nnice_table(\n  judo_athletes_ger\n)\n\n\n\n\nTable 1: German olympic medal winners in Judo.\n\n\n\nYearNameSexAgeHeightWeightRegionMedal1,964Wolfgang HofmannM2317780.00GermanySilver1,964Klaus GlahnM22187101.00GermanyBronze1,972Paul BarthM2618190.00GermanyBronze1,972Klaus GlahnM30187101.00GermanySilver1,972Dietmar HtgerM2517270.00GermanyBronze1,976Gnther NeureutherM2018695.00GermanySilver1,980Detlef UltschM2417080.00GermanyBronze1,980Dietmar LorenzM3018093.00GermanyGold1,980Harald HeinkeM2517878.00GermanyBronze1,980Dietmar LorenzM3018093.00GermanyBronze1,980Karl-Heinz LehmannM2316971.00GermanyBronze1,984Frank WienekeM2217978.00GermanyGold1,984Arthur SchnabelM35182104.00GermanyBronze1,984Gnther NeureutherM2818695.00GermanyBronze1,988Frank WienekeM2617978.00GermanySilver1,988Marcus \"Marc\" MeilingM2619495.00GermanySilver1,988Henry SthrM28194120.00GermanySilver1,988Sven LollM2418271.00GermanySilver1,988Torsten Brcht (Oehmigen-)M2417878.00GermanyBronze1,992Richard TrautmannM2316865.00GermanyBronze1,992Udo Gnther QuellmalzM2517565.00GermanyBronze1,996Johanna HagnF23168GermanyBronze1,996Udo Gnther QuellmalzM2917565.00GermanyGold1,996Frank MllerM25189125.00GermanyBronze1,996Richard TrautmannM2716865.00GermanyBronze1,996Marko SpittkaM2517988.00GermanyBronze2,000Anna-Maria GradanteF2315448.00GermanyBronze2,004Yvonne BnischF2316861.00GermanyGold2,004Julia MatijassF3016148.00GermanyBronze2,004Annett BhmF2417983.00GermanyBronze2,004Michael JurackM25190100.00GermanyBronze2,008Ole BischofM2818081.00GermanyGold2,012Kerstin ThieleF2516870.00GermanySilver2,012Dimitri PetersM28188100.00GermanyBronze2,012Ole BischofM3218081.00GermanySilver2,012Andreas TlzerM32192131.00GermanyBronze2,016Laura Vargas KochF2617370.00GermanyBronze\n\n\n\n\n\n\n\nLabels\nTables that are build programmatically can be labeled with #| label: tbl-judo at the top of the chunk. This will always put the correct number in the caption and also lets you cross-reference the table in your text by writing @tbl-judo Table 1.\nThe apaquarto template will take care of correctly rendering it to APA-style.\nCaptions can be written with #| tbl-cap: German olympic medal winners in Judo.."
  },
  {
    "objectID": "docs/r_sig/24_07_15_quarto_1/index.html#formatting-model-output",
    "href": "docs/r_sig/24_07_15_quarto_1/index.html#formatting-model-output",
    "title": "Reproducible manuscripts with Quarto",
    "section": "Formatting model output",
    "text": "Formatting model output\nThere are some packages out there that help you to format output of statistical models. Let’s fit a simple logistic regression model to predict an athletes medal win by country (Germany or Japan) in Judo:\n\nlibrary(tidyverse)\n\nathletes_judo &lt;- readRDS(file = here::here(\"raw_data\", \"athletes.rds\")) %&gt;%\n  mutate(Medal_bi = ifelse(is.na(Medal), 0, 1)) %&gt;%\n  filter(Sport == \"Judo\", Region %in% c(\"Germany\", \"Japan\"))\n\n\nmodel &lt;- glm(Medal_bi ~ Region, family = binomial(link = \"logit\"), data = athletes_judo)\n\nNormally, the output looks something like this:\n\nsummary(model)\n\n\nCall:\nglm(formula = Medal_bi ~ Region, family = binomial(link = \"logit\"), \n    data = athletes_judo)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -0.9740     0.1930  -5.048 4.46e-07 ***\nRegionJapan   1.5982     0.2671   5.983 2.19e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 364.15  on 263  degrees of freedom\nResidual deviance: 325.42  on 262  degrees of freedom\nAIC: 329.42\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nTidy up!\nNow we have multiple options to easily extract the results of this regression. Most prominently, there is the broom package:\n\nlibrary(broom)\n\nmodel_broom &lt;- tidy(model)\nmodel_broom\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic       p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n1 (Intercept)   -0.974     0.193     -5.05 0.000000446  \n2 RegionJapan    1.60      0.267      5.98 0.00000000219\n\n\nIf we want to convert the estimates to Odds:\n\nmodel_broom &lt;- tidy(model, exponentiate = TRUE)\nmodel_broom\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic       p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n1 (Intercept)    0.378     0.193     -5.05 0.000000446  \n2 RegionJapan    4.94      0.267      5.98 0.00000000219\n\n\nAnd if we want to extract the fit statistics:\n\nglance(model)\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1          364.     263  -163.  329.  337.     325.         262   264\n\n\n\n\n\n\n\n\nTip\n\n\n\nThis works with many different model types, from t-tests over linear models to GLMs and multi level models and even lavaan output. They might be split out over multiple packages, multi level models for example can be tidied with broom.mixed.\n\n\n\n\nReporting\nWe can also let R write our report section for us ;):\n\nlibrary(report)\n\nreport(model)\n\nWe fitted a logistic model (estimated using ML) to predict Medal_bi with Region\n(formula: Medal_bi ~ Region). The model's explanatory power is moderate (Tjur's\nR2 = 0.14). The model's intercept, corresponding to Region = Germany, is at\n-0.97 (95% CI [-1.36, -0.61], p &lt; .001). Within this model:\n\n  - The effect of Region [Japan] is statistically significant and positive (beta\n= 1.60, 95% CI [1.08, 2.13], p &lt; .001; Std. beta = 1.60, 95% CI [1.08, 2.13])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald z-distribution approximation.\n\n\nIf you want, take a look at report, it has many more functions to make the reporting workflow of your model a lot easier.\n\n\n\n\n\n\nAutomate in-text values\n\n\n\nEven when not using report or some similar package, we can still extract the values automatically from a model and put them programmatically into the text. This can be achieved by simply adding an inline-codechunck into our markdown text:\n\nThe model’s intercept, corresponding to Region = Germany, is at 0.38.\n\n\n\n\n\n\nTip\n\n\n\nMaybe put the data extraction into an own object to keep the text more readable:\n\nmodel_intercept &lt;- model_broom %&gt;% filter(term == \"(Intercept)\") %&gt;% pull(estimate) %&gt;% round(2)\n\n\nThe model’s intercept, corresponding to Region = Germany, is at 0.38.\n\n\n\n\n\n\nAPA tables\nFor example with rempsyc:\n\nlibrary(rempsyc)\n\nnice_table(model_broom, broom = \"glm\")\n\nTermestimateSEtp(Intercept)0.380.19-5.05&lt; .001***RegionJapan4.940.275.98&lt; .001***"
  },
  {
    "objectID": "docs/r_sig/24_07_15_quarto_1/index.html#plots",
    "href": "docs/r_sig/24_07_15_quarto_1/index.html#plots",
    "title": "Reproducible manuscripts with Quarto",
    "section": "Plots",
    "text": "Plots\nPlots can be very easily created from within a code chunk:\n\nbest_by_sport &lt;- athletes %&gt;%\n  ## Get all gold medalists\n  filter(Medal == \"Gold\") %&gt;%\n  ## Group them by sport and region\n  group_by(Sport, Region) %&gt;%\n  ## count the number of medals each country has per sport category\n  count(Medal) %&gt;%\n  ## Now only group by sport, so we can extract the maximum medal row by sport, and not by sport and country\n  group_by(Sport) %&gt;%\n  ## Extract the country with the most medals\n  slice(which.max(n))\n\n\n\np1 &lt;- ggplot(\n  data = best_by_sport,\n  aes(\n    x = Sport,\n    y = n\n  )\n) +\n  geom_col(aes(fill = Region, x = reorder(Sport, n))) +\n  geom_text(aes(label = Region), hjust = -0.3, angle = 90, size = 2.5) +\n  theme_classic() +\n  ## And turn the axis labels again, because the new theme has overwritten our theme\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n  ## Specify which colors are used for the filling. They are from the package viridsLite, so you might need to install it.\n  scale_fill_manual(values = viridisLite::viridis(19)) +\n  ggtitle(\"Country with the most Olympic gold medal winners by sport\") +\n  xlab(\"Sport\") +\n  ylab(\"Number of gold medal winners\")\n\nAgain, we can tweak the layout, captions etc. via the chunk options, see here for an overview.\n#| fig-height: 8\n#| fig-width: 11\n\np1"
  },
  {
    "objectID": "docs/r_sig/24_07_15_quarto_1/index.html#citations",
    "href": "docs/r_sig/24_07_15_quarto_1/index.html#citations",
    "title": "Reproducible manuscripts with Quarto",
    "section": "Citations",
    "text": "Citations\nCitations are saved in .bib files. The .bib format can be chosen to download or copy on almost every website, often next to APA and others. It looks like this:\n@article{allport1936trait,\n  title={Trait-names: A psycho-lexical study.},\n  author={Allport, Gordon W and Odbert, Henry S},\n  journal={Psychological monographs},\n  volume={47},\n  number={1},\n  pages={i},\n  year={1936},\n  publisher={Psychological Review Company}\n}\n\n@book{darwin1859,\n  added-at = {2008-05-27T04:02:47.000+0200},\n  address = {London},\n  author = {Darwin, Charles},\n  biburl = {https://www.bibsonomy.org/bibtex/2d70d713c717fb28384fb073c9f6dfbc2/neilernst},\n  citeulike-article-id = {2376343},\n  interhash = {c738acbb887362be5b0e6abc51be42d3},\n  intrahash = {d70d713c717fb28384fb073c9f6dfbc2},\n  keywords = {evolution},\n  note = { or the Preservation of Favored Races in the Struggle for Life},\n  priority = {2},\n  publisher = {Murray},\n  timestamp = {2008-05-27T04:02:47.000+0200},\n  title = {On the Origin of Species by Means of Natural Selection},\n  year = 1859\n}\nOf course, you should still check if the fields are filled in correctly. If you have created a references.bib file in your project directory, you can include it in your quarto document by adding bibliography: references.bib to your YAML header.\nTo cite a reference in you text, you can use an @ in front of the tag like @darwin1859 Darwin (1859) , or [@allport1936trait] (Allport & Odbert, 1936).\n\nReferencing R packages\nR packages are an important part of your analysis, and should be cited as such. The package grateful helps you with that.\nTo use it, put a grateful-refs.bib file into your YAML header:\n---\ntitle: \"Reproducible manuscripts with Quarto\"\ndescription: \"R-SIG 15.07.2024\"\nauthor: \n  - name: Nicklas Hafiz\n  - affiliation: PhD student at the IQB, Methods team\ncategories: [R, quarto]\ndate: 07-15-2024\nbibliography: \n  - references.bib\n  - grateful-refs.bib\ncsl: apa7.csl\nformat: pdf\n---\nBy using this list syntax, we can add multiple .bib-files to our quarto document. Then we only have to call the citation function in a code chunk:\n\ngrateful::cite_packages(output = \"paragraph\", out.dir = \".\")\n\nWe used R version 4.4.2 (R Core Team, 2024) and the following R packages: flextable v. 0.9.7 (Gohel & Skintzos, 2024), here v. 1.0.1 (Müller, 2020), knitr v. 1.49 (Xie, 2014, 2015, 2024), rempsyc v. 0.1.8 (Thériault, 2023), report v. 0.5.9 (Makowski et al., 2023), rmarkdown v. 2.29 (Allaire et al., 2024; Xie et al., 2018, 2020), tidyverse v. 2.0.0 (Wickham et al., 2019), viridisLite v. 0.4.2 (Garnier et al., 2023).\n\n\n\n\nCitation styles\nAgain, because we have our references in a plain text format, we can easily convert between different citation styles. One way to do this is to provide th csl argument in the YAML header, like so:\n---\ntitle: \"Reproducible manuscripts with Quarto\"\ndescription: \"R-SIG 15.07.2024\"\nauthor: \n  - name: Nicklas Hafiz\n  - affiliation: PhD student at the IQB, Methods team\ncategories: [R, quarto]\ndate: 07-15-2024\nbibliography: references.bib\ncsl: apa7.csl\nformat: pdf\n---\n.csl files can just be put into your project folder. They define the citation style, and can for example be downloaded from Zoteros style repository.\n\n\nReference section\nThe references will be automatically generated at the end of your document. Alternatively, you can include it where you want with\n::: {#refs}\n:::\n\n\nAllaire, J., Xie, Y., Dervieux, C., McPherson, J., Luraschi, J., Ushey, K., Atkins, A., Wickham, H., Cheng, J., Chang, W., & Iannone, R. (2024). rmarkdown: Dynamic documents for r. https://github.com/rstudio/rmarkdown\n\n\nAllport, G. W., & Odbert, H. S. (1936). Trait-names: A psycho-lexical study. Psychological Monographs, 47(1).\n\n\nDarwin, C. (1859). On the origin of species by means of natural selection. Murray.\n\n\nGarnier, Simon, Ross, Noam, Rudis, Robert, Camargo, Pedro, A., Sciaini, Marco, Scherer, & Cédric. (2023). viridis(Lite) - colorblind-friendly color maps for r. https://doi.org/10.5281/zenodo.4678327\n\n\nGohel, D., & Skintzos, P. (2024). flextable: Functions for tabular reporting. https://ardata-fr.github.io/flextable-book/\n\n\nMakowski, D., Lüdecke, D., Patil, I., Thériault, R., Ben-Shachar, M. S., & Wiernik, B. M. (2023). Automated results reporting as a practical tool to improve reproducibility and methodological best practices adoption. CRAN. https://easystats.github.io/report/\n\n\nMüller, K. (2020). here: A simpler way to find your files. https://here.r-lib.org/\n\n\nR Core Team. (2024). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nThériault, R. (2023). rempsyc: Convenience functions for psychology. Journal of Open Source Software, 8(87), 5466. https://doi.org/10.21105/joss.05466\n\n\nWickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686. https://doi.org/10.21105/joss.01686\n\n\nXie, Y. (2014). knitr: A comprehensive tool for reproducible research in R. In V. Stodden, F. Leisch, & R. D. Peng (Eds.), Implementing reproducible computational research. Chapman; Hall/CRC.\n\n\nXie, Y. (2015). Dynamic documents with R and knitr (2nd ed.). Chapman; Hall/CRC. https://yihui.org/knitr/\n\n\nXie, Y. (2024). knitr: A general-purpose package for dynamic report generation in r. https://yihui.org/knitr/\n\n\nXie, Y., Allaire, J. J., & Grolemund, G. (2018). R markdown: The definitive guide. Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown\n\n\nXie, Y., Dervieux, C., & Riederer, E. (2020). R markdown cookbook. Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown-cookbook"
  },
  {
    "objectID": "docs/r_sig/24_07_15_quarto_1/index.html#own-templates",
    "href": "docs/r_sig/24_07_15_quarto_1/index.html#own-templates",
    "title": "Reproducible manuscripts with Quarto",
    "section": "Own Templates",
    "text": "Own Templates\nYou can always create your own template Luckily, some people have done a lot of the work for us, and therefore we can use templates provided for specific journals. Oooor more generally, APA templates:"
  },
  {
    "objectID": "docs/r_sig/24_07_15_quarto_1/index.html#papaja",
    "href": "docs/r_sig/24_07_15_quarto_1/index.html#papaja",
    "title": "Reproducible manuscripts with Quarto",
    "section": "Papaja",
    "text": "Papaja\nThere are some markdown templates that format your text in APA style. Most famously, the papaja package lets you write APA conform manuscripts. Sadly only in R Markdown, not in Quarto."
  },
  {
    "objectID": "docs/r_sig/24_07_15_quarto_1/index.html#apaquarto",
    "href": "docs/r_sig/24_07_15_quarto_1/index.html#apaquarto",
    "title": "Reproducible manuscripts with Quarto",
    "section": "apaquarto",
    "text": "apaquarto\nAlternatively, I’ve found (but not yet tested in a whole project) the apaquarto extension. You can install via the Terminal (not the R Console):\n## Set the working directory\ncd path/to/my/folder\n\n## Use the Quarto Template\nquarto use wjschne/apaquarto\n\n\n\n\n\n\nVia R Console\n\n\n\n\n\nAlternativley, you can also try to install via the R Console, however, it didn’t work for quite some people:\n\nsetwd(\"home/my_project\") # Make sure the folder is empty\nquarto::quarto_use_template(\"wjschne/apaquarto\")\n\n\n\n\nThis will create the necessary files in your folder. Update the .qmd file with the same name as your folder. I’d suggest to also create a RStudio-project there, and maybe structure your files into multiple folders (data, R-Scripts …).\nThe template will label your tables and figures correctly, and format the bibliography as well as the whole document.\nThe tables can be build with the packages presented in the last chapter."
  },
  {
    "objectID": "docs/r_sig/24_07_15_quarto_1/index.html#word-templates",
    "href": "docs/r_sig/24_07_15_quarto_1/index.html#word-templates",
    "title": "Reproducible manuscripts with Quarto",
    "section": "Word templates",
    "text": "Word templates\nIf you want a word file as output (maybe some journal or co-author requires you to), you can do that easily by setting format: docx in your yaml header. If you don’t use a template like apaquarto, you can also style your own word template simply by changing the styles in a template word file and then load the template file into your quarto document with\nformat:\n  docx:\n    reference-doc: custom-reference-doc.docx\nin the YAML header. Take a look at the official documentation for more detailled info.\n\n\n\n\n\n\nSplit your project\n\n\n\nI recommend that you split up your project into many subfiles, that get merged in the end in a main document. In my opinion, this makes everything a lot easier to overview, because working with quarto makes it easy to just put everything from data preperation to reporting into one huge, confousing document. For example, you can put R-Functions into a own script and source it with source(functions.R). You can also put each chapter into a own .qmd file, and merge them together in a main document. Take a look at include for some input on how to do that."
  },
  {
    "objectID": "docs/r_sig/24_07_15_quarto_1/index.html#footnotes",
    "href": "docs/r_sig/24_07_15_quarto_1/index.html#footnotes",
    "title": "Reproducible manuscripts with Quarto",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Towfiqu barbhuiya on Unsplash.↩︎"
  },
  {
    "objectID": "docs/r_sig/25_02_10_regex/index.html",
    "href": "docs/r_sig/25_02_10_regex/index.html",
    "title": "Regular expressions",
    "section": "",
    "text": "1"
  },
  {
    "objectID": "docs/r_sig/25_02_10_regex/index.html#selecting-patterns",
    "href": "docs/r_sig/25_02_10_regex/index.html#selecting-patterns",
    "title": "Regular expressions",
    "section": "Selecting patterns",
    "text": "Selecting patterns\nIn base-R we can use grep() for extracting certain patterns from character vectors:\n\nfruits &lt;- c(\"Apple\", \"Banana\", \"Orange\", \"Lemon\", \"Blackberry\", \"Peach\", \"annona\", \"peach\")\n\ngrep(\"e\", fruits)\n\n[1] 1 3 4 5 6 8\n\nfruits[grep(\"e\", fruits)]\n\n[1] \"Apple\"      \"Orange\"     \"Lemon\"      \"Blackberry\" \"Peach\"     \n[6] \"peach\"     \n\n\nIn the tidyverse, we can use str_detect(), which is also easily pipeable:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\niris %&gt;%\n  filter(str_detect(Species, \"set\")) %&gt;% \n  head()\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa"
  },
  {
    "objectID": "docs/r_sig/25_02_10_regex/index.html#manipulating-patterns",
    "href": "docs/r_sig/25_02_10_regex/index.html#manipulating-patterns",
    "title": "Regular expressions",
    "section": "Manipulating patterns",
    "text": "Manipulating patterns\n\ngsub(\"e\", \"a\", fruits)\n\n[1] \"Appla\"      \"Banana\"     \"Oranga\"     \"Lamon\"      \"Blackbarry\"\n[6] \"Paach\"      \"annona\"     \"paach\"     \n\n\nOr, in tidyverse:\n\nstr_replace(fruits, \"e\", \"a\")\n\n[1] \"Appla\"      \"Banana\"     \"Oranga\"     \"Lamon\"      \"Blackbarry\"\n[6] \"Paach\"      \"annona\"     \"paach\"     \n\n\nWith stringr::str_view() we can see how the chosen characters look without having to use grep():\n\nstringr::str_view(fruits, \"e\")\n\n[1] │ Appl&lt;e&gt;\n[3] │ Orang&lt;e&gt;\n[4] │ L&lt;e&gt;mon\n[5] │ Blackb&lt;e&gt;rry\n[6] │ P&lt;e&gt;ach\n[8] │ p&lt;e&gt;ach"
  },
  {
    "objectID": "docs/r_sig/25_02_10_regex/index.html#section",
    "href": "docs/r_sig/25_02_10_regex/index.html#section",
    "title": "Regular expressions",
    "section": ".",
    "text": ".\nThe point . matches any character. So if we want to extract all fruits with an e and another character following we can do that like so:\n\nstr_view(fruits, \"e.\")\n\n[4] │ L&lt;em&gt;on\n[5] │ Blackb&lt;er&gt;ry\n[6] │ P&lt;ea&gt;ch\n[8] │ p&lt;ea&gt;ch\n\n\nOf course we can use multiple points if necessary:\n\nstr_view(fruits, \"a..e\")\n\n[3] │ Or&lt;ange&gt;"
  },
  {
    "objectID": "docs/r_sig/25_02_10_regex/index.html#section-1",
    "href": "docs/r_sig/25_02_10_regex/index.html#section-1",
    "title": "Regular expressions",
    "section": "?",
    "text": "?\nWith ? we can make a pattern optional. In the following example, any letter can preceed or follow the m:\n\nmeasures &lt;- c(\"10 mm\", \"100 m\", \"2 km\", \"8 cm\", \"100 kg\", \"80 g\")\nstr_extract_all(measures, \".?m.?\")\n\n[[1]]\n[1] \" mm\"\n\n[[2]]\n[1] \" m\"\n\n[[3]]\n[1] \"km\"\n\n[[4]]\n[1] \"cm\"\n\n[[5]]\ncharacter(0)\n\n[[6]]\ncharacter(0)"
  },
  {
    "objectID": "docs/r_sig/25_02_10_regex/index.html#section-2",
    "href": "docs/r_sig/25_02_10_regex/index.html#section-2",
    "title": "Regular expressions",
    "section": "+",
    "text": "+\nWith the + the pattern has to match at least once (or more often):\n\nstr_extract_all(measures, \"m+\")\n\n[[1]]\n[1] \"mm\"\n\n[[2]]\n[1] \"m\"\n\n[[3]]\n[1] \"m\"\n\n[[4]]\n[1] \"m\"\n\n[[5]]\ncharacter(0)\n\n[[6]]\ncharacter(0)"
  },
  {
    "objectID": "docs/r_sig/25_02_10_regex/index.html#section-3",
    "href": "docs/r_sig/25_02_10_regex/index.html#section-3",
    "title": "Regular expressions",
    "section": "*",
    "text": "*\nThe * makes any number of following matches optional, so the pattern can be repeated any number of times, including 0:\n\nmeasures[grep(\"m*\", measures)]\n\n[1] \"10 mm\"  \"100 m\"  \"2 km\"   \"8 cm\"   \"100 kg\" \"80 g\""
  },
  {
    "objectID": "docs/r_sig/25_02_10_regex/index.html#section-4",
    "href": "docs/r_sig/25_02_10_regex/index.html#section-4",
    "title": "Regular expressions",
    "section": "[]",
    "text": "[]\nThis creates a character class, so any of the included characters can match (or not match, if we put a ^ in front):\n\nstr_view(fruits, \"a[cn]\")\n\n[2] │ B&lt;an&gt;&lt;an&gt;a\n[3] │ Or&lt;an&gt;ge\n[5] │ Bl&lt;ac&gt;kberry\n[6] │ Pe&lt;ac&gt;h\n[7] │ &lt;an&gt;nona\n[8] │ pe&lt;ac&gt;h\n\n\nThis selects all strings including an a followed by either c or n. Alternatively, we can also choose all e followed by a consonant:\n\nstr_view(fruits, \"e[^aeiou]\")\n\n[4] │ L&lt;em&gt;on\n[5] │ Blackb&lt;er&gt;ry\n\n\nEven better, if we want to match all letters:\n\nstr_view(c(\"ca1\", \"x3\", \"a\"), \"[a-z]\")\n\n[1] │ &lt;c&gt;&lt;a&gt;1\n[2] │ &lt;x&gt;3\n[3] │ &lt;a&gt;\n\n\n… followed by a number:\n\nstr_view(c(\"ca1\", \"x3\", \"3a\"), \"[a-z][0-9]\")\n\n[1] │ c&lt;a1&gt;\n[2] │ &lt;x3&gt;\n\n\n… also starting with a letter:\n\nstr_view(c(\"ca1\", \"x3\", \"3a\"), \"^[a-z][0-9]\")\n\n[2] │ &lt;x3&gt;"
  },
  {
    "objectID": "docs/r_sig/25_02_10_regex/index.html#section-5",
    "href": "docs/r_sig/25_02_10_regex/index.html#section-5",
    "title": "Regular expressions",
    "section": "|",
    "text": "|\nThis is our ‘or’-symbol:\n\nstr_view(fruits, \"an|ea\")\n\n[2] │ B&lt;an&gt;&lt;an&gt;a\n[3] │ Or&lt;an&gt;ge\n[6] │ P&lt;ea&gt;ch\n[7] │ &lt;an&gt;nona\n[8] │ p&lt;ea&gt;ch"
  },
  {
    "objectID": "docs/r_sig/25_02_10_regex/index.html#section-6",
    "href": "docs/r_sig/25_02_10_regex/index.html#section-6",
    "title": "Regular expressions",
    "section": "^",
    "text": "^\nMatches the start:\n\nstr_view(c(\"ba\", \"ab\"), \"^b\")\n\n[1] │ &lt;b&gt;a"
  },
  {
    "objectID": "docs/r_sig/25_02_10_regex/index.html#section-7",
    "href": "docs/r_sig/25_02_10_regex/index.html#section-7",
    "title": "Regular expressions",
    "section": "$",
    "text": "$\nMatches the end:\n\nstr_view(c(\"ba\", \"ab\"), \"b$\")\n\n[2] │ a&lt;b&gt;"
  },
  {
    "objectID": "docs/r_sig/25_02_10_regex/index.html#other-predefined-classes",
    "href": "docs/r_sig/25_02_10_regex/index.html#other-predefined-classes",
    "title": "Regular expressions",
    "section": "Other predefined classes:",
    "text": "Other predefined classes:\n\n\\d: Match digit\n\\D: Match anything but digits\n\\s: Match any whitespace\n\\S: Match anything but whitespace\n\\w: Match any “word”-character (letters and numbers)\n\\W: Match any “non-word”-character.\nFinally, the function tolower() might be helpful to convert Upper case letters to lower case letters."
  },
  {
    "objectID": "docs/r_sig/25_02_10_regex/index.html#escaping",
    "href": "docs/r_sig/25_02_10_regex/index.html#escaping",
    "title": "Regular expressions",
    "section": "Escaping",
    "text": "Escaping\nIf we want to use the actual character instead of its meta-function, we have to escape it (with two \\):\n\nchar_vec &lt;- c(\"+?\", \"ab\", \"34.+\")\n\nstr_view(char_vec, \"\\\\+\")\n\n[1] │ &lt;+&gt;?\n[3] │ 34.&lt;+&gt;\n\n\nFor matching a \\, we need to escape it in the string first, and then match it with four \\:\n\nx &lt;- \"a\\\\b\"\nstr_view(x, \"\\\\\\\\\")\n\n[1] │ a&lt;\\&gt;b"
  },
  {
    "objectID": "docs/r_sig/25_02_10_regex/index.html#section-8",
    "href": "docs/r_sig/25_02_10_regex/index.html#section-8",
    "title": "Regular expressions",
    "section": "{}",
    "text": "{}\n{} allows us to specify the number of matches we are looking for:\n\nstr_view(fruits, \"p{2}\")\n\n[1] │ A&lt;pp&gt;le\n\n\nOr a minimum number:\n\nstr_view(fruits, \"p{1,}\")\n\n[1] │ A&lt;pp&gt;le\n[8] │ &lt;p&gt;each"
  },
  {
    "objectID": "docs/r_sig/25_02_10_regex/index.html#section-9",
    "href": "docs/r_sig/25_02_10_regex/index.html#section-9",
    "title": "Regular expressions",
    "section": "()",
    "text": "()\n() can help us to clarify how the meta-expressions should relate to each other:\n\nstr_view(fruits, \"(an){2}\")\n\n[2] │ B&lt;anan&gt;a\n\n## Instead of:\nstr_view(fruits, \"an{2}\")\n\n[7] │ &lt;ann&gt;ona\n\n\nIn the second example, the {2} relates only to the n, in the first to the an pattern."
  },
  {
    "objectID": "docs/r_sig/25_02_10_regex/index.html#grouping",
    "href": "docs/r_sig/25_02_10_regex/index.html#grouping",
    "title": "Regular expressions",
    "section": "Grouping",
    "text": "Grouping\nUsing paranthesis, we can also create groups which we can use later on in the regex:\n\nstr_view(fruits, \"(.)\\\\1\")\n\n[1] │ A&lt;pp&gt;le\n[5] │ Blackbe&lt;rr&gt;y\n[7] │ a&lt;nn&gt;ona\n\n\nThis selects all fruits that have a double letter. With the \\\\1 we use the content of the first (),which can be any letter in this example (but has to be the same as in the first selection). We can also use multiple groups:\n\nstr_view(fruits, \"(.)(n)\\\\1\\\\2\")\n\n[2] │ B&lt;anan&gt;a"
  },
  {
    "objectID": "docs/r_sig/25_02_10_regex/index.html#footnotes",
    "href": "docs/r_sig/25_02_10_regex/index.html#footnotes",
    "title": "Regular expressions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by verdian chua on Unsplash.↩︎"
  },
  {
    "objectID": "docs/r_sig/24_04_08_tidyverse_column_wise/index.html",
    "href": "docs/r_sig/24_04_08_tidyverse_column_wise/index.html",
    "title": "Column-wise operations in the tidyverse",
    "section": "",
    "text": "1\nlibrary(tidyverse)\n\nathletes &lt;- readRDS(file = here::here(  \"raw_data\", \"athletes.rds\"))"
  },
  {
    "objectID": "docs/r_sig/24_04_08_tidyverse_column_wise/index.html#column-wise-operations-with-across",
    "href": "docs/r_sig/24_04_08_tidyverse_column_wise/index.html#column-wise-operations-with-across",
    "title": "Column-wise operations in the tidyverse",
    "section": "Column-wise operations with across()",
    "text": "Column-wise operations with across()\nInstead of looping over columns with a for-loop, we can also use across() in combination with other tidyverse functions.\n\n\n\n\n\n\nmutate_...()\n\n\n\nThe functions mutate_all(), mutate_at(), and mutate_if() do the same, but are superseded. This means they still work, but the tidyverse team recommends to use across() instead.\n\n\nAcross can take column names and a function that should be applied to the selected columns:\n\n## Here we transform the Height and Weight columns to the type character:\nathletes %&gt;%\n  mutate(across(c(Height, Weight), as.character)) %&gt;%\n  str\n\n'data.frame':   270767 obs. of  16 variables:\n $ NOC   : chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ ID    : int  132181 87371 44977 502 109153 29626 1076 121376 80210 87374 ...\n $ Name  : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Mohammad Halilula\" \"Ahmad Shah Abouwi\" ...\n $ Sex   : chr  \"M\" \"M\" \"M\" \"M\" ...\n $ Age   : int  NA NA 28 NA 24 28 28 NA NA NA ...\n $ Height: chr  NA NA \"163\" NA ...\n $ Weight: chr  NA NA \"57\" NA ...\n $ Team  : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ Games : chr  \"1956 Summer\" \"1948 Summer\" \"1980 Summer\" \"1956 Summer\" ...\n $ Year  : int  1956 1948 1980 1956 1964 1960 1936 1956 1972 1956 ...\n $ Season: chr  \"Summer\" \"Summer\" \"Summer\" \"Summer\" ...\n $ City  : chr  \"Melbourne\" \"London\" \"Moskva\" \"Melbourne\" ...\n $ Sport : chr  \"Hockey\" \"Hockey\" \"Wrestling\" \"Hockey\" ...\n $ Event : chr  \"Hockey Men's Hockey\" \"Hockey Men's Hockey\" \"Wrestling Men's Bantamweight, Freestyle\" \"Hockey Men's Hockey\" ...\n $ Medal : chr  NA NA NA NA ...\n $ Region: chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n\n\nBut it is also possible to select columns based on a selection function:\n\n## And here we transform all numeric columns into character:\nathletes %&gt;%\n  mutate(across(where(is.numeric), as.character)) %&gt;%\n  str()\n\n'data.frame':   270767 obs. of  16 variables:\n $ NOC   : chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ ID    : chr  \"132181\" \"87371\" \"44977\" \"502\" ...\n $ Name  : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Mohammad Halilula\" \"Ahmad Shah Abouwi\" ...\n $ Sex   : chr  \"M\" \"M\" \"M\" \"M\" ...\n $ Age   : chr  NA NA \"28\" NA ...\n $ Height: chr  NA NA \"163\" NA ...\n $ Weight: chr  NA NA \"57\" NA ...\n $ Team  : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ Games : chr  \"1956 Summer\" \"1948 Summer\" \"1980 Summer\" \"1956 Summer\" ...\n $ Year  : chr  \"1956\" \"1948\" \"1980\" \"1956\" ...\n $ Season: chr  \"Summer\" \"Summer\" \"Summer\" \"Summer\" ...\n $ City  : chr  \"Melbourne\" \"London\" \"Moskva\" \"Melbourne\" ...\n $ Sport : chr  \"Hockey\" \"Hockey\" \"Wrestling\" \"Hockey\" ...\n $ Event : chr  \"Hockey Men's Hockey\" \"Hockey Men's Hockey\" \"Wrestling Men's Bantamweight, Freestyle\" \"Hockey Men's Hockey\" ...\n $ Medal : chr  NA NA NA NA ...\n $ Region: chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n\n\nWe can also specify our own transformation function."
  },
  {
    "objectID": "docs/r_sig/24_04_08_tidyverse_column_wise/index.html#using-tidyverse-functions-in-loops",
    "href": "docs/r_sig/24_04_08_tidyverse_column_wise/index.html#using-tidyverse-functions-in-loops",
    "title": "Column-wise operations in the tidyverse",
    "section": "Using tidyverse functions in loops",
    "text": "Using tidyverse functions in loops\nWhen using tidyverse syntax within a loop, we might run into the problem that the tidyverse function can’t deal with our iteration counter like we are used to:\n\n## Trying to transform the Height and Weight column to character using a for-loop.\n## Note: Normally across() would be a better option in this case (and most of the time anyways).\n##       But sometimes a good old fashioned for-loop might be easier to programm to get the job done, \n##       in which case one should keep some specifics in mind: \n\n## This throws an error: \nathletes_2 &lt;- athletes\n\nfor(i in c(\"Height\", \"Weight\")){\n  athletes_2 &lt;- athletes_2 %&gt;%\n    mutate(i = as.character(.$i))\n}\n\nThis doesn’t work, because we are trying to program a function using data masking. Data masking just means that we don’t have to type athletes$Height in a tidyverse function, but simply Height, because the function knows this refers to a column in the current data.frame.\n\nLoops\n\nIn the case of mutate(), we have to use dynamic dots, which need to used if we want to create names programmatically: := instead of =.\nWe need to embrace the changeable variable (either in a function or a loop) like this: {var}.\nIn mutate(), we can also simply write \"{var}_...\" to paste together a new column name.\nIf we just want to extract data, we can use the .data pronoun with [[ (see here). .data helps to clear up ambiguity, it makes clear you want to extract a column from the current data.frame. This is something different than the ., which can be read like “data up to this point” and references the data that gets put into the function where the . is used. The . actually stands for a data.frame, while .data is used for symbol evaluation.\n\n\nathletes_2 &lt;- athletes\n\nfor(i in c(\"Height\", \"Weight\")){\n  athletes_2 &lt;- athletes_2 %&gt;%\n    mutate({{i}} := as.character(.[[i]]))\n}\nstr(athletes_2)\n\n'data.frame':   270767 obs. of  16 variables:\n $ NOC   : chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ ID    : int  132181 87371 44977 502 109153 29626 1076 121376 80210 87374 ...\n $ Name  : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Mohammad Halilula\" \"Ahmad Shah Abouwi\" ...\n $ Sex   : chr  \"M\" \"M\" \"M\" \"M\" ...\n $ Age   : int  NA NA 28 NA 24 28 28 NA NA NA ...\n $ Height: chr  NA NA \"163\" NA ...\n $ Weight: chr  NA NA \"57\" NA ...\n $ Team  : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ Games : chr  \"1956 Summer\" \"1948 Summer\" \"1980 Summer\" \"1956 Summer\" ...\n $ Year  : int  1956 1948 1980 1956 1964 1960 1936 1956 1972 1956 ...\n $ Season: chr  \"Summer\" \"Summer\" \"Summer\" \"Summer\" ...\n $ City  : chr  \"Melbourne\" \"London\" \"Moskva\" \"Melbourne\" ...\n $ Sport : chr  \"Hockey\" \"Hockey\" \"Wrestling\" \"Hockey\" ...\n $ Event : chr  \"Hockey Men's Hockey\" \"Hockey Men's Hockey\" \"Wrestling Men's Bantamweight, Freestyle\" \"Hockey Men's Hockey\" ...\n $ Medal : chr  NA NA NA NA ...\n $ Region: chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n\nfor(i in c(\"Height\", \"Weight\")){\n  athletes_2 &lt;- athletes_2 %&gt;%\n    mutate({{i}} := as.character({{i}}))\n}\nstr(athletes_2)\n\n'data.frame':   270767 obs. of  16 variables:\n $ NOC   : chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ ID    : int  132181 87371 44977 502 109153 29626 1076 121376 80210 87374 ...\n $ Name  : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Mohammad Halilula\" \"Ahmad Shah Abouwi\" ...\n $ Sex   : chr  \"M\" \"M\" \"M\" \"M\" ...\n $ Age   : int  NA NA 28 NA 24 28 28 NA NA NA ...\n $ Height: chr  \"Height\" \"Height\" \"Height\" \"Height\" ...\n $ Weight: chr  \"Weight\" \"Weight\" \"Weight\" \"Weight\" ...\n $ Team  : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ Games : chr  \"1956 Summer\" \"1948 Summer\" \"1980 Summer\" \"1956 Summer\" ...\n $ Year  : int  1956 1948 1980 1956 1964 1960 1936 1956 1972 1956 ...\n $ Season: chr  \"Summer\" \"Summer\" \"Summer\" \"Summer\" ...\n $ City  : chr  \"Melbourne\" \"London\" \"Moskva\" \"Melbourne\" ...\n $ Sport : chr  \"Hockey\" \"Hockey\" \"Wrestling\" \"Hockey\" ...\n $ Event : chr  \"Hockey Men's Hockey\" \"Hockey Men's Hockey\" \"Wrestling Men's Bantamweight, Freestyle\" \"Hockey Men's Hockey\" ...\n $ Medal : chr  NA NA NA NA ...\n $ Region: chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n\n## With programmatically built new columns: \nathletes_3 &lt;- athletes\nfor(i in c(\"Height\", \"Weight\")){\n  athletes_3 &lt;- athletes_3 %&gt;%\n    mutate(\"{i}_char\" := as.character(.[[i]]))\n}\n\nstr(athletes_3)\n\n'data.frame':   270767 obs. of  18 variables:\n $ NOC        : chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ ID         : int  132181 87371 44977 502 109153 29626 1076 121376 80210 87374 ...\n $ Name       : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Mohammad Halilula\" \"Ahmad Shah Abouwi\" ...\n $ Sex        : chr  \"M\" \"M\" \"M\" \"M\" ...\n $ Age        : int  NA NA 28 NA 24 28 28 NA NA NA ...\n $ Height     : int  NA NA 163 NA NA 168 NA NA NA NA ...\n $ Weight     : num  NA NA 57 NA 74 73 NA NA 57 NA ...\n $ Team       : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ Games      : chr  \"1956 Summer\" \"1948 Summer\" \"1980 Summer\" \"1956 Summer\" ...\n $ Year       : int  1956 1948 1980 1956 1964 1960 1936 1956 1972 1956 ...\n $ Season     : chr  \"Summer\" \"Summer\" \"Summer\" \"Summer\" ...\n $ City       : chr  \"Melbourne\" \"London\" \"Moskva\" \"Melbourne\" ...\n $ Sport      : chr  \"Hockey\" \"Hockey\" \"Wrestling\" \"Hockey\" ...\n $ Event      : chr  \"Hockey Men's Hockey\" \"Hockey Men's Hockey\" \"Wrestling Men's Bantamweight, Freestyle\" \"Hockey Men's Hockey\" ...\n $ Medal      : chr  NA NA NA NA ...\n $ Region     : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ Height_char: chr  NA NA \"163\" NA ...\n $ Weight_char: chr  NA NA \"57\" NA ...\n\n\nBeware of overwriting the same data.frame you put into mutate()! Otherwise the resulting data.frame will always be overwritten by the old one that always gets put into the function.\n\n\nFunctions\nThis also applies if we want to define a function with column names as arguments, using tidyverse inside. Here we need to embrace our variable as well to make it data masking friendly:\n\n## This doesn't work:\nprint_col &lt;- function(dat, var){\n  print(dat %&gt;% pull(var))\n}\n\nathletes %&gt;%\n  print_col(Region)\n\n\n## This works:\nprint_col &lt;- function(dat, var){\n  print(dat %&gt;% pull({{var}}))\n}\n\nathletes %&gt;%\n  print_col(Region)\n\n    [1] \"Afghanistan\"                      \"Afghanistan\"                     \n    [3] \"Afghanistan\"                      \"Afghanistan\"                     \n    [5] \"Afghanistan\"                      \"Afghanistan\"                     \n    [7] \"Afghanistan\"                      \"Afghanistan\"                     \n...\n\n\n\n\n\n\n\n\n!!sym()\n\n\n\nIn previous SIG-Sessions we have used !!sym() for this, which also works, but is more to remember:\n\nathletes_2 &lt;- athletes\nfor(i in c(\"Height\", \"Weight\")){\n  athletes_2 &lt;- athletes_2 %&gt;%\n    mutate(!!sym(i) := as.character(!!sym(i)))\n}\n\nstr(athletes_2)\n\n'data.frame':   270767 obs. of  16 variables:\n $ NOC   : chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ ID    : int  132181 87371 44977 502 109153 29626 1076 121376 80210 87374 ...\n $ Name  : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Mohammad Halilula\" \"Ahmad Shah Abouwi\" ...\n $ Sex   : chr  \"M\" \"M\" \"M\" \"M\" ...\n $ Age   : int  NA NA 28 NA 24 28 28 NA NA NA ...\n $ Height: chr  NA NA \"163\" NA ...\n $ Weight: chr  NA NA \"57\" NA ...\n $ Team  : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ Games : chr  \"1956 Summer\" \"1948 Summer\" \"1980 Summer\" \"1956 Summer\" ...\n $ Year  : int  1956 1948 1980 1956 1964 1960 1936 1956 1972 1956 ...\n $ Season: chr  \"Summer\" \"Summer\" \"Summer\" \"Summer\" ...\n $ City  : chr  \"Melbourne\" \"London\" \"Moskva\" \"Melbourne\" ...\n $ Sport : chr  \"Hockey\" \"Hockey\" \"Wrestling\" \"Hockey\" ...\n $ Event : chr  \"Hockey Men's Hockey\" \"Hockey Men's Hockey\" \"Wrestling Men's Bantamweight, Freestyle\" \"Hockey Men's Hockey\" ...\n $ Medal : chr  NA NA NA NA ...\n $ Region: chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ..."
  },
  {
    "objectID": "docs/r_sig/24_04_08_tidyverse_column_wise/index.html#footnotes",
    "href": "docs/r_sig/24_04_08_tidyverse_column_wise/index.html#footnotes",
    "title": "Column-wise operations in the tidyverse",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Darryl Low on Unsplash.↩︎"
  },
  {
    "objectID": "docs/r_sig/23_11_06_renv/index.html",
    "href": "docs/r_sig/23_11_06_renv/index.html",
    "title": "Reproducibility with renv",
    "section": "",
    "text": "1"
  },
  {
    "objectID": "docs/r_sig/23_11_06_renv/index.html#motivation",
    "href": "docs/r_sig/23_11_06_renv/index.html#motivation",
    "title": "Reproducibility with renv",
    "section": "Motivation",
    "text": "Motivation\nPackage versions will change over time. The same goes for R versions. As a consequence, they might work different in the future, which can make it difficult to reproduce your scripts. Therefore it is considered good practice to note down the package and R-versions you use. The package renv can help you with that. Look here for the official getting started page."
  },
  {
    "objectID": "docs/r_sig/23_11_06_renv/index.html#workflow",
    "href": "docs/r_sig/23_11_06_renv/index.html#workflow",
    "title": "Reproducibility with renv",
    "section": "Workflow",
    "text": "Workflow\nFirst, create an RStudio Project in the working directory that should be made reproducible (if you haven’t already).\nIf another R-version should be used in your project, switch to that version. On Windows, you can simply install multiple versions of R and switch between them in RStudio by going to Tools - Global Options - General. Maybe you will have to install renv for this version again.\nThen, initialize the project:\n\n# install.packages(renv)\nrenv::init()\n\nThis will create the basic infrastructure for the usage of renv mainly will do two things:\n\nCreate a project specific package library in the folder renv in your working directory, which contains all the packages currently used by the project. This means different projects can use different package versions, and even different R-Versions. Don’t be confused, the renv folder can get quite big and isn’t uploaded to GitHub by default.\nA .lock file, where the R version and the package versions get documented. From this .lock file we can restore the used packages.\n\nBy the way, it doesn’t matter if you do this in the beginning of your project, in between or at the end. renv::init() will automatically setup the project with all the packages you have used in the project.\nThe rest of your workflow is pretty similar to what you are used to: If you need a new package for you project, you install it like you normally would. You can also use renv::install() which has some additional features compared to install.packages()). For example, you can install specific package versions: renv::install(\"dplyr@1.1.1\"). No matter which one you use: The package will be installed into a global cache, and a link to that package will be put into your project specific library. Then you load your package like you normally would with library().\n\n\n\n\n\n\nCaution\n\n\n\nIn case you are using a renv project not locally but on the IQB-drive, the links won’t work, and renv will have to download and install the packages newly into your directory.\n\n\nThe next step is to write the package into your .lock file:\n\nrenv::snapshot()\n\nThis will update the .lock file with your new package.\nIf on the other hand you want to restore the packages from the .lock file, use:\n\nrenv::restore()\n\nThis will install all packages that are not already in your project specific library with the package version that is documented in the lock file into your project specific library.\nYou can update your dependencies to the latest version using:\n\nrenv::update()"
  },
  {
    "objectID": "docs/r_sig/23_11_06_renv/index.html#package-versions",
    "href": "docs/r_sig/23_11_06_renv/index.html#package-versions",
    "title": "Reproducibility with renv",
    "section": "Package Versions",
    "text": "Package Versions\nIf you want to install specific package versions, you can use\n\nrenv::intit(bare = TRUE)\n\nin the beginning. This sets up the renv project without trying to find the used dependencies. Thus, you can install the specific versions manually afterward:\n\nrenv::install(packagename/@version-number)\n\nFor example:\n\nrenv::install(\"tidyselect@1.1.2\")\n\nLocal packages or packages from GitHub can be installed as well (see here).\nPosit Public Package Manager contains the CRAN history of CRAN packages back to 2014. Package version historys can be found here easily, for example, when a script was finished on 06.05.22, we can look up which package version was the current one on that day."
  },
  {
    "objectID": "docs/r_sig/23_11_06_renv/index.html#footnotes",
    "href": "docs/r_sig/23_11_06_renv/index.html#footnotes",
    "title": "Reproducibility with renv",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage by Nagara Oyodo on Unsplash.↩︎"
  },
  {
    "objectID": "docs/posts_r_sig.html",
    "href": "docs/posts_r_sig.html",
    "title": "R-SIG",
    "section": "",
    "text": "In the “R Special Interest Group” (R-SIG) we talk about all kinds of topics related to coding in R. It takes place every other week, so drop by if you’re interested!\n\nStructure\nEach session will focus on a specific topic/exercise, with a little input in the beginning, and a longer exercise part afterwards.\nYou also have the opportunity to bring in R-related questions which we will discuss in the end for 10 - 15 minutes. Please send them in the Friday before the next session.\nA suggestion for a timetable we can loosely follow:\n\n13:00 - 13:15: Input\n13:15 - 13:35: Exercise time :)\n13:35 - 13:50: Discuss exercises\n13:50 - 14:10: Questions\n\n\n\nFuture Topics\nHere a list of possible topics for the next sessions.\n\ntidyverse\n\nIntroduction\nData wrangling\nPlotting with ggplot2\n\nRecap of “Advanced Basics”:\n\nOwn functions\nloops\napply-family\n\nPackage development and how it might be relevant for scientific analyses:\n\nOwn functions\nStructure of projects\nTesting!\n\nCode Review: How to improve code I (or somebody else) has written. You can send in your code, it might be a nice way of getting feedback you won’t get otherwise. (Code review is very common in programming, as it can be very helpful to get some feedback or learn about different ways of doing stuff).\nCoding Kata: The website Codewars let’s you solve different coding challenges.\n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\nReading Time\n\n\n\n\n\n\n\n\n\nOct 2, 2025\n\n\nRegular expressions\n\n\nNicklas Hafiz\n\n\n5 min\n\n\n\n\n\n\n\nSep 9, 2024\n\n\nReproducible manuscripts with Git\n\n\nNicklas Hafiz\n\n\n6 min\n\n\n\n\n\n\n\nJul 15, 2024\n\n\nReproducible manuscripts with Quarto\n\n\nNicklas Hafiz\n\n\n14 min\n\n\n\n\n\n\n\nJun 3, 2024\n\n\nPlotting with ggplot2\n\n\nNicklas Hafiz\n\n\n1 min\n\n\n\n\n\n\n\nApr 8, 2024\n\n\nColumn-wise operations in the tidyverse\n\n\nNicklas Hafiz\n\n\n6 min\n\n\n\n\n\n\n\nMar 25, 2024\n\n\nData wrangling in the tidyverse\n\n\nNicklas Hafiz\n\n\n12 min\n\n\n\n\n\n\n\nMar 22, 2024\n\n\nData sets\n\n\nNicklas Hafiz\n\n\n2 min\n\n\n\n\n\n\n\nFeb 26, 2024\n\n\nIntroduction to the tidyverse\n\n\nNicklas Hafiz\n\n\n7 min\n\n\n\n\n\n\n\nDec 18, 2023\n\n\nCase_when() function\n\n\nNicklas Hafiz\n\n\n5 min\n\n\n\n\n\n\n\nOct 23, 2023\n\n\nReproducibility with renv\n\n\nNicklas Hafiz\n\n\n3 min\n\n\n\n\n\n\n\nOct 9, 2023\n\n\nCleaner Scripts\n\n\nNicklas Hafiz\n\n\n2 min\n\n\n\n\n\n\n\nJul 31, 2023\n\n\nThe apply family\n\n\nNicklas Hafiz\n\n\n4 min\n\n\n\n\n\n\n\nMar 20, 2023\n\n\nfor-loops\n\n\nNicklas Hafiz\n\n\n1 min\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "docs/advanced.html",
    "href": "docs/advanced.html",
    "title": "Advanced R",
    "section": "",
    "text": "1\nWelcome to our advanced learn page. Here you can find more advanced material, links and articles about R, RStudio and more."
  },
  {
    "objectID": "docs/advanced.html#articles-and-workshops",
    "href": "docs/advanced.html#articles-and-workshops",
    "title": "Advanced R",
    "section": "Articles and Workshops",
    "text": "Articles and Workshops"
  },
  {
    "objectID": "docs/advanced.html#footnotes",
    "href": "docs/advanced.html#footnotes",
    "title": "Advanced R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFoto von Nicolas Lobos auf Unsplash↩︎"
  }
]